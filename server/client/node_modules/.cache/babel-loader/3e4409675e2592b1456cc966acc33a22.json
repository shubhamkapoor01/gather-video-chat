{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2018 Google LLC. All Rights Reserved.\r\n * Licensed under the Apache License, Version 2.0 (the \"License\");\r\n * you may not use this file except in compliance with the License.\r\n * You may obtain a copy of the License at\r\n *\r\n * http://www.apache.org/licenses/LICENSE-2.0\r\n *\r\n * Unless required by applicable law or agreed to in writing, software\r\n * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n * See the License for the specific language governing permissions and\r\n * limitations under the License.\r\n *\r\n * =============================================================================\r\n */\nimport * as tf from '@tensorflow/tfjs-core';\nimport * as seedrandom from 'seedrandom';\nimport { deepClone } from '../util/deep_clone';\nimport { deepMapAndAwaitAll, deepZip, zipToList } from '../util/deep_map';\nimport { GrowingRingBuffer } from '../util/growing_ring_buffer';\nimport { RingBuffer } from '../util/ring_buffer'; // Here we implement a simple asynchronous iterator.\n// This lets us avoid using either third-party stream libraries or\n// recent TypeScript language support requiring polyfills.\n\n/**\r\n * Create a `LazyIterator` from an array of items.\r\n */\n\nexport function iteratorFromItems(items) {\n  return new ArrayIterator(items);\n}\n/**\r\n * Create a `LazyIterator` of incrementing integers.\r\n */\n\nexport function iteratorFromIncrementing(start) {\n  let i = start;\n  return iteratorFromFunction(() => ({\n    value: i++,\n    done: false\n  }));\n}\n/**\r\n * Create a `LazyIterator` from a function.\r\n *\r\n * ```js\r\n * let i = -1;\r\n * const func = () =>\r\n *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\r\n * const iter = tf.data.iteratorFromFunction(func);\r\n * await iter.forEachAsync(e => console.log(e));\r\n * ```\r\n *\r\n * @param func A function that produces data on each call.\r\n */\n\nexport function iteratorFromFunction(func) {\n  return new FunctionCallIterator(func);\n}\n/**\r\n * Create a `LazyIterator` by concatenating underlying streams, which are\r\n * themselves provided as a stream.\r\n *\r\n * This can also be thought of as a \"stream flatten\" operation.\r\n *\r\n * @param baseIterators A stream of streams to be concatenated.\r\n * @param baseErrorHandler An optional function that can intercept `Error`s\r\n *   raised during a `next()` call on the base stream.  This function can decide\r\n *   whether the error should be propagated, whether the error should be\r\n *   ignored, or whether the base stream should be terminated.\r\n */\n\nexport function iteratorFromConcatenated(baseIterators, baseErrorHandler) {\n  return new ChainedIterator(baseIterators, baseErrorHandler);\n}\n/**\r\n * Create a `LazyIterator` by concatenating streams produced by calling a\r\n * stream-generating function a given number of times.\r\n *\r\n * Since a `LazyIterator` is read-once, it cannot be repeated, but this\r\n * function can be used to achieve a similar effect:\r\n *\r\n *   LazyIterator.ofConcatenatedFunction(() => new MyIterator(), 6);\r\n *\r\n * @param iteratorFunc: A function that produces a new stream on each call.\r\n * @param count: The number of times to call the function.\r\n * @param baseErrorHandler An optional function that can intercept `Error`s\r\n *   raised during a `next()` call on the base stream.  This function can decide\r\n *   whether the error should be propagated, whether the error should be\r\n *   ignored, or whether the base stream should be terminated.\r\n */\n\nexport function iteratorFromConcatenatedFunction(iteratorFunc, count, baseErrorHandler) {\n  return iteratorFromConcatenated(iteratorFromFunction(iteratorFunc).take(count), baseErrorHandler);\n}\n/**\r\n * Create a `LazyIterator` by zipping together an array, dict, or nested\r\n * structure of `LazyIterator`s (and perhaps additional constants).\r\n *\r\n * The underlying streams must provide elements in a consistent order such\r\n * that they correspond.\r\n *\r\n * Typically, the underlying streams should have the same number of\r\n * elements. If they do not, the behavior is determined by the\r\n * `mismatchMode` argument.\r\n *\r\n * The nested structure of the `iterators` argument determines the\r\n * structure of elements in the resulting iterator.\r\n *\r\n * @param iterators: An array or object containing LazyIterators at the\r\n * leaves.\r\n * @param mismatchMode: Determines what to do when one underlying iterator\r\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\r\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\r\n * causes the zipped iterator to terminate with the furst underlying\r\n * streams, so elements remaining on the longer streams are ignored.\r\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\r\n * in nulls for the exhausted streams, until all streams are exhausted.\r\n */\n\nexport function iteratorFromZipped(iterators, mismatchMode = ZipMismatchMode.FAIL) {\n  return new ZipIterator(iterators, mismatchMode);\n}\n/**\r\n * An asynchronous iterator, providing lazy access to a potentially\r\n * unbounded stream of elements.\r\n *\r\n * Iterator can be obtained from a dataset:\r\n * `const iter = await dataset.iterator();`\r\n */\n\nexport class LazyIterator {\n  /**\r\n   * Collect all remaining elements of a bounded stream into an array.\r\n   * Obviously this will succeed only for small streams that fit in memory.\r\n   * Useful for testing.\r\n   *\r\n   * @returns A Promise for an array of stream elements, which will resolve\r\n   *   when the stream is exhausted.\r\n   */\n  async toArray() {\n    const result = [];\n    let x = await this.next();\n\n    while (!x.done) {\n      result.push(x.value);\n      x = await this.next();\n    }\n\n    return result;\n  }\n  /**\r\n   * Collect all elements of this dataset into an array with prefetching 100\r\n   * elements. This is useful for testing, because the prefetch changes the\r\n   * order in which the Promises are resolved along the processing pipeline.\r\n   * This may help expose bugs where results are dependent on the order of\r\n   * Promise resolution rather than on the logical order of the stream (i.e.,\r\n   * due to hidden mutable state).\r\n   *\r\n   * @returns A Promise for an array of stream elements, which will resolve\r\n   *   when the stream is exhausted.\r\n   */\n\n\n  async toArrayForTest() {\n    const stream = this.prefetch(100);\n    const result = [];\n    let x = await stream.next();\n\n    while (!x.done) {\n      result.push(x.value);\n      x = await stream.next();\n    }\n\n    return result;\n  }\n  /**\r\n   * Draw items from the stream until it is exhausted.\r\n   *\r\n   * This can be useful when the stream has side effects but no output.  In\r\n   * that case, calling this function guarantees that the stream will be\r\n   * fully processed.\r\n   */\n\n\n  async resolveFully() {\n    let x = await this.next();\n\n    while (!x.done) {\n      x = await this.next();\n    }\n  }\n  /**\r\n   * Draw items from the stream until it is exhausted, or a predicate fails.\r\n   *\r\n   * This can be useful when the stream has side effects but no output.  In\r\n   * that case, calling this function guarantees that the stream will be\r\n   * fully processed.\r\n   */\n\n\n  async resolveWhile(predicate) {\n    let x = await this.next();\n    let shouldContinue = predicate(x.value);\n\n    while (!x.done && shouldContinue) {\n      x = await this.next();\n      shouldContinue = predicate(x.value);\n    }\n  }\n  /**\r\n   * Handles errors thrown on this stream using a provided handler function.\r\n   *\r\n   * @param handler A function that handles any `Error` thrown during a `next()`\r\n   *   call and returns true if the stream should continue (dropping the failed\r\n   *   call) or false if the stream should quietly terminate.  If the handler\r\n   *   itself throws (or rethrows) an `Error`, that will be propagated.\r\n   *\r\n   * @returns A `LazyIterator` of elements passed through from upstream,\r\n   *   possibly filtering or terminating on upstream `next()` calls that\r\n   *   throw an `Error`.\r\n   */\n\n\n  handleErrors(handler) {\n    return new ErrorHandlingLazyIterator(this, handler);\n  } // TODO(soergel): Implement reduce() etc.\n\n  /**\r\n   * Filters this stream according to `predicate`.\r\n   *\r\n   * @param predicate A function mapping a stream element to a boolean or a\r\n   * `Promise` for one.\r\n   *\r\n   * @returns A `LazyIterator` of elements for which the predicate was true.\r\n   */\n\n\n  filter(predicate) {\n    return new FilterIterator(this, predicate);\n  }\n  /**\r\n   * Maps this stream through a 1-to-1 transform.\r\n   *\r\n   * @param transform A function mapping a stream element to a transformed\r\n   *   element.\r\n   *\r\n   * @returns A `LazyIterator` of transformed elements.\r\n   */\n\n\n  map(transform) {\n    return new MapIterator(this, transform);\n  }\n  /**\r\n   * Maps this stream through an async 1-to-1 transform.\r\n   *\r\n   * @param transform A function mapping a stream element to a `Promise` for a\r\n   *   transformed stream element.\r\n   *\r\n   * @returns A `LazyIterator` of transformed elements.\r\n   */\n\n\n  mapAsync(transform) {\n    return new AsyncMapIterator(this, transform);\n  }\n  /**\r\n   * Maps this stream through a 1-to-1 transform, forcing serial execution.\r\n   *\r\n   * @param transform A function mapping a stream element to a transformed\r\n   *   element.\r\n   *\r\n   * @returns A `LazyIterator` of transformed elements.\r\n   */\n\n\n  serialMapAsync(transform) {\n    return new AsyncMapIterator(this, transform).serial();\n  }\n  /**\r\n   * Maps this stream through a 1-to-many transform.\r\n   *\r\n   * @param transform A function mapping a stream element to an array of\r\n   *   transformed elements.\r\n   *\r\n   * @returns A `DataStream` of transformed elements.\r\n   */\n\n\n  flatmap(transform) {\n    return new FlatmapIterator(this, transform);\n  }\n  /**\r\n   * Apply a function to every element of the stream.\r\n   *\r\n   * @param f A function to apply to each stream element.\r\n   */\n\n\n  async forEachAsync(f) {\n    return this.map(f).resolveFully();\n  }\n  /**\r\n   * Apply a function to every element of the stream, forcing serial execution.\r\n   *\r\n   * @param f A function to apply to each stream element.  Should return 'true'\r\n   *   to indicate that the stream should continue, or 'false' to cause it to\r\n   *   terminate.\r\n   */\n\n\n  async serialForEach(f) {\n    return this.serialMapAsync(f).resolveWhile(x => x === true);\n  }\n  /**\r\n   * Groups elements into batches, represented as arrays of elements.\r\n   *\r\n   * We can think of the elements of this iterator as 'rows' (even if they are\r\n   * nested structures).  By the same token, consecutive values for a given\r\n   * key within the elements form a 'column'.  This matches the usual sense of\r\n   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\r\n   *\r\n   * Thus, \"Row-major\" means that the resulting batch is simply a collection of\r\n   * rows: `[row1, row2, row3, ...]`.  This is contrast to the column-major\r\n   * form, which is needed for vectorized computation.\r\n   *\r\n   * @param batchSize The number of elements desired per batch.\r\n   * @param smallLastBatch Whether to emit the final batch when it has fewer\r\n   *   than batchSize elements. Default true.\r\n   * @returns A `LazyIterator` of batches of elements, represented as arrays\r\n   *   of the original element type.\r\n   */\n\n\n  rowMajorBatch(batchSize, smallLastBatch = true) {\n    return new RowMajorBatchIterator(this, batchSize, smallLastBatch);\n  }\n  /**\r\n   * Groups elements into batches, represented in column-major form.\r\n   *\r\n   * We can think of the elements of this iterator as 'rows' (even if they are\r\n   * nested structures).  By the same token, consecutive values for a given\r\n   * key within the elements form a 'column'.  This matches the usual sense of\r\n   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\r\n   *\r\n   * Thus, \"column-major\" means that the resulting batch is a (potentially\r\n   * nested) structure representing the columns.  Each column entry, then,\r\n   * contains a collection of the values found in that column for a range of\r\n   * input elements.  This representation allows for vectorized computation, in\r\n   * contrast to the row-major form.\r\n   *\r\n   * The inputs should all have the same nested structure (i.e., of arrays and\r\n   * dicts).  The result is a single object with the same nested structure,\r\n   * where the leaves are arrays collecting the values of the inputs at that\r\n   * location (or, optionally, the result of a custom function applied to those\r\n   * arrays).\r\n   *\r\n   * @param batchSize The number of elements desired per batch.\r\n   * @param smallLastBatch Whether to emit the final batch when it has fewer\r\n   *   than batchSize elements. Default true.\r\n   * @param zipFn: (optional) A function that expects an array of elements at a\r\n   *   single node of the object tree, and returns a `DeepMapResult`.  The\r\n   *   `DeepMapResult` either provides a result value for that node (i.e.,\r\n   *   representing the subtree), or indicates that the node should be processed\r\n   *   recursively.  The default zipFn recurses as far as possible and places\r\n   *   arrays at the leaves.\r\n   * @returns A `LazyIterator` of batches of elements, represented as an object\r\n   *   with collections at the leaves.\r\n   */\n\n\n  columnMajorBatch(batchSize, smallLastBatch = true, // tslint:disable-next-line:no-any\n  zipFn = zipToList) {\n    // First collect the desired number of input elements as a row-major batch.\n    const rowBatches = this.rowMajorBatch(batchSize, smallLastBatch); // Now 'rotate' or 'pivot' the data, collecting all values from each column\n    // in the batch (i.e., for each key within the elements) into an array.\n\n    return rowBatches.map(x => deepZip(x, zipFn));\n  }\n  /**\r\n   * Concatenate this `LazyIterator` with another.\r\n   *\r\n   * @param iterator A `LazyIterator` to be concatenated onto this one.\r\n   * @param baseErrorHandler An optional function that can intercept `Error`s\r\n   *   raised during a `next()` call on the base stream.  This function can\r\n   *   decide whether the error should be propagated, whether the error should\r\n   *   be ignored, or whether the base stream should be terminated.\r\n   * @returns A `LazyIterator`.\r\n   */\n\n\n  concatenate(iterator, baseErrorHandler) {\n    return new ChainedIterator(iteratorFromItems([this, iterator]), baseErrorHandler);\n  }\n  /**\r\n   * Limits this stream to return at most `count` items.\r\n   *\r\n   * @param count The maximum number of items to provide from the stream. If\r\n   * a negative or undefined value is given, the entire stream is returned\r\n   *   unaltered.\r\n   */\n\n\n  take(count) {\n    if (count < 0 || count == null) {\n      return this;\n    }\n\n    return new TakeIterator(this, count);\n  }\n  /**\r\n   * Skips the first `count` items in this stream.\r\n   *\r\n   * @param count The number of items to skip.  If a negative or undefined\r\n   * value is given, the entire stream is returned unaltered.\r\n   */\n\n\n  skip(count) {\n    if (count < 0 || count == null) {\n      return this;\n    }\n\n    return new SkipIterator(this, count);\n  }\n  /**\r\n   * Prefetch the first `bufferSize` items in this stream.\r\n   *\r\n   * Note this prefetches Promises, but makes no guarantees about when those\r\n   * Promises resolve.\r\n   *\r\n   * @param bufferSize: An integer specifying the number of elements to be\r\n   *   prefetched.\r\n   */\n\n\n  prefetch(bufferSize) {\n    return new PrefetchIterator(this, bufferSize);\n  } // TODO(soergel): deep sharded shuffle, where supported\n\n  /**\r\n   * Randomly shuffles the elements of this stream.\r\n   *\r\n   * @param bufferSize: An integer specifying the number of elements from\r\n   * this stream from which the new stream will sample.\r\n   * @param seed: (Optional.) An integer specifying the random seed that\r\n   * will be used to create the distribution.\r\n   */\n\n\n  shuffle(windowSize, seed) {\n    return new ShuffleIterator(this, windowSize, seed);\n  }\n  /**\r\n   * Force an iterator to execute serially: each next() call will await the\r\n   * prior one, so that they cannot execute concurrently.\r\n   */\n\n\n  serial() {\n    return new SerialIterator(this);\n  }\n\n} // ============================================================================\n// The following private classes serve to implement the chainable methods\n// on LazyIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n// Iterators that just extend LazyIterator directly\n// ============================================================================\n\nclass ArrayIterator extends LazyIterator {\n  constructor(items) {\n    super();\n    this.items = items;\n    this.trav = 0;\n  }\n\n  summary() {\n    return `Array of ${this.items.length} items`;\n  }\n\n  async next() {\n    if (this.trav >= this.items.length) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    const item = this.items[this.trav];\n    this.trav++;\n    return {\n      value: deepClone(item),\n      done: false\n    };\n  }\n\n}\n\nclass FunctionCallIterator extends LazyIterator {\n  constructor(nextFn) {\n    super();\n    this.nextFn = nextFn;\n  }\n\n  summary() {\n    return `Function call`;\n  }\n\n  async next() {\n    try {\n      return this.nextFn();\n    } catch (e) {\n      // Modify the error message but leave the stack trace intact\n      e.message = `Error thrown while iterating through a dataset: ${e.message}`;\n      throw e;\n    }\n  }\n\n}\n\nclass SerialIterator extends LazyIterator {\n  constructor(upstream) {\n    super();\n    this.upstream = upstream;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Serial`;\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    return this.upstream.next();\n  }\n\n}\n\nclass SkipIterator extends LazyIterator {\n  constructor(upstream, maxCount) {\n    super();\n    this.upstream = upstream;\n    this.maxCount = maxCount; // Local state that should not be clobbered by out-of-order execution.\n\n    this.count = 0;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Skip`;\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    // TODO(soergel): consider tradeoffs of reading in parallel, eg.\n    // collecting next() promises in an Array and then waiting for\n    // Promise.all() of those. Benefit: pseudo-parallel execution.  Drawback:\n    // maybe delayed GC.\n    while (this.count++ < this.maxCount) {\n      const skipped = await this.upstream.next(); // short-circuit if upstream is already empty\n\n      if (skipped.done) {\n        return skipped;\n      }\n\n      tf.dispose(skipped.value);\n    }\n\n    return this.upstream.next();\n  }\n\n}\n\nclass TakeIterator extends LazyIterator {\n  constructor(upstream, maxCount) {\n    super();\n    this.upstream = upstream;\n    this.maxCount = maxCount;\n    this.count = 0;\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Take`;\n  }\n\n  async next() {\n    if (this.count++ >= this.maxCount) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    return this.upstream.next();\n  }\n\n} // Note this batch just groups items into row-wise element arrays.\n// Rotating these to a column-wise representation happens only at the dataset\n// level.\n\n\nclass RowMajorBatchIterator extends LazyIterator {\n  constructor(upstream, batchSize, enableSmallLastBatch = true) {\n    super();\n    this.upstream = upstream;\n    this.batchSize = batchSize;\n    this.enableSmallLastBatch = enableSmallLastBatch;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> RowMajorBatch`;\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    const batch = [];\n\n    while (batch.length < this.batchSize) {\n      const item = await this.upstream.next();\n\n      if (item.done) {\n        if (this.enableSmallLastBatch && batch.length > 0) {\n          return {\n            value: batch,\n            done: false\n          };\n        }\n\n        return {\n          value: null,\n          done: true\n        };\n      }\n\n      batch.push(item.value);\n    }\n\n    return {\n      value: batch,\n      done: false\n    };\n  }\n\n}\n\nclass FilterIterator extends LazyIterator {\n  constructor(upstream, predicate) {\n    super();\n    this.upstream = upstream;\n    this.predicate = predicate;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Filter`;\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    while (true) {\n      const item = await this.upstream.next();\n\n      if (item.done || this.predicate(item.value)) {\n        return item;\n      }\n\n      tf.dispose(item.value);\n    }\n  }\n\n}\n\nclass MapIterator extends LazyIterator {\n  constructor(upstream, transform) {\n    super();\n    this.upstream = upstream;\n    this.transform = transform;\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Map`;\n  }\n\n  async next() {\n    const item = await this.upstream.next();\n\n    if (item.done) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value); // Careful: the transform may mutate the item in place.\n    // That's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying\n    // any intermediate Tensors.  Here we are concerned only about the\n    // inputs.\n\n    const mapped = this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mapped); // TODO(soergel) faster intersection\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n\n    return {\n      value: mapped,\n      done: false\n    };\n  }\n\n}\n\nclass ErrorHandlingLazyIterator extends LazyIterator {\n  constructor(upstream, handler) {\n    super();\n    this.upstream = upstream;\n    this.handler = handler;\n    this.count = 0;\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> handleErrors`;\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    while (true) {\n      try {\n        return await this.upstream.next();\n      } catch (e) {\n        if (!this.handler(e)) {\n          return {\n            value: null,\n            done: true\n          };\n        } // If the handler returns true, loop and fetch the next upstream item.\n        // If the upstream iterator throws an endless stream of errors, and if\n        // the handler says to ignore them, then we loop forever here.  That is\n        // the correct behavior-- it's up to the handler to decide when to stop.\n\n      }\n    }\n  }\n\n}\n\nclass AsyncMapIterator extends LazyIterator {\n  constructor(upstream, transform) {\n    super();\n    this.upstream = upstream;\n    this.transform = transform;\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> AsyncMap`;\n  }\n\n  async next() {\n    const item = await this.upstream.next();\n\n    if (item.done) {\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value); // Careful: the transform may mutate the item in place.\n    // That's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying\n    // any intermediate Tensors.  Here we are concerned only about the\n    // inputs.\n\n    const mapped = await this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mapped); // TODO(soergel) faster intersection\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n\n    return {\n      value: mapped,\n      done: false\n    };\n  }\n\n} // Iterators that maintain a queue of pending items\n// ============================================================================\n\n/**\r\n * A base class for transforming streams that operate by maintaining an\r\n * output queue of elements that are ready to return via next().  This is\r\n * commonly required when the transformation is 1-to-many:  A call to next()\r\n * may trigger a call to the underlying stream, which will produce many\r\n * mapped elements of this stream-- of which we need to return only one, so\r\n * we have to queue the rest.\r\n */\n\n\nexport class OneToManyIterator extends LazyIterator {\n  constructor() {\n    super();\n    this.outputQueue = new GrowingRingBuffer();\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext() {\n    // Fetch so that the queue contains at least one item if possible.\n    // If the upstream source is exhausted, AND there are no items left in\n    // the output queue, then this stream is also exhausted.\n    while (this.outputQueue.length() === 0) {\n      // TODO(soergel): consider parallel reads.\n      if (!(await this.pump())) {\n        return {\n          value: null,\n          done: true\n        };\n      }\n    }\n\n    return {\n      value: this.outputQueue.shift(),\n      done: false\n    };\n  }\n\n}\n\nclass FlatmapIterator extends OneToManyIterator {\n  constructor(upstream, transform) {\n    super();\n    this.upstream = upstream;\n    this.transform = transform;\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Flatmap`;\n  }\n\n  async pump() {\n    const item = await this.upstream.next();\n\n    if (item.done) {\n      return false;\n    }\n\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value); // Careful: the transform may mutate the item in place.\n    // that's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying any\n    // intermediate Tensors.  Here we are concerned only about the inputs.\n\n    const mappedArray = this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mappedArray);\n    this.outputQueue.pushAll(mappedArray); // TODO(soergel) faster intersection, and deduplicate outputTensors\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n\n    return true;\n  }\n\n}\n/**\r\n * Provides a `LazyIterator` that concatenates a stream of underlying\r\n * streams.\r\n *\r\n * Doing this in a concurrency-safe way requires some trickery.  In\r\n * particular, we want this stream to return the elements from the\r\n * underlying streams in the correct order according to when next() was\r\n * called, even if the resulting Promises resolve in a different order.\r\n */\n\n\nexport class ChainedIterator extends LazyIterator {\n  constructor(iterators, baseErrorHandler) {\n    super();\n    this.baseErrorHandler = baseErrorHandler; // Strict Promise execution order:\n    // a next() call may not even begin until the previous one completes.\n\n    this.lastRead = null; // Local state that should not be clobbered by out-of-order execution.\n\n    this.iterator = null;\n    this.moreIterators = iterators;\n  }\n\n  summary() {\n    const upstreamSummaries = 'TODO: fill in upstream of chained summaries';\n    return `${upstreamSummaries} -> Chained`;\n  }\n\n  async next() {\n    this.lastRead = this.readFromChain(this.lastRead);\n    return this.lastRead;\n  }\n\n  async readFromChain(lastRead) {\n    // Must await on the previous read since the previous read may have advanced\n    // the stream of streams, from which we need to read.\n    // This is unfortunate since we can't parallelize reads. Which means\n    // prefetching of chained streams is a no-op.\n    // One solution is to prefetch immediately upstream of this.\n    await lastRead;\n\n    if (this.iterator == null) {\n      const iteratorResult = await this.moreIterators.next();\n\n      if (iteratorResult.done) {\n        // No more streams to stream from.\n        return {\n          value: null,\n          done: true\n        };\n      }\n\n      this.iterator = iteratorResult.value;\n\n      if (this.baseErrorHandler != null) {\n        this.iterator = this.iterator.handleErrors(this.baseErrorHandler);\n      }\n    }\n\n    const itemResult = await this.iterator.next();\n\n    if (itemResult.done) {\n      this.iterator = null;\n      return this.readFromChain(lastRead);\n    }\n\n    return itemResult;\n  }\n\n}\nexport var ZipMismatchMode;\n\n(function (ZipMismatchMode) {\n  ZipMismatchMode[ZipMismatchMode[\"FAIL\"] = 0] = \"FAIL\";\n  ZipMismatchMode[ZipMismatchMode[\"SHORTEST\"] = 1] = \"SHORTEST\";\n  ZipMismatchMode[ZipMismatchMode[\"LONGEST\"] = 2] = \"LONGEST\"; // use nulls for exhausted streams; use up the longest stream.\n})(ZipMismatchMode || (ZipMismatchMode = {}));\n/**\r\n * Provides a `LazyIterator` that zips together an array, dict, or nested\r\n * structure of `LazyIterator`s (and perhaps additional constants).\r\n *\r\n * The underlying streams must provide elements in a consistent order such\r\n * that they correspond.\r\n *\r\n * Typically, the underlying streams should have the same number of\r\n * elements. If they do not, the behavior is determined by the\r\n * `mismatchMode` argument.\r\n *\r\n * The nested structure of the `iterators` argument determines the\r\n * structure of elements in the resulting iterator.\r\n *\r\n * Doing this in a concurrency-safe way requires some trickery.  In\r\n * particular, we want this stream to return the elements from the\r\n * underlying streams in the correct order according to when next() was\r\n * called, even if the resulting Promises resolve in a different order.\r\n *\r\n * @param iterators: An array or object containing LazyIterators at the\r\n * leaves.\r\n * @param mismatchMode: Determines what to do when one underlying iterator\r\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\r\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\r\n * causes the zipped iterator to terminate with the furst underlying\r\n * streams, so elements remaining on the longer streams are ignored.\r\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\r\n * in nulls for the exhausted streams, until all streams are exhausted.\r\n */\n\n\nclass ZipIterator extends LazyIterator {\n  constructor(iterators, mismatchMode = ZipMismatchMode.FAIL) {\n    super();\n    this.iterators = iterators;\n    this.mismatchMode = mismatchMode;\n    this.count = 0;\n    this.currentPromise = null;\n  }\n\n  summary() {\n    const upstreamSummaries = 'TODO: fill in upstream of zip summaries';\n    return `{${upstreamSummaries}} -> Zip`;\n  }\n\n  async nextState(afterState) {\n    // This chaining ensures that the underlying next() are not even called\n    // before the previous ones have resolved.\n    await afterState; // Collect underlying iterator \"done\" signals as a side effect in\n    // getNext()\n\n    let numIterators = 0;\n    let iteratorsDone = 0;\n\n    function getNext(container) {\n      if (container instanceof LazyIterator) {\n        const result = container.next();\n        return {\n          value: result.then(x => {\n            numIterators++;\n\n            if (x.done) {\n              iteratorsDone++;\n            }\n\n            return x.value;\n          }),\n          recurse: false\n        };\n      } else {\n        return {\n          value: null,\n          recurse: true\n        };\n      }\n    }\n\n    const mapped = await deepMapAndAwaitAll(this.iterators, getNext);\n\n    if (numIterators === iteratorsDone) {\n      // The streams have all ended.\n      return {\n        value: null,\n        done: true\n      };\n    }\n\n    if (iteratorsDone > 0) {\n      switch (this.mismatchMode) {\n        case ZipMismatchMode.FAIL:\n          throw new Error('Zipped streams should have the same length. ' + `Mismatched at element ${this.count}.`);\n\n        case ZipMismatchMode.SHORTEST:\n          return {\n            value: null,\n            done: true\n          };\n\n        case ZipMismatchMode.LONGEST:\n        default: // Continue.  The exhausted streams already produced value: null.\n\n      }\n    }\n\n    this.count++;\n    return {\n      value: mapped,\n      done: false\n    };\n  }\n\n  async next() {\n    this.currentPromise = this.nextState(this.currentPromise);\n    return this.currentPromise;\n  }\n\n} // Iterators that maintain a ring buffer of pending promises\n// ============================================================================\n\n/**\r\n * A stream that prefetches a given number of items from an upstream source,\r\n * returning them in FIFO order.\r\n *\r\n * Note this prefetches Promises, but makes no guarantees about when those\r\n * Promises resolve.\r\n */\n\n\nexport class PrefetchIterator extends LazyIterator {\n  constructor(upstream, bufferSize) {\n    super();\n    this.upstream = upstream;\n    this.bufferSize = bufferSize;\n    this.buffer = new RingBuffer(bufferSize);\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Prefetch`;\n  }\n  /**\r\n   * Refill the prefetch buffer.  Returns only after the buffer is full, or\r\n   * the upstream source is exhausted.\r\n   */\n\n\n  refill() {\n    while (!this.buffer.isFull()) {\n      const v = this.upstream.next();\n      this.buffer.push(v);\n    }\n  }\n\n  next() {\n    this.refill(); // This shift will never throw an error because the buffer is always\n    // full after a refill. If the stream is exhausted, the buffer will be\n    // full of Promises that will resolve to the end-of-stream signal.\n\n    return this.buffer.shift();\n  }\n\n}\n/**\r\n * A stream that performs a sliding-window random shuffle on an upstream\r\n * source. This is like a `PrefetchIterator` except that the items are\r\n * returned in randomized order.  Mixing naturally improves as the buffer\r\n * size increases.\r\n */\n\nexport class ShuffleIterator extends PrefetchIterator {\n  constructor(upstream, windowSize, seed) {\n    super(upstream, windowSize);\n    this.upstream = upstream;\n    this.windowSize = windowSize; // Local state that should not be clobbered by out-of-order execution.\n\n    this.upstreamExhausted = false;\n    this.random = seedrandom.alea(seed || tf.util.now().toString());\n    this.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n  }\n\n  async next() {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  randomInt(max) {\n    return Math.floor(this.random() * max);\n  }\n\n  chooseIndex() {\n    return this.randomInt(this.buffer.length());\n  }\n\n  async serialNext() {\n    // TODO(soergel): consider performance\n    if (!this.upstreamExhausted) {\n      this.refill();\n    }\n\n    while (!this.buffer.isEmpty()) {\n      const chosenIndex = this.chooseIndex();\n      const result = await this.buffer.shuffleExcise(chosenIndex);\n\n      if (result.done) {\n        this.upstreamExhausted = true;\n      } else {\n        this.refill();\n        return result;\n      }\n    }\n\n    return {\n      value: null,\n      done: true\n    };\n  }\n\n}","map":{"version":3,"sources":["../../../../../../tfjs-data/src/iterators/lazy_iterator.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;;AAgBG;AAEH,OAAO,KAAK,EAAZ,MAAoB,uBAApB;AACA,OAAO,KAAK,UAAZ,MAA4B,YAA5B;AAGA,SAAQ,SAAR,QAAwB,oBAAxB;AACA,SAAQ,kBAAR,EAA+D,OAA/D,EAAwE,SAAxE,QAAwF,kBAAxF;AACA,SAAQ,iBAAR,QAAgC,6BAAhC;AACA,SAAQ,UAAR,QAAyB,qBAAzB,C,CAOA;AACA;AACA;;AAEA;;AAEG;;AACH,OAAM,SAAU,iBAAV,CAA+B,KAA/B,EAAyC;AAC7C,SAAO,IAAI,aAAJ,CAAkB,KAAlB,CAAP;AACD;AAED;;AAEG;;AACH,OAAM,SAAU,wBAAV,CAAmC,KAAnC,EAAgD;AACpD,MAAI,CAAC,GAAG,KAAR;AACA,SAAO,oBAAoB,CAAC,OAAO;AAAC,IAAA,KAAK,EAAE,CAAC,EAAT;AAAa,IAAA,IAAI,EAAE;AAAnB,GAAP,CAAD,CAA3B;AACD;AAED;;;;;;;;;;;;AAYG;;AACH,OAAM,SAAU,oBAAV,CACF,IADE,EAE+C;AACnD,SAAO,IAAI,oBAAJ,CAAyB,IAAzB,CAAP;AACD;AAED;;;;;;;;;;;AAWG;;AACH,OAAM,SAAU,wBAAV,CACF,aADE,EAEF,gBAFE,EAEsC;AAC1C,SAAO,IAAI,eAAJ,CAAoB,aAApB,EAAmC,gBAAnC,CAAP;AACD;AAED;;;;;;;;;;;;;;;AAeG;;AACH,OAAM,SAAU,gCAAV,CACF,YADE,EACmD,KADnD,EAEF,gBAFE,EAEsC;AAC1C,SAAO,wBAAwB,CAC3B,oBAAoB,CAAC,YAAD,CAApB,CAAmC,IAAnC,CAAwC,KAAxC,CAD2B,EACqB,gBADrB,CAA/B;AAED;AAED;;;;;;;;;;;;;;;;;;;;;;;AAuBG;;AACH,OAAM,SAAU,kBAAV,CACF,SADE,EAEF,YAAA,GAAgC,eAAe,CAAC,IAF9C,EAEkD;AACtD,SAAO,IAAI,WAAJ,CAAmB,SAAnB,EAA8B,YAA9B,CAAP;AACD;AAED;;;;;;AAMG;;AACH,OAAM,MAAgB,YAAhB,CAA4B;AAgBhC;;;;;;;AAOG;AACU,QAAP,OAAO,GAAA;AACX,UAAM,MAAM,GAAQ,EAApB;AACA,QAAI,CAAC,GAAG,MAAM,KAAK,IAAL,EAAd;;AACA,WAAO,CAAC,CAAC,CAAC,IAAV,EAAgB;AACd,MAAA,MAAM,CAAC,IAAP,CAAY,CAAC,CAAC,KAAd;AACA,MAAA,CAAC,GAAG,MAAM,KAAK,IAAL,EAAV;AACD;;AACD,WAAO,MAAP;AACD;AAED;;;;;;;;;;AAUG;;;AACiB,QAAd,cAAc,GAAA;AAClB,UAAM,MAAM,GAAG,KAAK,QAAL,CAAc,GAAd,CAAf;AACA,UAAM,MAAM,GAAQ,EAApB;AACA,QAAI,CAAC,GAAG,MAAM,MAAM,CAAC,IAAP,EAAd;;AACA,WAAO,CAAC,CAAC,CAAC,IAAV,EAAgB;AACd,MAAA,MAAM,CAAC,IAAP,CAAY,CAAC,CAAC,KAAd;AACA,MAAA,CAAC,GAAG,MAAM,MAAM,CAAC,IAAP,EAAV;AACD;;AACD,WAAO,MAAP;AACD;AAED;;;;;;AAMG;;;AACe,QAAZ,YAAY,GAAA;AAChB,QAAI,CAAC,GAAG,MAAM,KAAK,IAAL,EAAd;;AACA,WAAO,CAAC,CAAC,CAAC,IAAV,EAAgB;AACd,MAAA,CAAC,GAAG,MAAM,KAAK,IAAL,EAAV;AACD;AACF;AAED;;;;;;AAMG;;;AACe,QAAZ,YAAY,CAAC,SAAD,EAA6B;AAC7C,QAAI,CAAC,GAAG,MAAM,KAAK,IAAL,EAAd;AACA,QAAI,cAAc,GAAG,SAAS,CAAC,CAAC,CAAC,KAAH,CAA9B;;AACA,WAAQ,CAAC,CAAC,CAAC,IAAJ,IAAa,cAApB,EAAoC;AAClC,MAAA,CAAC,GAAG,MAAM,KAAK,IAAL,EAAV;AACA,MAAA,cAAc,GAAG,SAAS,CAAC,CAAC,CAAC,KAAH,CAA1B;AACD;AACF;AAED;;;;;;;;;;;AAWG;;;AACH,EAAA,YAAY,CAAC,OAAD,EAAmC;AAC7C,WAAO,IAAI,yBAAJ,CAA8B,IAA9B,EAAoC,OAApC,CAAP;AACD,GApG+B,CAsGhC;;AAEA;;;;;;;AAOG;;;AACH,EAAA,MAAM,CAAC,SAAD,EAAiC;AACrC,WAAO,IAAI,cAAJ,CAAmB,IAAnB,EAAyB,SAAzB,CAAP;AACD;AAED;;;;;;;AAOG;;;AACH,EAAA,GAAG,CAAI,SAAJ,EAA8B;AAC/B,WAAO,IAAI,WAAJ,CAAgB,IAAhB,EAAsB,SAAtB,CAAP;AACD;AAED;;;;;;;AAOG;;;AACH,EAAA,QAAQ,CAAI,SAAJ,EAAuC;AAC7C,WAAO,IAAI,gBAAJ,CAAqB,IAArB,EAA2B,SAA3B,CAAP;AACD;AAED;;;;;;;AAOG;;;AACH,EAAA,cAAc,CAAI,SAAJ,EAAuC;AACnD,WAAO,IAAI,gBAAJ,CAAqB,IAArB,EAA2B,SAA3B,EAAsC,MAAtC,EAAP;AACD;AAED;;;;;;;AAOG;;;AACH,EAAA,OAAO,CAAI,SAAJ,EAAgC;AACrC,WAAO,IAAI,eAAJ,CAAoB,IAApB,EAA0B,SAA1B,CAAP;AACD;AAED;;;;AAIG;;;AACe,QAAZ,YAAY,CAAC,CAAD,EAAsB;AACtC,WAAO,KAAK,GAAL,CAAS,CAAT,EAAY,YAAZ,EAAP;AACD;AAED;;;;;;AAMG;;;AACgB,QAAb,aAAa,CAAC,CAAD,EAAkC;AACnD,WAAO,KAAK,cAAL,CAAoB,CAApB,EAAuB,YAAvB,CAAoC,CAAC,IAAK,CAAC,KAAK,IAAhD,CAAP;AACD;AAED;;;;;;;;;;;;;;;;;AAiBG;;;AACH,EAAA,aAAa,CAAC,SAAD,EAAoB,cAAc,GAAG,IAArC,EAAyC;AACpD,WAAO,IAAI,qBAAJ,CAA0B,IAA1B,EAAgC,SAAhC,EAA2C,cAA3C,CAAP;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA+BG;;;AACH,EAAA,gBAAgB,CACZ,SADY,EACO,cAAc,GAAG,IADxB,EAEZ;AACA,EAAA,KAAA,GAAsC,SAH1B,EAGmC;AAEjD;AACA,UAAM,UAAU,GAAG,KAAK,aAAL,CAAmB,SAAnB,EAA8B,cAA9B,CAAnB,CAHiD,CAIjD;AACA;;AACA,WAAO,UAAU,CAAC,GAAX,CAAe,CAAC,IAAI,OAAO,CAAC,CAAD,EAAI,KAAJ,CAA3B,CAAP;AACD;AAED;;;;;;;;;AASG;;;AACH,EAAA,WAAW,CACP,QADO,EAEP,gBAFO,EAEiC;AAC1C,WAAO,IAAI,eAAJ,CACH,iBAAiB,CAAC,CAAC,IAAD,EAAO,QAAP,CAAD,CADd,EACkC,gBADlC,CAAP;AAED;AAED;;;;;;AAMG;;;AACH,EAAA,IAAI,CAAC,KAAD,EAAc;AAChB,QAAI,KAAK,GAAG,CAAR,IAAa,KAAK,IAAI,IAA1B,EAAgC;AAC9B,aAAO,IAAP;AACD;;AACD,WAAO,IAAI,YAAJ,CAAiB,IAAjB,EAAuB,KAAvB,CAAP;AACD;AAED;;;;;AAKG;;;AACH,EAAA,IAAI,CAAC,KAAD,EAAc;AAChB,QAAI,KAAK,GAAG,CAAR,IAAa,KAAK,IAAI,IAA1B,EAAgC;AAC9B,aAAO,IAAP;AACD;;AACD,WAAO,IAAI,YAAJ,CAAiB,IAAjB,EAAuB,KAAvB,CAAP;AACD;AAED;;;;;;;;AAQG;;;AACH,EAAA,QAAQ,CAAC,UAAD,EAAmB;AACzB,WAAO,IAAI,gBAAJ,CAAqB,IAArB,EAA2B,UAA3B,CAAP;AACD,GAjT+B,CAmThC;;AAEA;;;;;;;AAOG;;;AACH,EAAA,OAAO,CAAC,UAAD,EAAqB,IAArB,EAAkC;AACvC,WAAO,IAAI,eAAJ,CAAoB,IAApB,EAA0B,UAA1B,EAAsC,IAAtC,CAAP;AACD;AAED;;;AAGG;;;AACH,EAAA,MAAM,GAAA;AACJ,WAAO,IAAI,cAAJ,CAAmB,IAAnB,CAAP;AACD;;AAvU+B,C,CA0UlC;AACA;AACA;AACA;AACA;AAEA;AACA;;AAEA,MAAM,aAAN,SAA+B,YAA/B,CAA8C;AAE5C,EAAA,WAAA,CAAsB,KAAtB,EAAgC;AAC9B;AADoB,SAAA,KAAA,GAAA,KAAA;AADd,SAAA,IAAA,GAAO,CAAP;AAGP;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,YAAY,KAAK,KAAL,CAAW,MAAM,QAApC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,QAAI,KAAK,IAAL,IAAa,KAAK,KAAL,CAAW,MAA5B,EAAoC;AAClC,aAAO;AAAC,QAAA,KAAK,EAAE,IAAR;AAAc,QAAA,IAAI,EAAE;AAApB,OAAP;AACD;;AACD,UAAM,IAAI,GAAG,KAAK,KAAL,CAAW,KAAK,IAAhB,CAAb;AACA,SAAK,IAAL;AACA,WAAO;AAAC,MAAA,KAAK,EAAE,SAAS,CAAC,IAAD,CAAjB;AAAyB,MAAA,IAAI,EAAE;AAA/B,KAAP;AACD;;AAjB2C;;AAoB9C,MAAM,oBAAN,SAAsC,YAAtC,CAAqD;AACnD,EAAA,WAAA,CACc,MADd,EACyE;AACvE;AADY,SAAA,MAAA,GAAA,MAAA;AAEb;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,eAAP;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,QAAI;AACF,aAAO,KAAK,MAAL,EAAP;AACD,KAFD,CAEE,OAAO,CAAP,EAAU;AACV;AACA,MAAA,CAAC,CAAC,OAAF,GACI,mDAAmD,CAAC,CAAC,OAAO,EADhE;AAEA,YAAM,CAAN;AACD;AACF;;AAnBkD;;AAsBrD,MAAM,cAAN,SAAgC,YAAhC,CAA+C;AAK7C,EAAA,WAAA,CAAsB,QAAtB,EAA+C;AAC7C;AADoB,SAAA,QAAA,GAAA,QAAA;AAEpB,SAAK,QAAL,GAAgB,OAAO,CAAC,OAAR,CAAgB;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,YAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR;AACA;AACA;AACA;AACA,SAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,IAAd,CAAmB,MAAM,KAAK,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAEuB,QAAV,UAAU,GAAA;AACtB,WAAO,KAAK,QAAL,CAAc,IAAd,EAAP;AACD;;AAzB4C;;AA4B/C,MAAM,YAAN,SAA8B,YAA9B,CAA6C;AAQ3C,EAAA,WAAA,CAAsB,QAAtB,EAA2D,QAA3D,EAA2E;AACzE;AADoB,SAAA,QAAA,GAAA,QAAA;AAAqC,SAAA,QAAA,GAAA,QAAA,CAAgB,CAH3E;;AACA,SAAA,KAAA,GAAQ,CAAR;AAIE,SAAK,QAAL,GAAgB,OAAO,CAAC,OAAR,CAAgB;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,UAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR;AACA;AACA;AACA;AACA,SAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,IAAd,CAAmB,MAAM,KAAK,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAEuB,QAAV,UAAU,GAAA;AACtB;AACA;AACA;AACA;AACA,WAAO,KAAK,KAAL,KAAe,KAAK,QAA3B,EAAqC;AACnC,YAAM,OAAO,GAAG,MAAM,KAAK,QAAL,CAAc,IAAd,EAAtB,CADmC,CAEnC;;AACA,UAAI,OAAO,CAAC,IAAZ,EAAkB;AAChB,eAAO,OAAP;AACD;;AACD,MAAA,EAAE,CAAC,OAAH,CAAW,OAAO,CAAC,KAAnB;AACD;;AACD,WAAO,KAAK,QAAL,CAAc,IAAd,EAAP;AACD;;AAxC0C;;AA2C7C,MAAM,YAAN,SAA8B,YAA9B,CAA6C;AAE3C,EAAA,WAAA,CAAsB,QAAtB,EAA2D,QAA3D,EAA2E;AACzE;AADoB,SAAA,QAAA,GAAA,QAAA;AAAqC,SAAA,QAAA,GAAA,QAAA;AAD3D,SAAA,KAAA,GAAQ,CAAR;AAGC;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,UAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,QAAI,KAAK,KAAL,MAAgB,KAAK,QAAzB,EAAmC;AACjC,aAAO;AAAC,QAAA,KAAK,EAAE,IAAR;AAAc,QAAA,IAAI,EAAE;AAApB,OAAP;AACD;;AACD,WAAO,KAAK,QAAL,CAAc,IAAd,EAAP;AACD;;AAf0C,C,CAkB7C;AACA;AACA;;;AACA,MAAM,qBAAN,SAAuC,YAAvC,CAAwD;AAKtD,EAAA,WAAA,CACc,QADd,EACmD,SADnD,EAEc,oBAAA,GAAuB,IAFrC,EAEyC;AACvC;AAFY,SAAA,QAAA,GAAA,QAAA;AAAqC,SAAA,SAAA,GAAA,SAAA;AACrC,SAAA,oBAAA,GAAA,oBAAA;AAEZ,SAAK,QAAL,GAAgB,OAAO,CAAC,OAAR,CAAgB;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,mBAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR;AACA;AACA;AACA;AACA,SAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,IAAd,CAAmB,MAAM,KAAK,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAEuB,QAAV,UAAU,GAAA;AACtB,UAAM,KAAK,GAAQ,EAAnB;;AACA,WAAO,KAAK,CAAC,MAAN,GAAe,KAAK,SAA3B,EAAsC;AACpC,YAAM,IAAI,GAAG,MAAM,KAAK,QAAL,CAAc,IAAd,EAAnB;;AACA,UAAI,IAAI,CAAC,IAAT,EAAe;AACb,YAAI,KAAK,oBAAL,IAA6B,KAAK,CAAC,MAAN,GAAe,CAAhD,EAAmD;AACjD,iBAAO;AAAC,YAAA,KAAK,EAAE,KAAR;AAAe,YAAA,IAAI,EAAE;AAArB,WAAP;AACD;;AACD,eAAO;AAAC,UAAA,KAAK,EAAE,IAAR;AAAc,UAAA,IAAI,EAAE;AAApB,SAAP;AACD;;AACD,MAAA,KAAK,CAAC,IAAN,CAAW,IAAI,CAAC,KAAhB;AACD;;AACD,WAAO;AAAC,MAAA,KAAK,EAAE,KAAR;AAAe,MAAA,IAAI,EAAE;AAArB,KAAP;AACD;;AAtCqD;;AAyCxD,MAAM,cAAN,SAAgC,YAAhC,CAA+C;AAK7C,EAAA,WAAA,CACc,QADd,EAEc,SAFd,EAE8C;AAC5C;AAFY,SAAA,QAAA,GAAA,QAAA;AACA,SAAA,SAAA,GAAA,SAAA;AAEZ,SAAK,QAAL,GAAgB,OAAO,CAAC,OAAR,CAAgB;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,YAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR;AACA;AACA;AACA;AACA,SAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,IAAd,CAAmB,MAAM,KAAK,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAEuB,QAAV,UAAU,GAAA;AACtB,WAAO,IAAP,EAAa;AACX,YAAM,IAAI,GAAG,MAAM,KAAK,QAAL,CAAc,IAAd,EAAnB;;AACA,UAAI,IAAI,CAAC,IAAL,IAAa,KAAK,SAAL,CAAe,IAAI,CAAC,KAApB,CAAjB,EAA6C;AAC3C,eAAO,IAAP;AACD;;AACD,MAAA,EAAE,CAAC,OAAH,CAAW,IAAI,CAAC,KAAhB;AACD;AACF;;AAjC4C;;AAoC/C,MAAM,WAAN,SAAgC,YAAhC,CAA+C;AAC7C,EAAA,WAAA,CACc,QADd,EAEc,SAFd,EAEwC;AACtC;AAFY,SAAA,QAAA,GAAA,QAAA;AACA,SAAA,SAAA,GAAA,SAAA;AAEb;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,SAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,UAAM,IAAI,GAAG,MAAM,KAAK,QAAL,CAAc,IAAd,EAAnB;;AACA,QAAI,IAAI,CAAC,IAAT,EAAe;AACb,aAAO;AAAC,QAAA,KAAK,EAAE,IAAR;AAAc,QAAA,IAAI,EAAE;AAApB,OAAP;AACD;;AACD,UAAM,YAAY,GAAG,EAAE,CAAC,WAAH,CAAe,qBAAf,CAAqC,IAAI,CAAC,KAA1C,CAArB,CALQ,CAMR;AACA;AACA;AACA;AACA;AACA;;AACA,UAAM,MAAM,GAAG,KAAK,SAAL,CAAe,IAAI,CAAC,KAApB,CAAf;AACA,UAAM,aAAa,GAAG,EAAE,CAAC,WAAH,CAAe,qBAAf,CAAqC,MAArC,CAAtB,CAbQ,CAeR;AACA;;AACA,SAAK,MAAM,CAAX,IAAgB,YAAhB,EAA8B;AAC5B,UAAI,CAAC,EAAE,CAAC,WAAH,CAAe,cAAf,CAA8B,CAA9B,EAAiC,aAAjC,CAAL,EAAsD;AACpD,QAAA,CAAC,CAAC,OAAF;AACD;AACF;;AACD,WAAO;AAAC,MAAA,KAAK,EAAE,MAAR;AAAgB,MAAA,IAAI,EAAE;AAAtB,KAAP;AACD;;AAlC4C;;AAqC/C,MAAM,yBAAN,SAA2C,YAA3C,CAA0D;AAExD,EAAA,WAAA,CACc,QADd,EAEc,OAFd,EAEgD;AAC9C;AAFY,SAAA,QAAA,GAAA,QAAA;AACA,SAAA,OAAA,GAAA,OAAA;AAHd,SAAA,KAAA,GAAQ,CAAR;AAKE,SAAK,QAAL,GAAgB,OAAO,CAAC,OAAR,CAAgB;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,kBAAjC;AACD;;AAMS,QAAJ,IAAI,GAAA;AACR;AACA;AACA;AACA;AACA,SAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,IAAd,CAAmB,MAAM,KAAK,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAEe,QAAV,UAAU,GAAA;AACd,WAAO,IAAP,EAAa;AACX,UAAI;AACF,eAAO,MAAM,KAAK,QAAL,CAAc,IAAd,EAAb;AACD,OAFD,CAEE,OAAO,CAAP,EAAU;AACV,YAAI,CAAC,KAAK,OAAL,CAAa,CAAb,CAAL,EAAsB;AACpB,iBAAO;AAAC,YAAA,KAAK,EAAE,IAAR;AAAc,YAAA,IAAI,EAAE;AAApB,WAAP;AACD,SAHS,CAIV;AAEA;AACA;AACA;;AACD;AACF;AACF;;AAzCuD;;AA4C1D,MAAM,gBAAN,SAAqC,YAArC,CAAoD;AAClD,EAAA,WAAA,CACc,QADd,EAEc,SAFd,EAEiD;AAC/C;AAFY,SAAA,QAAA,GAAA,QAAA;AACA,SAAA,SAAA,GAAA,SAAA;AAEb;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,cAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,UAAM,IAAI,GAAG,MAAM,KAAK,QAAL,CAAc,IAAd,EAAnB;;AACA,QAAI,IAAI,CAAC,IAAT,EAAe;AACb,aAAO;AAAC,QAAA,KAAK,EAAE,IAAR;AAAc,QAAA,IAAI,EAAE;AAApB,OAAP;AACD;;AACD,UAAM,YAAY,GAAG,EAAE,CAAC,WAAH,CAAe,qBAAf,CAAqC,IAAI,CAAC,KAA1C,CAArB,CALQ,CAMR;AACA;AACA;AACA;AACA;AACA;;AACA,UAAM,MAAM,GAAG,MAAM,KAAK,SAAL,CAAe,IAAI,CAAC,KAApB,CAArB;AACA,UAAM,aAAa,GAAG,EAAE,CAAC,WAAH,CAAe,qBAAf,CAAqC,MAArC,CAAtB,CAbQ,CAeR;AACA;;AACA,SAAK,MAAM,CAAX,IAAgB,YAAhB,EAA8B;AAC5B,UAAI,CAAC,EAAE,CAAC,WAAH,CAAe,cAAf,CAA8B,CAA9B,EAAiC,aAAjC,CAAL,EAAsD;AACpD,QAAA,CAAC,CAAC,OAAF;AACD;AACF;;AACD,WAAO;AAAC,MAAA,KAAK,EAAE,MAAR;AAAgB,MAAA,IAAI,EAAE;AAAtB,KAAP;AACD;;AAlCiD,C,CAqCpD;AACA;;AAEA;;;;;;;AAOG;;;AACH,OAAM,MAAgB,iBAAhB,SAA6C,YAA7C,CAA4D;AAQhE,EAAA,WAAA,GAAA;AACE;AACA,SAAK,WAAL,GAAmB,IAAI,iBAAJ,EAAnB;AACA,SAAK,QAAL,GAAgB,OAAO,CAAC,OAAR,CAAgB;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAES,QAAJ,IAAI,GAAA;AACR;AACA;AACA;AACA;AACA,SAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,IAAd,CAAmB,MAAM,KAAK,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAgBe,QAAV,UAAU,GAAA;AACd;AACA;AACA;AACA,WAAO,KAAK,WAAL,CAAiB,MAAjB,OAA8B,CAArC,EAAwC;AACtC;AACA,UAAI,EAAC,MAAM,KAAK,IAAL,EAAP,CAAJ,EAAwB;AACtB,eAAO;AAAC,UAAA,KAAK,EAAE,IAAR;AAAc,UAAA,IAAI,EAAE;AAApB,SAAP;AACD;AACF;;AACD,WAAO;AAAC,MAAA,KAAK,EAAE,KAAK,WAAL,CAAiB,KAAjB,EAAR;AAAkC,MAAA,IAAI,EAAE;AAAxC,KAAP;AACD;;AAhD+D;;AAkDlE,MAAM,eAAN,SAAoC,iBAApC,CAAwD;AACtD,EAAA,WAAA,CACc,QADd,EAEc,SAFd,EAE0C;AACxC;AAFY,SAAA,QAAA,GAAA,QAAA;AACA,SAAA,SAAA,GAAA,SAAA;AAEb;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,aAAjC;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,UAAM,IAAI,GAAG,MAAM,KAAK,QAAL,CAAc,IAAd,EAAnB;;AACA,QAAI,IAAI,CAAC,IAAT,EAAe;AACb,aAAO,KAAP;AACD;;AACD,UAAM,YAAY,GAAG,EAAE,CAAC,WAAH,CAAe,qBAAf,CAAqC,IAAI,CAAC,KAA1C,CAArB,CALQ,CAMR;AACA;AACA;AACA;AACA;;AACA,UAAM,WAAW,GAAG,KAAK,SAAL,CAAe,IAAI,CAAC,KAApB,CAApB;AACA,UAAM,aAAa,GACf,EAAE,CAAC,WAAH,CAAe,qBAAf,CAAqC,WAArC,CADJ;AAEA,SAAK,WAAL,CAAiB,OAAjB,CAAyB,WAAzB,EAdQ,CAgBR;AACA;;AACA,SAAK,MAAM,CAAX,IAAgB,YAAhB,EAA8B;AAC5B,UAAI,CAAC,EAAE,CAAC,WAAH,CAAe,cAAf,CAA8B,CAA9B,EAAiC,aAAjC,CAAL,EAAsD;AACpD,QAAA,CAAC,CAAC,OAAF;AACD;AACF;;AAED,WAAO,IAAP;AACD;;AApCqD;AAuCxD;;;;;;;;AAQG;;;AACH,OAAM,MAAO,eAAP,SAAkC,YAAlC,CAAiD;AASrD,EAAA,WAAA,CACI,SADJ,EAEqB,gBAFrB,EAE6D;AAC3D;AADmB,SAAA,gBAAA,GAAA,gBAAA,CAAwC,CAV7D;AACA;;AACQ,SAAA,QAAA,GAAuC,IAAvC,CAQqD,CAN7D;;AACQ,SAAA,QAAA,GAA4B,IAA5B;AAON,SAAK,aAAL,GAAqB,SAArB;AACD;;AAED,EAAA,OAAO,GAAA;AACL,UAAM,iBAAiB,GAAG,6CAA1B;AACA,WAAO,GAAG,iBAAiB,aAA3B;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,SAAK,QAAL,GAAgB,KAAK,aAAL,CAAmB,KAAK,QAAxB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAE0B,QAAb,aAAa,CAAC,QAAD,EAAqC;AAE9D;AACA;AACA;AACA;AACA;AACA,UAAM,QAAN;;AACA,QAAI,KAAK,QAAL,IAAiB,IAArB,EAA2B;AACzB,YAAM,cAAc,GAAG,MAAM,KAAK,aAAL,CAAmB,IAAnB,EAA7B;;AACA,UAAI,cAAc,CAAC,IAAnB,EAAyB;AACvB;AACA,eAAO;AAAC,UAAA,KAAK,EAAE,IAAR;AAAc,UAAA,IAAI,EAAE;AAApB,SAAP;AACD;;AACD,WAAK,QAAL,GAAgB,cAAc,CAAC,KAA/B;;AACA,UAAI,KAAK,gBAAL,IAAyB,IAA7B,EAAmC;AACjC,aAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,YAAd,CAA2B,KAAK,gBAAhC,CAAhB;AACD;AACF;;AACD,UAAM,UAAU,GAAG,MAAM,KAAK,QAAL,CAAc,IAAd,EAAzB;;AACA,QAAI,UAAU,CAAC,IAAf,EAAqB;AACnB,WAAK,QAAL,GAAgB,IAAhB;AACA,aAAO,KAAK,aAAL,CAAmB,QAAnB,CAAP;AACD;;AACD,WAAO,UAAP;AACD;;AAnDoD;AAsDvD,OAAA,IAAY,eAAZ;;AAAA,CAAA,UAAY,eAAZ,EAA2B;AACzB,EAAA,eAAA,CAAA,eAAA,CAAA,MAAA,CAAA,GAAA,CAAA,CAAA,GAAA,MAAA;AACA,EAAA,eAAA,CAAA,eAAA,CAAA,UAAA,CAAA,GAAA,CAAA,CAAA,GAAA,UAAA;AACA,EAAA,eAAA,CAAA,eAAA,CAAA,SAAA,CAAA,GAAA,CAAA,CAAA,GAAA,SAAA,CAHyB,CAGd;AACZ,CAJD,EAAY,eAAe,KAAf,eAAe,GAAA,EAAA,CAA3B;AAMA;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA4BG;;;AACH,MAAM,WAAN,SAAwD,YAAxD,CAAuE;AAIrE,EAAA,WAAA,CACuB,SADvB,EAEuB,YAAA,GAAgC,eAAe,CAAC,IAFvE,EAE2E;AACzE;AAFqB,SAAA,SAAA,GAAA,SAAA;AACA,SAAA,YAAA,GAAA,YAAA;AALf,SAAA,KAAA,GAAQ,CAAR;AACA,SAAA,cAAA,GAA6C,IAA7C;AAMP;;AAED,EAAA,OAAO,GAAA;AACL,UAAM,iBAAiB,GAAG,yCAA1B;AACA,WAAO,IAAI,iBAAiB,UAA5B;AACD;;AAEsB,QAAT,SAAS,CAAC,UAAD,EAAuC;AAE5D;AACA;AACA,UAAM,UAAN,CAJ4D,CAM5D;AACA;;AACA,QAAI,YAAY,GAAG,CAAnB;AACA,QAAI,aAAa,GAAG,CAApB;;AAEA,aAAS,OAAT,CAAiB,SAAjB,EAA6C;AAC3C,UAAI,SAAS,YAAY,YAAzB,EAAuC;AACrC,cAAM,MAAM,GAAG,SAAS,CAAC,IAAV,EAAf;AACA,eAAO;AACL,UAAA,KAAK,EAAE,MAAM,CAAC,IAAP,CAAY,CAAC,IAAG;AACrB,YAAA,YAAY;;AACZ,gBAAI,CAAC,CAAC,IAAN,EAAY;AACV,cAAA,aAAa;AACd;;AACD,mBAAO,CAAC,CAAC,KAAT;AACD,WANM,CADF;AAQL,UAAA,OAAO,EAAE;AARJ,SAAP;AAUD,OAZD,MAYO;AACL,eAAO;AAAC,UAAA,KAAK,EAAE,IAAR;AAAc,UAAA,OAAO,EAAE;AAAvB,SAAP;AACD;AACF;;AAED,UAAM,MAAM,GAAM,MAAM,kBAAkB,CAAC,KAAK,SAAN,EAAiB,OAAjB,CAA1C;;AAEA,QAAI,YAAY,KAAK,aAArB,EAAoC;AAClC;AACA,aAAO;AAAC,QAAA,KAAK,EAAE,IAAR;AAAc,QAAA,IAAI,EAAE;AAApB,OAAP;AACD;;AACD,QAAI,aAAa,GAAG,CAApB,EAAuB;AACrB,cAAQ,KAAK,YAAb;AACE,aAAK,eAAe,CAAC,IAArB;AACE,gBAAM,IAAI,KAAJ,CACF,iDACA,yBAAyB,KAAK,KAAK,GAFjC,CAAN;;AAGF,aAAK,eAAe,CAAC,QAArB;AACE,iBAAO;AAAC,YAAA,KAAK,EAAE,IAAR;AAAc,YAAA,IAAI,EAAE;AAApB,WAAP;;AACF,aAAK,eAAe,CAAC,OAArB;AACA,gBARF,CASI;;AATJ;AAWD;;AAED,SAAK,KAAL;AACA,WAAO;AAAC,MAAA,KAAK,EAAE,MAAR;AAAgB,MAAA,IAAI,EAAE;AAAtB,KAAP;AACD;;AAES,QAAJ,IAAI,GAAA;AACR,SAAK,cAAL,GAAsB,KAAK,SAAL,CAAe,KAAK,cAApB,CAAtB;AACA,WAAO,KAAK,cAAZ;AACD;;AAvEoE,C,CA0EvE;AACA;;AAEA;;;;;;AAMG;;;AACH,OAAM,MAAO,gBAAP,SAAmC,YAAnC,CAAkD;AAGtD,EAAA,WAAA,CACc,QADd,EACmD,UADnD,EACqE;AACnE;AADY,SAAA,QAAA,GAAA,QAAA;AAAqC,SAAA,UAAA,GAAA,UAAA;AAEjD,SAAK,MAAL,GAAc,IAAI,UAAJ,CAA2C,UAA3C,CAAd;AACD;;AAED,EAAA,OAAO,GAAA;AACL,WAAO,GAAG,KAAK,QAAL,CAAc,OAAd,EAAuB,cAAjC;AACD;AAED;;;AAGG;;;AACO,EAAA,MAAM,GAAA;AACd,WAAO,CAAC,KAAK,MAAL,CAAY,MAAZ,EAAR,EAA8B;AAC5B,YAAM,CAAC,GAAG,KAAK,QAAL,CAAc,IAAd,EAAV;AACA,WAAK,MAAL,CAAY,IAAZ,CAAiB,CAAjB;AACD;AACF;;AAED,EAAA,IAAI,GAAA;AACF,SAAK,MAAL,GADE,CAEF;AACA;AACA;;AACA,WAAO,KAAK,MAAL,CAAY,KAAZ,EAAP;AACD;;AA9BqD;AAiCxD;;;;;AAKG;;AACH,OAAM,MAAO,eAAP,SAAkC,gBAAlC,CAAqD;AAUzD,EAAA,WAAA,CACc,QADd,EACmD,UADnD,EAEI,IAFJ,EAEiB;AACf,UAAM,QAAN,EAAgB,UAAhB;AAFY,SAAA,QAAA,GAAA,QAAA;AAAqC,SAAA,UAAA,GAAA,UAAA,CAClC,CALjB;;AACQ,SAAA,iBAAA,GAAoB,KAApB;AAMN,SAAK,MAAL,GAAc,UAAU,CAAC,IAAX,CAAgB,IAAI,IAAI,EAAE,CAAC,IAAH,CAAQ,GAAR,GAAc,QAAd,EAAxB,CAAd;AACA,SAAK,QAAL,GAAgB,OAAO,CAAC,OAAR,CAAgB;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAhB,CAAhB;AACD;;AAES,QAAJ,IAAI,GAAA;AACR;AACA;AACA;AACA;AACA,SAAK,QAAL,GAAgB,KAAK,QAAL,CAAc,IAAd,CAAmB,MAAM,KAAK,UAAL,EAAzB,CAAhB;AACA,WAAO,KAAK,QAAZ;AACD;;AAEO,EAAA,SAAS,CAAC,GAAD,EAAY;AAC3B,WAAO,IAAI,CAAC,KAAL,CAAW,KAAK,MAAL,KAAgB,GAA3B,CAAP;AACD;;AAES,EAAA,WAAW,GAAA;AACnB,WAAO,KAAK,SAAL,CAAe,KAAK,MAAL,CAAY,MAAZ,EAAf,CAAP;AACD;;AAEe,QAAV,UAAU,GAAA;AACd;AACA,QAAI,CAAC,KAAK,iBAAV,EAA6B;AAC3B,WAAK,MAAL;AACD;;AACD,WAAO,CAAC,KAAK,MAAL,CAAY,OAAZ,EAAR,EAA+B;AAC7B,YAAM,WAAW,GAAG,KAAK,WAAL,EAApB;AACA,YAAM,MAAM,GAAG,MAAM,KAAK,MAAL,CAAY,aAAZ,CAA0B,WAA1B,CAArB;;AACA,UAAI,MAAM,CAAC,IAAX,EAAiB;AACf,aAAK,iBAAL,GAAyB,IAAzB;AACD,OAFD,MAEO;AACL,aAAK,MAAL;AACA,eAAO,MAAP;AACD;AACF;;AACD,WAAO;AAAC,MAAA,KAAK,EAAE,IAAR;AAAc,MAAA,IAAI,EAAE;AAApB,KAAP;AACD;;AAnDwD","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport * as seedrandom from 'seedrandom';\n\nimport {Container} from '../types';\nimport {deepClone} from '../util/deep_clone';\nimport {deepMapAndAwaitAll, DeepMapAsyncResult, DeepMapResult, deepZip, zipToList} from '../util/deep_map';\nimport {GrowingRingBuffer} from '../util/growing_ring_buffer';\nimport {RingBuffer} from '../util/ring_buffer';\n\n/**\n * A nested structure of LazyIterators, used as the input to zip().\n */\nexport type IteratorContainer = Container<LazyIterator<tf.TensorContainer>>;\n\n// Here we implement a simple asynchronous iterator.\n// This lets us avoid using either third-party stream libraries or\n// recent TypeScript language support requiring polyfills.\n\n/**\n * Create a `LazyIterator` from an array of items.\n */\nexport function iteratorFromItems<T>(items: T[]): LazyIterator<T> {\n  return new ArrayIterator(items);\n}\n\n/**\n * Create a `LazyIterator` of incrementing integers.\n */\nexport function iteratorFromIncrementing(start: number): LazyIterator<number> {\n  let i = start;\n  return iteratorFromFunction(() => ({value: i++, done: false}));\n}\n\n/**\n * Create a `LazyIterator` from a function.\n *\n * ```js\n * let i = -1;\n * const func = () =>\n *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\n * const iter = tf.data.iteratorFromFunction(func);\n * await iter.forEachAsync(e => console.log(e));\n * ```\n *\n * @param func A function that produces data on each call.\n */\nexport function iteratorFromFunction<T>(\n    func: () =>\n        IteratorResult<T>| Promise<IteratorResult<T>>): LazyIterator<T> {\n  return new FunctionCallIterator(func);\n}\n\n/**\n * Create a `LazyIterator` by concatenating underlying streams, which are\n * themselves provided as a stream.\n *\n * This can also be thought of as a \"stream flatten\" operation.\n *\n * @param baseIterators A stream of streams to be concatenated.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\nexport function iteratorFromConcatenated<T>(\n    baseIterators: LazyIterator<LazyIterator<T>>,\n    baseErrorHandler?: (e: Error) => boolean): LazyIterator<T> {\n  return new ChainedIterator(baseIterators, baseErrorHandler);\n}\n\n/**\n * Create a `LazyIterator` by concatenating streams produced by calling a\n * stream-generating function a given number of times.\n *\n * Since a `LazyIterator` is read-once, it cannot be repeated, but this\n * function can be used to achieve a similar effect:\n *\n *   LazyIterator.ofConcatenatedFunction(() => new MyIterator(), 6);\n *\n * @param iteratorFunc: A function that produces a new stream on each call.\n * @param count: The number of times to call the function.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\nexport function iteratorFromConcatenatedFunction<T>(\n    iteratorFunc: () => IteratorResult<LazyIterator<T>>, count: number,\n    baseErrorHandler?: (e: Error) => boolean): LazyIterator<T> {\n  return iteratorFromConcatenated(\n      iteratorFromFunction(iteratorFunc).take(count), baseErrorHandler);\n}\n\n/**\n * Create a `LazyIterator` by zipping together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\nexport function iteratorFromZipped<O extends tf.TensorContainer>(\n    iterators: IteratorContainer,\n    mismatchMode: ZipMismatchMode = ZipMismatchMode.FAIL): LazyIterator<O> {\n  return new ZipIterator<O>(iterators, mismatchMode);\n}\n\n/**\n * An asynchronous iterator, providing lazy access to a potentially\n * unbounded stream of elements.\n *\n * Iterator can be obtained from a dataset:\n * `const iter = await dataset.iterator();`\n */\nexport abstract class LazyIterator<T> {\n  // This class implements AsyncIterator<T>, but we have not yet set the\n  // TypeScript --downlevelIteration flag to enable that.\n\n  abstract summary(): string;\n\n  /**\n   * Returns a `Promise` for the next element in the stream.\n   *\n   * When an item can be provided successfully, the return value is\n   * `{value:T, done:false}`.\n   *\n   * Calling next() on a closed stream returns `{value:null, done:true}`.\n   */\n  abstract async next(): Promise<IteratorResult<T>>;\n\n  /**\n   * Collect all remaining elements of a bounded stream into an array.\n   * Obviously this will succeed only for small streams that fit in memory.\n   * Useful for testing.\n   *\n   * @returns A Promise for an array of stream elements, which will resolve\n   *   when the stream is exhausted.\n   */\n  async toArray(): Promise<T[]> {\n    const result: T[] = [];\n    let x = await this.next();\n    while (!x.done) {\n      result.push(x.value);\n      x = await this.next();\n    }\n    return result;\n  }\n\n  /**\n   * Collect all elements of this dataset into an array with prefetching 100\n   * elements. This is useful for testing, because the prefetch changes the\n   * order in which the Promises are resolved along the processing pipeline.\n   * This may help expose bugs where results are dependent on the order of\n   * Promise resolution rather than on the logical order of the stream (i.e.,\n   * due to hidden mutable state).\n   *\n   * @returns A Promise for an array of stream elements, which will resolve\n   *   when the stream is exhausted.\n   */\n  async toArrayForTest(): Promise<T[]> {\n    const stream = this.prefetch(100);\n    const result: T[] = [];\n    let x = await stream.next();\n    while (!x.done) {\n      result.push(x.value);\n      x = await stream.next();\n    }\n    return result;\n  }\n\n  /**\n   * Draw items from the stream until it is exhausted.\n   *\n   * This can be useful when the stream has side effects but no output.  In\n   * that case, calling this function guarantees that the stream will be\n   * fully processed.\n   */\n  async resolveFully(): Promise<void> {\n    let x = await this.next();\n    while (!x.done) {\n      x = await this.next();\n    }\n  }\n\n  /**\n   * Draw items from the stream until it is exhausted, or a predicate fails.\n   *\n   * This can be useful when the stream has side effects but no output.  In\n   * that case, calling this function guarantees that the stream will be\n   * fully processed.\n   */\n  async resolveWhile(predicate: (r: T) => boolean): Promise<void> {\n    let x = await this.next();\n    let shouldContinue = predicate(x.value);\n    while ((!x.done) && shouldContinue) {\n      x = await this.next();\n      shouldContinue = predicate(x.value);\n    }\n  }\n\n  /**\n   * Handles errors thrown on this stream using a provided handler function.\n   *\n   * @param handler A function that handles any `Error` thrown during a `next()`\n   *   call and returns true if the stream should continue (dropping the failed\n   *   call) or false if the stream should quietly terminate.  If the handler\n   *   itself throws (or rethrows) an `Error`, that will be propagated.\n   *\n   * @returns A `LazyIterator` of elements passed through from upstream,\n   *   possibly filtering or terminating on upstream `next()` calls that\n   *   throw an `Error`.\n   */\n  handleErrors(handler: (error: Error) => boolean): LazyIterator<T> {\n    return new ErrorHandlingLazyIterator(this, handler);\n  }\n\n  // TODO(soergel): Implement reduce() etc.\n\n  /**\n   * Filters this stream according to `predicate`.\n   *\n   * @param predicate A function mapping a stream element to a boolean or a\n   * `Promise` for one.\n   *\n   * @returns A `LazyIterator` of elements for which the predicate was true.\n   */\n  filter(predicate: (value: T) => boolean): LazyIterator<T> {\n    return new FilterIterator(this, predicate);\n  }\n\n  /**\n   * Maps this stream through a 1-to-1 transform.\n   *\n   * @param transform A function mapping a stream element to a transformed\n   *   element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n  map<O>(transform: (value: T) => O): LazyIterator<O> {\n    return new MapIterator(this, transform);\n  }\n\n  /**\n   * Maps this stream through an async 1-to-1 transform.\n   *\n   * @param transform A function mapping a stream element to a `Promise` for a\n   *   transformed stream element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n  mapAsync<O>(transform: (value: T) => Promise<O>): LazyIterator<O> {\n    return new AsyncMapIterator(this, transform);\n  }\n\n  /**\n   * Maps this stream through a 1-to-1 transform, forcing serial execution.\n   *\n   * @param transform A function mapping a stream element to a transformed\n   *   element.\n   *\n   * @returns A `LazyIterator` of transformed elements.\n   */\n  serialMapAsync<O>(transform: (value: T) => Promise<O>): LazyIterator<O> {\n    return new AsyncMapIterator(this, transform).serial();\n  }\n\n  /**\n   * Maps this stream through a 1-to-many transform.\n   *\n   * @param transform A function mapping a stream element to an array of\n   *   transformed elements.\n   *\n   * @returns A `DataStream` of transformed elements.\n   */\n  flatmap<O>(transform: (value: T) => O[]): LazyIterator<O> {\n    return new FlatmapIterator(this, transform);\n  }\n\n  /**\n   * Apply a function to every element of the stream.\n   *\n   * @param f A function to apply to each stream element.\n   */\n  async forEachAsync(f: (value: T) => void): Promise<void> {\n    return this.map(f).resolveFully();\n  }\n\n  /**\n   * Apply a function to every element of the stream, forcing serial execution.\n   *\n   * @param f A function to apply to each stream element.  Should return 'true'\n   *   to indicate that the stream should continue, or 'false' to cause it to\n   *   terminate.\n   */\n  async serialForEach(f: (value: T) => Promise<boolean>): Promise<void> {\n    return this.serialMapAsync(f).resolveWhile(x => (x === true));\n  }\n\n  /**\n   * Groups elements into batches, represented as arrays of elements.\n   *\n   * We can think of the elements of this iterator as 'rows' (even if they are\n   * nested structures).  By the same token, consecutive values for a given\n   * key within the elements form a 'column'.  This matches the usual sense of\n   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n   *\n   * Thus, \"Row-major\" means that the resulting batch is simply a collection of\n   * rows: `[row1, row2, row3, ...]`.  This is contrast to the column-major\n   * form, which is needed for vectorized computation.\n   *\n   * @param batchSize The number of elements desired per batch.\n   * @param smallLastBatch Whether to emit the final batch when it has fewer\n   *   than batchSize elements. Default true.\n   * @returns A `LazyIterator` of batches of elements, represented as arrays\n   *   of the original element type.\n   */\n  rowMajorBatch(batchSize: number, smallLastBatch = true): LazyIterator<T[]> {\n    return new RowMajorBatchIterator(this, batchSize, smallLastBatch);\n  }\n\n  /**\n   * Groups elements into batches, represented in column-major form.\n   *\n   * We can think of the elements of this iterator as 'rows' (even if they are\n   * nested structures).  By the same token, consecutive values for a given\n   * key within the elements form a 'column'.  This matches the usual sense of\n   * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n   *\n   * Thus, \"column-major\" means that the resulting batch is a (potentially\n   * nested) structure representing the columns.  Each column entry, then,\n   * contains a collection of the values found in that column for a range of\n   * input elements.  This representation allows for vectorized computation, in\n   * contrast to the row-major form.\n   *\n   * The inputs should all have the same nested structure (i.e., of arrays and\n   * dicts).  The result is a single object with the same nested structure,\n   * where the leaves are arrays collecting the values of the inputs at that\n   * location (or, optionally, the result of a custom function applied to those\n   * arrays).\n   *\n   * @param batchSize The number of elements desired per batch.\n   * @param smallLastBatch Whether to emit the final batch when it has fewer\n   *   than batchSize elements. Default true.\n   * @param zipFn: (optional) A function that expects an array of elements at a\n   *   single node of the object tree, and returns a `DeepMapResult`.  The\n   *   `DeepMapResult` either provides a result value for that node (i.e.,\n   *   representing the subtree), or indicates that the node should be processed\n   *   recursively.  The default zipFn recurses as far as possible and places\n   *   arrays at the leaves.\n   * @returns A `LazyIterator` of batches of elements, represented as an object\n   *   with collections at the leaves.\n   */\n  columnMajorBatch(\n      batchSize: number, smallLastBatch = true,\n      // tslint:disable-next-line:no-any\n      zipFn: (xs: any[]) => DeepMapResult = zipToList):\n      LazyIterator<tf.TensorContainer> {\n    // First collect the desired number of input elements as a row-major batch.\n    const rowBatches = this.rowMajorBatch(batchSize, smallLastBatch);\n    // Now 'rotate' or 'pivot' the data, collecting all values from each column\n    // in the batch (i.e., for each key within the elements) into an array.\n    return rowBatches.map(x => deepZip(x, zipFn));\n  }\n\n  /**\n   * Concatenate this `LazyIterator` with another.\n   *\n   * @param iterator A `LazyIterator` to be concatenated onto this one.\n   * @param baseErrorHandler An optional function that can intercept `Error`s\n   *   raised during a `next()` call on the base stream.  This function can\n   *   decide whether the error should be propagated, whether the error should\n   *   be ignored, or whether the base stream should be terminated.\n   * @returns A `LazyIterator`.\n   */\n  concatenate(\n      iterator: LazyIterator<T>,\n      baseErrorHandler?: (e: Error) => boolean): LazyIterator<T> {\n    return new ChainedIterator(\n        iteratorFromItems([this, iterator]), baseErrorHandler);\n  }\n\n  /**\n   * Limits this stream to return at most `count` items.\n   *\n   * @param count The maximum number of items to provide from the stream. If\n   * a negative or undefined value is given, the entire stream is returned\n   *   unaltered.\n   */\n  take(count: number): LazyIterator<T> {\n    if (count < 0 || count == null) {\n      return this;\n    }\n    return new TakeIterator(this, count);\n  }\n\n  /**\n   * Skips the first `count` items in this stream.\n   *\n   * @param count The number of items to skip.  If a negative or undefined\n   * value is given, the entire stream is returned unaltered.\n   */\n  skip(count: number): LazyIterator<T> {\n    if (count < 0 || count == null) {\n      return this;\n    }\n    return new SkipIterator(this, count);\n  }\n\n  /**\n   * Prefetch the first `bufferSize` items in this stream.\n   *\n   * Note this prefetches Promises, but makes no guarantees about when those\n   * Promises resolve.\n   *\n   * @param bufferSize: An integer specifying the number of elements to be\n   *   prefetched.\n   */\n  prefetch(bufferSize: number): LazyIterator<T> {\n    return new PrefetchIterator(this, bufferSize);\n  }\n\n  // TODO(soergel): deep sharded shuffle, where supported\n\n  /**\n   * Randomly shuffles the elements of this stream.\n   *\n   * @param bufferSize: An integer specifying the number of elements from\n   * this stream from which the new stream will sample.\n   * @param seed: (Optional.) An integer specifying the random seed that\n   * will be used to create the distribution.\n   */\n  shuffle(windowSize: number, seed?: string): LazyIterator<T> {\n    return new ShuffleIterator(this, windowSize, seed);\n  }\n\n  /**\n   * Force an iterator to execute serially: each next() call will await the\n   * prior one, so that they cannot execute concurrently.\n   */\n  serial(): LazyIterator<T> {\n    return new SerialIterator(this);\n  }\n}\n\n// ============================================================================\n// The following private classes serve to implement the chainable methods\n// on LazyIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n\n// Iterators that just extend LazyIterator directly\n// ============================================================================\n\nclass ArrayIterator<T> extends LazyIterator<T> {\n  private trav = 0;\n  constructor(protected items: T[]) {\n    super();\n  }\n\n  summary() {\n    return `Array of ${this.items.length} items`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    if (this.trav >= this.items.length) {\n      return {value: null, done: true};\n    }\n    const item = this.items[this.trav];\n    this.trav++;\n    return {value: deepClone(item), done: false};\n  }\n}\n\nclass FunctionCallIterator<T> extends LazyIterator<T> {\n  constructor(\n      protected nextFn: () => IteratorResult<T>| Promise<IteratorResult<T>>) {\n    super();\n  }\n\n  summary() {\n    return `Function call`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    try {\n      return this.nextFn();\n    } catch (e) {\n      // Modify the error message but leave the stack trace intact\n      e.message =\n          `Error thrown while iterating through a dataset: ${e.message}`;\n      throw e;\n    }\n  }\n}\n\nclass SerialIterator<T> extends LazyIterator<T> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  constructor(protected upstream: LazyIterator<T>) {\n    super();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Serial`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  private async serialNext(): Promise<IteratorResult<T>> {\n    return this.upstream.next();\n  }\n}\n\nclass SkipIterator<T> extends LazyIterator<T> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  // Local state that should not be clobbered by out-of-order execution.\n  count = 0;\n\n  constructor(protected upstream: LazyIterator<T>, protected maxCount: number) {\n    super();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Skip`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  private async serialNext(): Promise<IteratorResult<T>> {\n    // TODO(soergel): consider tradeoffs of reading in parallel, eg.\n    // collecting next() promises in an Array and then waiting for\n    // Promise.all() of those. Benefit: pseudo-parallel execution.  Drawback:\n    // maybe delayed GC.\n    while (this.count++ < this.maxCount) {\n      const skipped = await this.upstream.next();\n      // short-circuit if upstream is already empty\n      if (skipped.done) {\n        return skipped;\n      }\n      tf.dispose(skipped.value as {});\n    }\n    return this.upstream.next();\n  }\n}\n\nclass TakeIterator<T> extends LazyIterator<T> {\n  count = 0;\n  constructor(protected upstream: LazyIterator<T>, protected maxCount: number) {\n    super();\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Take`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    if (this.count++ >= this.maxCount) {\n      return {value: null, done: true};\n    }\n    return this.upstream.next();\n  }\n}\n\n// Note this batch just groups items into row-wise element arrays.\n// Rotating these to a column-wise representation happens only at the dataset\n// level.\nclass RowMajorBatchIterator<T> extends LazyIterator<T[]> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T[]>>;\n\n  constructor(\n      protected upstream: LazyIterator<T>, protected batchSize: number,\n      protected enableSmallLastBatch = true) {\n    super();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> RowMajorBatch`;\n  }\n\n  async next(): Promise<IteratorResult<T[]>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  private async serialNext(): Promise<IteratorResult<T[]>> {\n    const batch: T[] = [];\n    while (batch.length < this.batchSize) {\n      const item = await this.upstream.next();\n      if (item.done) {\n        if (this.enableSmallLastBatch && batch.length > 0) {\n          return {value: batch, done: false};\n        }\n        return {value: null, done: true};\n      }\n      batch.push(item.value);\n    }\n    return {value: batch, done: false};\n  }\n}\n\nclass FilterIterator<T> extends LazyIterator<T> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  constructor(\n      protected upstream: LazyIterator<T>,\n      protected predicate: (value: T) => boolean) {\n    super();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Filter`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  private async serialNext(): Promise<IteratorResult<T>> {\n    while (true) {\n      const item = await this.upstream.next();\n      if (item.done || this.predicate(item.value)) {\n        return item;\n      }\n      tf.dispose(item.value as {});\n    }\n  }\n}\n\nclass MapIterator<I, O> extends LazyIterator<O> {\n  constructor(\n      protected upstream: LazyIterator<I>,\n      protected transform: (value: I) => O) {\n    super();\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Map`;\n  }\n\n  async next(): Promise<IteratorResult<O>> {\n    const item = await this.upstream.next();\n    if (item.done) {\n      return {value: null, done: true};\n    }\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value as {});\n    // Careful: the transform may mutate the item in place.\n    // That's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying\n    // any intermediate Tensors.  Here we are concerned only about the\n    // inputs.\n    const mapped = this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mapped as {});\n\n    // TODO(soergel) faster intersection\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n    return {value: mapped, done: false};\n  }\n}\n\nclass ErrorHandlingLazyIterator<T> extends LazyIterator<T> {\n  count = 0;\n  constructor(\n      protected upstream: LazyIterator<T>,\n      protected handler: (error: Error) => boolean) {\n    super();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> handleErrors`;\n  }\n\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  async serialNext(): Promise<IteratorResult<T>> {\n    while (true) {\n      try {\n        return await this.upstream.next();\n      } catch (e) {\n        if (!this.handler(e)) {\n          return {value: null, done: true};\n        }\n        // If the handler returns true, loop and fetch the next upstream item.\n\n        // If the upstream iterator throws an endless stream of errors, and if\n        // the handler says to ignore them, then we loop forever here.  That is\n        // the correct behavior-- it's up to the handler to decide when to stop.\n      }\n    }\n  }\n}\n\nclass AsyncMapIterator<I, O> extends LazyIterator<O> {\n  constructor(\n      protected upstream: LazyIterator<I>,\n      protected transform: (value: I) => Promise<O>) {\n    super();\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> AsyncMap`;\n  }\n\n  async next(): Promise<IteratorResult<O>> {\n    const item = await this.upstream.next();\n    if (item.done) {\n      return {value: null, done: true};\n    }\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value as {});\n    // Careful: the transform may mutate the item in place.\n    // That's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying\n    // any intermediate Tensors.  Here we are concerned only about the\n    // inputs.\n    const mapped = await this.transform(item.value);\n    const outputTensors = tf.tensor_util.getTensorsInContainer(mapped as {});\n\n    // TODO(soergel) faster intersection\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n    return {value: mapped, done: false};\n  }\n}\n\n// Iterators that maintain a queue of pending items\n// ============================================================================\n\n/**\n * A base class for transforming streams that operate by maintaining an\n * output queue of elements that are ready to return via next().  This is\n * commonly required when the transformation is 1-to-many:  A call to next()\n * may trigger a call to the underlying stream, which will produce many\n * mapped elements of this stream-- of which we need to return only one, so\n * we have to queue the rest.\n */\nexport abstract class OneToManyIterator<T> extends LazyIterator<T> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  // Local state that should not be clobbered by out-of-order execution.\n  protected outputQueue: RingBuffer<T>;\n\n  constructor() {\n    super();\n    this.outputQueue = new GrowingRingBuffer<T>();\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  /**\n   * Read one or more chunks from upstream and process them, possibly\n   * reading or writing a carryover, and adding processed items to the\n   * output queue.  Note it's possible that no items are added to the queue\n   * on a given pump() call, even if the upstream stream is not closed\n   * (e.g., because items are filtered).\n   *\n   * @return `true` if any action was taken, i.e. fetching items from the\n   *   upstream source OR adding items to the output queue.  `false` if the\n   *   upstream source is exhausted AND nothing was added to the queue\n   * (i.e., any remaining carryover).\n   */\n  protected abstract async pump(): Promise<boolean>;\n\n  async serialNext(): Promise<IteratorResult<T>> {\n    // Fetch so that the queue contains at least one item if possible.\n    // If the upstream source is exhausted, AND there are no items left in\n    // the output queue, then this stream is also exhausted.\n    while (this.outputQueue.length() === 0) {\n      // TODO(soergel): consider parallel reads.\n      if (!await this.pump()) {\n        return {value: null, done: true};\n      }\n    }\n    return {value: this.outputQueue.shift(), done: false};\n  }\n}\nclass FlatmapIterator<I, O> extends OneToManyIterator<O> {\n  constructor(\n      protected upstream: LazyIterator<I>,\n      protected transform: (value: I) => O[]) {\n    super();\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Flatmap`;\n  }\n\n  async pump(): Promise<boolean> {\n    const item = await this.upstream.next();\n    if (item.done) {\n      return false;\n    }\n    const inputTensors = tf.tensor_util.getTensorsInContainer(item.value as {});\n    // Careful: the transform may mutate the item in place.\n    // that's why we have to remember the input Tensors above, and then\n    // below dispose only those that were not passed through to the output.\n    // Note too that the transform function is responsible for tidying any\n    // intermediate Tensors.  Here we are concerned only about the inputs.\n    const mappedArray = this.transform(item.value);\n    const outputTensors =\n        tf.tensor_util.getTensorsInContainer(mappedArray as {});\n    this.outputQueue.pushAll(mappedArray);\n\n    // TODO(soergel) faster intersection, and deduplicate outputTensors\n    // TODO(soergel) move to tf.disposeExcept(in, out)?\n    for (const t of inputTensors) {\n      if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n        t.dispose();\n      }\n    }\n\n    return true;\n  }\n}\n\n/**\n * Provides a `LazyIterator` that concatenates a stream of underlying\n * streams.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n */\nexport class ChainedIterator<T> extends LazyIterator<T> {\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>> = null;\n\n  // Local state that should not be clobbered by out-of-order execution.\n  private iterator: LazyIterator<T> = null;\n  private moreIterators: LazyIterator<LazyIterator<T>>;\n\n  constructor(\n      iterators: LazyIterator<LazyIterator<T>>,\n      private readonly baseErrorHandler?: (e: Error) => boolean) {\n    super();\n    this.moreIterators = iterators;\n  }\n\n  summary() {\n    const upstreamSummaries = 'TODO: fill in upstream of chained summaries';\n    return `${upstreamSummaries} -> Chained`;\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    this.lastRead = this.readFromChain(this.lastRead);\n    return this.lastRead;\n  }\n\n  private async readFromChain(lastRead: Promise<IteratorResult<T>>):\n      Promise<IteratorResult<T>> {\n    // Must await on the previous read since the previous read may have advanced\n    // the stream of streams, from which we need to read.\n    // This is unfortunate since we can't parallelize reads. Which means\n    // prefetching of chained streams is a no-op.\n    // One solution is to prefetch immediately upstream of this.\n    await lastRead;\n    if (this.iterator == null) {\n      const iteratorResult = await this.moreIterators.next();\n      if (iteratorResult.done) {\n        // No more streams to stream from.\n        return {value: null, done: true};\n      }\n      this.iterator = iteratorResult.value;\n      if (this.baseErrorHandler != null) {\n        this.iterator = this.iterator.handleErrors(this.baseErrorHandler);\n      }\n    }\n    const itemResult = await this.iterator.next();\n    if (itemResult.done) {\n      this.iterator = null;\n      return this.readFromChain(lastRead);\n    }\n    return itemResult;\n  }\n}\n\nexport enum ZipMismatchMode {\n  FAIL,      // require zipped streams to have the same length\n  SHORTEST,  // terminate zip when the first stream is exhausted\n  LONGEST    // use nulls for exhausted streams; use up the longest stream.\n}\n\n/**\n * Provides a `LazyIterator` that zips together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\nclass ZipIterator<O extends tf.TensorContainer> extends LazyIterator<O> {\n  private count = 0;\n  private currentPromise: Promise<IteratorResult<O>> = null;\n\n  constructor(\n      protected readonly iterators: IteratorContainer,\n      protected readonly mismatchMode: ZipMismatchMode = ZipMismatchMode.FAIL) {\n    super();\n  }\n\n  summary() {\n    const upstreamSummaries = 'TODO: fill in upstream of zip summaries';\n    return `{${upstreamSummaries}} -> Zip`;\n  }\n\n  private async nextState(afterState: Promise<IteratorResult<O>>):\n      Promise<IteratorResult<O>> {\n    // This chaining ensures that the underlying next() are not even called\n    // before the previous ones have resolved.\n    await afterState;\n\n    // Collect underlying iterator \"done\" signals as a side effect in\n    // getNext()\n    let numIterators = 0;\n    let iteratorsDone = 0;\n\n    function getNext(container: IteratorContainer): DeepMapAsyncResult {\n      if (container instanceof LazyIterator) {\n        const result = container.next();\n        return {\n          value: result.then(x => {\n            numIterators++;\n            if (x.done) {\n              iteratorsDone++;\n            }\n            return x.value;\n          }),\n          recurse: false\n        };\n      } else {\n        return {value: null, recurse: true};\n      }\n    }\n\n    const mapped: O = await deepMapAndAwaitAll(this.iterators, getNext);\n\n    if (numIterators === iteratorsDone) {\n      // The streams have all ended.\n      return {value: null, done: true};\n    }\n    if (iteratorsDone > 0) {\n      switch (this.mismatchMode) {\n        case ZipMismatchMode.FAIL:\n          throw new Error(\n              'Zipped streams should have the same length. ' +\n              `Mismatched at element ${this.count}.`);\n        case ZipMismatchMode.SHORTEST:\n          return {value: null, done: true};\n        case ZipMismatchMode.LONGEST:\n        default:\n          // Continue.  The exhausted streams already produced value: null.\n      }\n    }\n\n    this.count++;\n    return {value: mapped, done: false};\n  }\n\n  async next(): Promise<IteratorResult<O>> {\n    this.currentPromise = this.nextState(this.currentPromise);\n    return this.currentPromise;\n  }\n}\n\n// Iterators that maintain a ring buffer of pending promises\n// ============================================================================\n\n/**\n * A stream that prefetches a given number of items from an upstream source,\n * returning them in FIFO order.\n *\n * Note this prefetches Promises, but makes no guarantees about when those\n * Promises resolve.\n */\nexport class PrefetchIterator<T> extends LazyIterator<T> {\n  protected buffer: RingBuffer<Promise<IteratorResult<T>>>;\n\n  constructor(\n      protected upstream: LazyIterator<T>, protected bufferSize: number) {\n    super();\n    this.buffer = new RingBuffer<Promise<IteratorResult<T>>>(bufferSize);\n  }\n\n  summary() {\n    return `${this.upstream.summary()} -> Prefetch`;\n  }\n\n  /**\n   * Refill the prefetch buffer.  Returns only after the buffer is full, or\n   * the upstream source is exhausted.\n   */\n  protected refill() {\n    while (!this.buffer.isFull()) {\n      const v = this.upstream.next();\n      this.buffer.push(v);\n    }\n  }\n\n  next(): Promise<IteratorResult<T>> {\n    this.refill();\n    // This shift will never throw an error because the buffer is always\n    // full after a refill. If the stream is exhausted, the buffer will be\n    // full of Promises that will resolve to the end-of-stream signal.\n    return this.buffer.shift();\n  }\n}\n\n/**\n * A stream that performs a sliding-window random shuffle on an upstream\n * source. This is like a `PrefetchIterator` except that the items are\n * returned in randomized order.  Mixing naturally improves as the buffer\n * size increases.\n */\nexport class ShuffleIterator<T> extends PrefetchIterator<T> {\n  private readonly random: seedrandom.prng;\n\n  // Strict Promise execution order:\n  // a next() call may not even begin until the previous one completes.\n  private lastRead: Promise<IteratorResult<T>>;\n\n  // Local state that should not be clobbered by out-of-order execution.\n  private upstreamExhausted = false;\n\n  constructor(\n      protected upstream: LazyIterator<T>, protected windowSize: number,\n      seed?: string) {\n    super(upstream, windowSize);\n    this.random = seedrandom.alea(seed || tf.util.now().toString());\n    this.lastRead = Promise.resolve({value: null, done: false});\n  }\n\n  async next(): Promise<IteratorResult<T>> {\n    // This sets this.lastRead to a new Promise right away, as opposed to\n    // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n    // would not work because this.nextRead would be updated only after the\n    // promise resolves.\n    this.lastRead = this.lastRead.then(() => this.serialNext());\n    return this.lastRead;\n  }\n\n  private randomInt(max: number) {\n    return Math.floor(this.random() * max);\n  }\n\n  protected chooseIndex(): number {\n    return this.randomInt(this.buffer.length());\n  }\n\n  async serialNext(): Promise<IteratorResult<T>> {\n    // TODO(soergel): consider performance\n    if (!this.upstreamExhausted) {\n      this.refill();\n    }\n    while (!this.buffer.isEmpty()) {\n      const chosenIndex = this.chooseIndex();\n      const result = await this.buffer.shuffleExcise(chosenIndex);\n      if (result.done) {\n        this.upstreamExhausted = true;\n      } else {\n        this.refill();\n        return result;\n      }\n    }\n    return {value: null, done: true};\n  }\n}\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}