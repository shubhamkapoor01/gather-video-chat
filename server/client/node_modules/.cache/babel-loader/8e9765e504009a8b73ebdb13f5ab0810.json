{"ast":null,"code":"/**\r\n * @license\r\n * Copyright 2018 Google LLC\r\n *\r\n * Use of this source code is governed by an MIT-style\r\n * license that can be found in the LICENSE file or at\r\n * https://opensource.org/licenses/MIT.\r\n * =============================================================================\r\n */\n\n/* Original Source: engine/training.py */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { io, Optimizer, scalar, serialization, Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { nameScope } from '../common';\nimport { NotImplementedError, RuntimeError, ValueError } from '../errors';\nimport { deserialize } from '../layers/serialization';\nimport * as losses from '../losses';\nimport * as Metrics from '../metrics';\nimport * as optimizers from '../optimizers';\nimport { checkUserDefinedMetadata } from '../user_defined_metadata';\nimport { count, pyListRepeat, singletonOrArray, toCamelCase, toSnakeCase, unique } from '../utils/generic_utils';\nimport { printSummary } from '../utils/layer_utils';\nimport { range } from '../utils/math_utils';\nimport { convertPythonicToTs } from '../utils/serialization_utils';\nimport { version } from '../version';\nimport { Container } from './container';\nimport { execute, FeedDict } from './executor';\nimport { evaluateDataset, fitDataset } from './training_dataset';\nimport { checkBatchSize, disposeNewTensors, ensureTensorsRank2OrHigher, fitTensors, makeBatches, sliceArrays, sliceArraysByIndices } from './training_tensors';\nimport { computeWeightedLoss, standardizeClassWeights, standardizeWeights } from './training_utils';\n/**\r\n * Helper function for polymorphic input data: 1. singleton Tensor.\r\n */\n\nexport function isDataTensor(x) {\n  return x instanceof Tensor;\n}\n/**\r\n * Helper function for polymorphic input data: 2. Array of Tensor.\r\n */\n\nexport function isDataArray(x) {\n  return Array.isArray(x);\n}\n/**\r\n * Helper function for polymorphic input data: 3. \"dict\" of Tensor.\r\n */\n\nexport function isDataDict(x) {\n  return !isDataTensor(x) && !isDataArray(x);\n}\n/**\r\n * Normalizes inputs and targets provided by users.\r\n * @param data User-provided input data (polymorphic).\r\n * @param names An Array of expected Tensor names.\r\n * @param shapes Optional Array of expected Tensor shapes.\r\n * @param checkBatchAxis Whether to check that the batch axis of the arrays\r\n *   match  the expected value found in `shapes`.\r\n * @param exceptionPrefix String prefix used for exception formatting.\r\n * @returns List of standardized input Tensors (one Tensor per model input).\r\n * @throws ValueError: in case of improperly formatted user data.\r\n */\n\nexport function standardizeInputData(data, names, shapes, checkBatchAxis = true, exceptionPrefix = '') {\n  if (names == null || names.length === 0) {\n    // Check for the case where the model expected no data, but some data got\n    // sent.\n    if (data != null) {\n      let gotUnexpectedData = false;\n\n      if (isDataArray(data) && data.length > 0) {\n        gotUnexpectedData = true;\n      } else if (isDataDict(data)) {\n        for (const key in data) {\n          if (data.hasOwnProperty(key)) {\n            gotUnexpectedData = true;\n            break;\n          }\n        }\n      } else {\n        // `data` is a singleton Tensor in this case.\n        gotUnexpectedData = true;\n      }\n\n      if (gotUnexpectedData) {\n        throw new ValueError(`Error when checking model ${exceptionPrefix} expected no data, ` + `but got ${data}`);\n      }\n    }\n\n    return [];\n  }\n\n  if (data == null) {\n    return names.map(name => null);\n  }\n\n  let arrays;\n\n  if (isDataDict(data)) {\n    data = data;\n    arrays = [];\n\n    for (const name of names) {\n      if (data[name] == null) {\n        throw new ValueError(`No data provided for \"${name}\". Need data for each key in: ` + `${names}`);\n      }\n\n      arrays.push(data[name]);\n    }\n  } else if (isDataArray(data)) {\n    data = data;\n\n    if (data.length !== names.length) {\n      throw new ValueError(`Error when checking model ${exceptionPrefix}: the Array of ` + `Tensors that you are passing to your model is not the size the ` + `model expected. Expected to see ${names.length} Tensor(s), but ` + `instead got the following list of Tensor(s): ${data}`);\n    }\n\n    arrays = data;\n  } else {\n    data = data;\n\n    if (names.length > 1) {\n      throw new ValueError(`The model ${exceptionPrefix} expects ${names.length} Tensor(s), ` + `but only received one Tensor. Found: Tensor with shape ${data.shape}`);\n    }\n\n    arrays = [data];\n  }\n\n  arrays = ensureTensorsRank2OrHigher(arrays); // Check shape compatibility.\n\n  if (shapes != null) {\n    for (let i = 0; i < names.length; ++i) {\n      if (shapes[i] == null) {\n        continue;\n      }\n\n      const array = arrays[i];\n\n      if (array.shape.length !== shapes[i].length) {\n        throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} ` + `to have ${shapes[i].length} dimension(s). but got array with ` + `shape ${array.shape}`);\n      }\n\n      for (let j = 0; j < shapes[i].length; ++j) {\n        if (j === 0 && !checkBatchAxis) {\n          // Skip the first (batch) axis.\n          continue;\n        }\n\n        const dim = array.shape[j];\n        const refDim = shapes[i][j];\n\n        if (refDim != null && refDim >= 0 && dim !== refDim) {\n          throw new ValueError(`${exceptionPrefix} expected a batch of elements where each ` + `example has shape [${shapes[i].slice(1, shapes[i].length)}] ` + `(i.e.,tensor shape [*,${shapes[i].slice(1, shapes[i].length)}])` + ` but the ${exceptionPrefix} received an input with ${array.shape[0]}` + ` examples, each with shape [${array.shape.slice(1, array.shape.length)}]` + ` (tensor shape [${array.shape}])`);\n        }\n      }\n    }\n  }\n\n  return arrays;\n}\n/**\r\n * User input validation for Tensors.\r\n * @param inputs `Array` of `tf.Tensor`s for inputs.\r\n * @param targets `Array` of `tf.Tensor`s for targets.\r\n * @param weights Optional `Array` of `tf.Tensor`s for sample weights.\r\n * @throws ValueError: in case of incorrectly formatted data.\r\n */\n\nexport function checkArrayLengths(inputs, targets, weights) {\n  const setX = unique(inputs.map(input => input.shape[0]));\n  setX.sort();\n  const setY = unique(targets.map(target => target.shape[0]));\n  setY.sort(); // TODO(cais): Check `weights` as well.\n\n  if (setX.length > 1) {\n    throw new ValueError(`All input Tensors (x) should have the same number of samples. ` + `Got array shapes: ` + `${JSON.stringify(inputs.map(input => input.shape))}`);\n  }\n\n  if (setY.length > 1) {\n    throw new ValueError(`All target Tensors (y) should have the same number of samples. ` + `Got array shapes: ` + `${JSON.stringify(targets.map(target => target.shape))}`);\n  }\n\n  if (setX.length > 0 && setY.length > 0 && !util.arraysEqual(setX, setY)) {\n    throw new ValueError(`Input Tensors should have the same number of samples as target ` + `Tensors. Found ${setX[0]} input sample(s) and ${setY[0]} target ` + `sample(s).`);\n  }\n}\n/**\r\n * Validation on the compatibility of targes and loss functions.\r\n *\r\n * This helps prevent users from using loss functions incorrectly.\r\n *\r\n * @param targets `Array` of `tf.Tensor`s of targets.\r\n * @param lossFns `Array` of loss functions.\r\n * @param outputShapes `Array` of shapes of model outputs.\r\n */\n\nfunction checkLossAndTargetCompatibility(targets, lossFns, outputShapes) {\n  // TODO(cais): Dedicated test coverage?\n  const keyLosses = [losses.meanSquaredError, losses.binaryCrossentropy, losses.categoricalCrossentropy];\n\n  for (let i = 0; i < targets.length; ++i) {\n    const y = targets[i];\n    const loss = lossFns[i];\n    const shape = outputShapes[i];\n\n    if (loss == null) {\n      continue;\n    }\n\n    if (loss === losses.categoricalCrossentropy) {\n      if (y.shape[y.shape.length - 1] === 1) {\n        throw new ValueError(`You are passing a target array of shape ${y.shape} while using ` + `a loss 'categorical_crossentropy'. 'categorical_crossentropy'` + `expects targets to be binary matrices (1s and 0s) of shape ` + `[samples, classes].`); // TODO(cais): Example code in error message.\n      }\n    }\n\n    if (keyLosses.indexOf(loss) !== -1) {\n      const slicedYShape = y.shape.slice(1);\n      const slicedShape = shape.slice(1);\n\n      for (let j = 0; j < slicedYShape.length; ++j) {\n        const targetDim = slicedYShape[j];\n        const outDim = slicedShape[j];\n\n        if (outDim != null && targetDim !== outDim) {\n          throw new ValueError(`A target Tensor with shape ${y.shape} was passed for an ` + `output of shape ${shape}, while using a loss function that ` + `expects targets to have the same shape as the output.`);\n        }\n      }\n    }\n  }\n}\n/**\r\n * Check inputs provided by the user.\r\n *\r\n * Porting Note: This corresponds to _standardize_input_data() in Python\r\n *   Keras. Because of the strong typing in TF.js, we do not need to convert\r\n *   the data. Specifically:\r\n *   1) in PyKeras, `data` can be `DataFrame` instances from pandas, for\r\n *      example. We don't need to worry about that here because there is no\r\n *      widely popular javascript/typesdcript equivalent of pandas (so far).\r\n *      If one becomes available in the future, we can add support.\r\n *   2) in PyKeras, inputs can be Python dict. But here we are stipulating\r\n * that the data is either a single `tf.Tensor` or an Array of `tf.Tensor`s. We\r\n * may add support for `Object` data inputs in the future when the need\r\n * arises.\r\n *\r\n * Instead, we perform basic checks for number of parameters and shapes.\r\n *\r\n * @param data: The input data.\r\n * @param names: Name for the inputs, from the model.\r\n * @param shapes: Expected shapes for the input data, from the model.\r\n * @param checkBatchAxis: Whether the size along the batch axis (i.e., the\r\n *   first dimension) will be checked for matching.\r\n * @param exceptionPrefix: Execption prefix message, used in generating error\r\n *   messages.\r\n * @throws ValueError: on incorrect number of inputs or mismatches in shapes.\r\n */\n\n\nfunction checkInputData(data, names, shapes, checkBatchAxis = true, exceptionPrefix = '') {\n  let arrays;\n\n  if (Array.isArray(data)) {\n    if (data.length !== names.length) {\n      throw new ValueError(`Error when checking model ${exceptionPrefix}: the Array of ` + `Tensors that you are passing to your model is not the size the ` + `the model expected. Expected to see ${names.length} Tensor(s),` + ` but instead got ${data.length} Tensors(s).`);\n    }\n\n    arrays = data;\n  } else {\n    if (names.length > 1) {\n      throw new ValueError(`The model expects ${names.length} ${exceptionPrefix} Tensors, ` + `but only received one Tensor. Found: array with shape ` + `${JSON.stringify(data.shape)}.`);\n    }\n\n    arrays = [data];\n  }\n\n  if (shapes != null) {\n    for (let i = 0; i < names.length; ++i) {\n      if (shapes[i] == null) {\n        continue;\n      }\n\n      const array = arrays[i];\n\n      if (array.shape.length !== shapes[i].length) {\n        throw new ValueError(`Error when checking ${exceptionPrefix}: expected ${names[i]} ` + `to have ${shapes[i].length} dimension(s), but got array with ` + `shape ${JSON.stringify(array.shape)}`);\n      }\n\n      for (let j = 0; j < shapes[i].length; ++j) {\n        if (j === 0 && !checkBatchAxis) {\n          continue;\n        }\n\n        const dim = array.shape[j];\n        const refDim = shapes[i][j];\n\n        if (refDim != null) {\n          if (refDim !== dim) {\n            throw new ValueError(`Error when checking ${exceptionPrefix}: expected ` + `${names[i]} to have shape ${JSON.stringify(shapes[i])} but ` + `got array with shape ${JSON.stringify(array.shape)}.`);\n          }\n        }\n      }\n    }\n  }\n}\n/**\r\n * Maps metric functions to model outputs.\r\n * @param metrics An shortcut strings name, metric function, `Array` or dict\r\n *   (`Object`) of metric functions.\r\n * @param outputNames An `Array` of the names of model outputs.\r\n * @returns An `Array` (one entry per model output) of `Array` of metric\r\n *   functions. For instance, if the model has 2 outputs, and for the first\r\n *   output we want to compute `binaryAccuracy` and `binaryCrossentropy`,\r\n *   and just `binaryAccuracy` for the second output, the `Array` would look\r\n *   like:\r\n *     `[[binaryAccuracy, binaryCrossentropy],  [binaryAccuracy]]`\r\n * @throws TypeError: incompatible metrics format.\r\n */\n\n\nexport function collectMetrics(metrics, outputNames) {\n  if (metrics == null || Array.isArray(metrics) && metrics.length === 0) {\n    return outputNames.map(name => []);\n  }\n\n  let wrappedMetrics;\n\n  if (typeof metrics === 'string' || typeof metrics === 'function') {\n    wrappedMetrics = [metrics];\n  } else if (Array.isArray(metrics) || typeof metrics === 'object') {\n    wrappedMetrics = metrics;\n  } else {\n    throw new TypeError('Type of metrics argument not understood. Expected an string,' + `function, Array, or Object, found: ${metrics}`);\n  }\n\n  if (Array.isArray(wrappedMetrics)) {\n    // We then apply all metrics to all outputs.\n    return outputNames.map(name => wrappedMetrics);\n  } else {\n    // In this case, metrics is a dict.\n    const nestedMetrics = [];\n\n    for (const name of outputNames) {\n      let outputMetrics = wrappedMetrics.hasOwnProperty(name) ? wrappedMetrics[name] : [];\n\n      if (!Array.isArray(outputMetrics)) {\n        outputMetrics = [outputMetrics];\n      }\n\n      nestedMetrics.push(outputMetrics);\n    }\n\n    return nestedMetrics;\n  }\n}\nconst LAYERS_MODEL_FORMAT_NAME = 'layers-model';\n/**\r\n * A `tf.LayersModel` is a directed, acyclic graph of `tf.Layer`s plus methods\r\n * for training, evaluation, prediction and saving.\r\n *\r\n * `tf.LayersModel` is the basic unit of training, inference and evaluation in\r\n * TensorFlow.js. To create a `tf.LayersModel`, use `tf.LayersModel`.\r\n *\r\n * See also:\r\n *   `tf.Sequential`, `tf.loadLayersModel`.\r\n *\r\n * @doc {heading: 'Models', subheading: 'Classes'}\r\n */\n\nexport class LayersModel extends Container {\n  constructor(args) {\n    super(args);\n    this.isTraining = false;\n  }\n  /**\r\n   * Print a text summary of the model's layers.\r\n   *\r\n   * The summary includes\r\n   * - Name and type of all layers that comprise the model.\r\n   * - Output shape(s) of the layers\r\n   * - Number of weight parameters of each layer\r\n   * - If the model has non-sequential-like topology, the inputs each layer\r\n   *   receives\r\n   * - The total number of trainable and non-trainable parameters of the model.\r\n   *\r\n   * ```js\r\n   * const input1 = tf.input({shape: [10]});\r\n   * const input2 = tf.input({shape: [20]});\r\n   * const dense1 = tf.layers.dense({units: 4}).apply(input1);\r\n   * const dense2 = tf.layers.dense({units: 8}).apply(input2);\r\n   * const concat = tf.layers.concatenate().apply([dense1, dense2]);\r\n   * const output =\r\n   *     tf.layers.dense({units: 3, activation: 'softmax'}).apply(concat);\r\n   *\r\n   * const model = tf.model({inputs: [input1, input2], outputs: output});\r\n   * model.summary();\r\n   * ```\r\n   *\r\n   * @param lineLength Custom line length, in number of characters.\r\n   * @param positions Custom widths of each of the columns, as either\r\n   *   fractions of `lineLength` (e.g., `[0.5, 0.75, 1]`) or absolute number\r\n   *   of characters (e.g., `[30, 50, 65]`). Each number corresponds to\r\n   *   right-most (i.e., ending) position of a column.\r\n   * @param printFn Custom print function. Can be used to replace the default\r\n   *   `console.log`. For example, you can use `x => {}` to mute the printed\r\n   *   messages in the console.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n\n\n  summary(lineLength, positions, printFn = console.log) {\n    if (!this.built) {\n      throw new ValueError(`This model has never been called, thus its weights have not been ` + `created yet. So no summary can be displayed. Build the model ` + `first (e.g., by calling it on some test data).`);\n    }\n\n    printSummary(this, lineLength, positions, printFn);\n  }\n  /**\r\n   * Configures and prepares the model for training and evaluation.  Compiling\r\n   * outfits the model with an optimizer, loss, and/or metrics.  Calling `fit`\r\n   * or `evaluate` on an un-compiled model will throw an error.\r\n   *\r\n   * @param args a `ModelCompileArgs` specifying the loss, optimizer, and\r\n   * metrics to be used for fitting and evaluating this model.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n\n\n  compile(args) {\n    if (args.loss == null) {\n      args.loss = [];\n    }\n\n    this.loss = args.loss;\n\n    if (typeof args.optimizer === 'string') {\n      this.optimizer_ = optimizers.getOptimizer(args.optimizer);\n      this.isOptimizerOwned = true;\n    } else {\n      if (!(args.optimizer instanceof Optimizer)) {\n        throw new ValueError(`User-defined optimizer must be an instance of tf.Optimizer.`);\n      }\n\n      this.optimizer_ = args.optimizer;\n      this.isOptimizerOwned = false;\n    } // TODO(cais): Add lossWeights.\n    // TODO(cais): Add sampleWeightMode.\n    // Prepare loss functions.\n\n\n    let lossFunctions = [];\n\n    if (!Array.isArray(args.loss) && typeof args.loss !== 'string' && typeof args.loss !== 'function') {\n      args.loss = args.loss;\n\n      for (const name in args.loss) {\n        if (this.outputNames.indexOf(name) === -1) {\n          throw new ValueError(`Unknown entry in loss dictionary: \"${name}\". ` + `Only expected the following keys: ${this.outputNames}`);\n        }\n      }\n\n      for (const name of this.outputNames) {\n        if (args.loss[name] == null) {\n          console.warn(`Output \"${name}\" is missing from loss dictionary. We assume ` + `this was done on purpose, and we will not be expecting data ` + `to be passed to ${name} during training`);\n        }\n\n        lossFunctions.push(losses.get(args.loss[name]));\n      }\n    } else if (Array.isArray(args.loss)) {\n      if (args.loss.length !== this.outputs.length) {\n        throw new ValueError(`When passing an Array as loss, it should have one entry per ` + `model output. The model has ${this.outputs.length} output(s), ` + `but you passed loss=${args.loss}.`);\n      }\n\n      const theLosses = args.loss;\n      lossFunctions = theLosses.map(l => losses.get(l));\n    } else {\n      const lossFunction = losses.get(args.loss);\n      this.outputs.forEach(_ => {\n        lossFunctions.push(lossFunction);\n      });\n    }\n\n    this.lossFunctions = lossFunctions;\n    this.feedOutputNames = [];\n    this.feedOutputShapes = [];\n    this.feedLossFns = [];\n\n    for (let i = 0; i < this.outputs.length; ++i) {\n      // TODO(cais): Logic for skipping target(s).\n      const shape = this.internalOutputShapes[i];\n      const name = this.outputNames[i];\n      this.feedOutputNames.push(name);\n      this.feedOutputShapes.push(shape);\n      this.feedLossFns.push(this.lossFunctions[i]);\n    } // TODO(cais): Add logic for output masks.\n    // TODO(cais): Add logic for sample weights.\n\n\n    const skipTargetIndices = []; // Prepare metrics.\n\n    this.metrics = args.metrics; // TODO(cais): Add weightedMetrics.\n\n    this.metricsNames = ['loss'];\n    this.metricsTensors = []; // Compute total loss.\n    // Porting Note: In PyKeras, metrics_tensors are symbolic tensor objects.\n    //   Here, metricsTensors are TypeScript functions. This difference is due\n    //   to the difference in symbolic/imperative property of the backends.\n\n    nameScope('loss', () => {\n      for (let i = 0; i < this.outputs.length; ++i) {\n        if (skipTargetIndices.indexOf(i) !== -1) {\n          continue;\n        } // TODO(cais): Add weightedLoss, sampleWeight and mask.\n        //   The following line should be weightedLoss\n\n\n        const weightedLoss = this.lossFunctions[i];\n\n        if (this.outputs.length > 1) {\n          this.metricsTensors.push([weightedLoss, i]);\n          this.metricsNames.push(this.outputNames[i] + '_loss');\n        }\n      } // Porting Note: Due to the imperative nature of the backend, we calculate\n      //   the regularizer penalties in the totalLossFunction, instead of here.\n\n    });\n    const nestedMetrics = collectMetrics(args.metrics, this.outputNames); // TODO(cais): Add nestedWeightedMetrics.\n\n    /**\r\n     * Helper function used in loop below.\r\n     */\n\n    const appendMetric = (outputIndex, metricName, metricTensor) => {\n      if (this.outputNames.length > 1) {\n        metricName = this.outputNames[outputIndex] + '_' + metricName;\n      }\n\n      this.metricsNames.push(metricName);\n      this.metricsTensors.push([metricTensor, outputIndex]);\n    };\n\n    nameScope('metric', () => {\n      for (let i = 0; i < this.outputs.length; ++i) {\n        if (skipTargetIndices.indexOf(i) !== -1) {\n          continue;\n        }\n\n        const outputMetrics = nestedMetrics[i]; // TODO(cais): Add weights and outputWeightedMetrics.\n        // TODO(cais): Add optional arg `weights` to the following function.\n\n        const handleMetrics = metrics => {\n          const metricNamePrefix = '';\n          let metricName;\n          let accFn;\n          let weightedMetricFn; //  TODO(cais): Use 'weights_' for weighted metrics.\n\n          for (const metric of metrics) {\n            if (typeof metric === 'string' && ['accuracy', 'acc', 'crossentropy', 'ce'].indexOf(metric) !== -1) {\n              const outputShape = this.internalOutputShapes[i];\n\n              if (outputShape[outputShape.length - 1] === 1 || this.lossFunctions[i] === losses.binaryCrossentropy) {\n                // case: binary accuracy/crossentropy.\n                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                  accFn = Metrics.binaryAccuracy;\n                } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                  accFn = Metrics.binaryCrossentropy;\n                }\n              } else if (this.lossFunctions[i] === losses.sparseCategoricalCrossentropy) {\n                // case: categorical accuracy / crossentropy with sparse\n                // targets.\n                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                  accFn = Metrics.sparseCategoricalAccuracy;\n                } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                  accFn = Metrics.sparseCategoricalCrossentropy;\n                }\n              } else {\n                // case: categorical accuracy / crossentropy.\n                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                  accFn = Metrics.categoricalAccuracy;\n                } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                  accFn = Metrics.categoricalCrossentropy;\n                }\n              }\n\n              let suffix;\n\n              if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                suffix = 'acc';\n              } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                suffix = 'ce';\n              } // TODO(cais): Add weighting actually.\n\n\n              weightedMetricFn = accFn;\n              metricName = metricNamePrefix + suffix;\n            } else {\n              const metricFn = Metrics.get(metric); // TODO(cais): Add weighting actually.\n\n              weightedMetricFn = metricFn;\n              metricName = metricNamePrefix + Metrics.getLossOrMetricName(metric);\n            } // TODO(cais): Add weighting and masking to metricResult.\n\n\n            let metricResult;\n            nameScope(metricName, () => {\n              metricResult = weightedMetricFn;\n            });\n            appendMetric(i, metricName, metricResult);\n          }\n        };\n\n        handleMetrics(outputMetrics); // TODO(cais): Call handleMetrics with weights.\n      }\n    }); // Porting Notes: Given the imperative backend of tfjs-core,\n    //   there is no need for constructing the symbolic graph and placeholders.\n\n    this.collectedTrainableWeights = this.trainableWeights;\n  }\n  /**\r\n   * Check trainable weights count consistency.\r\n   *\r\n   * This will raise a warning if `this.trainableWeights` and\r\n   * `this.collectedTrainableWeights` are inconsistent (i.e., have different\r\n   * numbers of parameters).\r\n   * Inconsistency will typically arise when one modifies `model.trainable`\r\n   * without calling `model.compile()` again.\r\n   */\n\n\n  checkTrainableWeightsConsistency() {\n    if (this.collectedTrainableWeights == null) {\n      return;\n    }\n\n    if (this.trainableWeights.length !== this.collectedTrainableWeights.length) {\n      console.warn('Discrepancy between trainableweights and collected trainable ' + 'weights. Did you set `model.trainable` without calling ' + '`model.compile()` afterwards?');\n    }\n  }\n  /**\r\n   * Returns the loss value & metrics values for the model in test mode.\r\n   *\r\n   * Loss and metrics are specified during `compile()`, which needs to happen\r\n   * before calls to `evaluate()`.\r\n   *\r\n   * Computation is done in batches.\r\n   *\r\n   * ```js\r\n   * const model = tf.sequential({\r\n   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\r\n   * });\r\n   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\r\n   * const result = model.evaluate(\r\n   *     tf.ones([8, 10]), tf.ones([8, 1]), {batchSize: 4});\r\n   * result.print();\r\n   * ```\r\n   *\r\n   * @param x `tf.Tensor` of test data, or an `Array` of `tf.Tensor`s if the\r\n   * model has multiple inputs.\r\n   * @param y `tf.Tensor` of target data, or an `Array` of `tf.Tensor`s if the\r\n   * model has multiple outputs.\r\n   * @param args A `ModelEvaluateArgs`, containing optional fields.\r\n   *\r\n   * @return `Scalar` test loss (if the model has a single output and no\r\n   *   metrics) or `Array` of `Scalar`s (if the model has multiple outputs\r\n   *   and/or metrics). The attribute `model.metricsNames`\r\n   *   will give you the display labels for the scalar outputs.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n\n\n  evaluate(x, y, args = {}) {\n    const batchSize = args.batchSize == null ? 32 : args.batchSize;\n    checkBatchSize(batchSize); // TODO(cais): Standardize `config.sampleWeights` as well.\n    // Validate user data.\n\n    const checkBatchAxis = true;\n    const standardizedOuts = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);\n\n    try {\n      // TODO(cais): If uses `useLearningPhase`, set the corresponding element\n      // of the input to 0.\n      const ins = standardizedOuts[0].concat(standardizedOuts[1]);\n      this.makeTestFunction();\n      const f = this.testFunction;\n      const testOuts = this.testLoop(f, ins, batchSize, args.verbose, args.steps);\n      return singletonOrArray(testOuts);\n    } finally {\n      disposeNewTensors(standardizedOuts[0], x);\n      disposeNewTensors(standardizedOuts[1], y);\n    }\n  } // TODO(cais): Add code snippet below once real dataset objects are\n  //   available.\n\n  /**\r\n   * Evaluate model using a dataset object.\r\n   *\r\n   * Note: Unlike `evaluate()`, this method is asynchronous (`async`);\r\n   *\r\n   * @param dataset A dataset object. Its `iterator()` method is expected\r\n   *   to generate a dataset iterator object, the `next()` method of which\r\n   *   is expected to produce data batches for evaluation. The return value\r\n   *   of the `next()` call ought to contain a boolean `done` field and a\r\n   *   `value` field. The `value` field is expected to be an array of two\r\n   *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former\r\n   *   case is for models with exactly one input and one output (e.g..\r\n   *   a sequential model). The latter case is for models with multiple\r\n   *   inputs and/or multiple outputs. Of the two items in the array, the\r\n   *   first is the input feature(s) and the second is the output target(s).\r\n   * @param args A configuration object for the dataset-based evaluation.\r\n   * @returns Loss and metric values as an Array of `Scalar` objects.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n\n\n  async evaluateDataset(dataset, args) {\n    this.makeTestFunction();\n    return evaluateDataset(this, dataset, args);\n  }\n  /**\r\n   * Get number of samples provided for training, evaluation or prediction.\r\n   *\r\n   * @param ins Input `tf.Tensor`.\r\n   * @param batchSize Integer batch size, optional.\r\n   * @param steps Total number of steps (batches of samples) before\r\n   * declaring loop finished. Optional.\r\n   * @param stepsName The public API's parameter name for `steps`.\r\n   * @returns Number of samples provided.\r\n   */\n\n\n  checkNumSamples(ins, batchSize, steps, stepsName = 'steps') {\n    let numSamples;\n\n    if (steps != null) {\n      numSamples = null;\n\n      if (batchSize != null) {\n        throw new ValueError(`If ${stepsName} is set, batchSize must be null or undefined.` + `Got batchSize = ${batchSize}`);\n      }\n    } else if (ins != null) {\n      if (Array.isArray(ins)) {\n        numSamples = ins[0].shape[0];\n      } else {\n        numSamples = ins.shape[0];\n      }\n    } else {\n      throw new ValueError(`Either the input data should have a defined shape, or ` + `${stepsName} shoud be specified.`);\n    }\n\n    return numSamples;\n  }\n  /**\r\n   * Execute internal tensors of the model with input data feed.\r\n   * @param inputs Input data feed. Must match the inputs of the model.\r\n   * @param outputs Names of the output tensors to be fetched. Must match\r\n   *   names of the SymbolicTensors that belong to the graph.\r\n   * @returns Fetched values for `outputs`.\r\n   */\n\n\n  execute(inputs, outputs) {\n    if (Array.isArray(outputs) && outputs.length === 0) {\n      throw new ValueError('`outputs` is an empty Array, which is not allowed.');\n    }\n\n    const outputsIsArray = Array.isArray(outputs);\n    const outputNames = outputsIsArray ? outputs : [outputs];\n    const outputSymbolicTensors = this.retrieveSymbolicTensors(outputNames); // Format the input into a FeedDict.\n\n    const feedDict = new FeedDict();\n\n    if (inputs instanceof Tensor) {\n      inputs = [inputs];\n    }\n\n    if (Array.isArray(inputs)) {\n      if (inputs.length !== this.inputs.length) {\n        throw new ValueError(`The number of inputs provided (${inputs.length}) ` + `does not match the number of inputs of this model ` + `(${this.inputs.length}).`);\n      }\n\n      for (let i = 0; i < this.inputs.length; ++i) {\n        feedDict.add(this.inputs[i], inputs[i]);\n      }\n    } else {\n      for (const input of this.inputs) {\n        const tensorValue = inputs[input.name];\n\n        if (tensorValue == null) {\n          throw new ValueError(`No value is provided for the model's input ${input.name}`);\n        }\n\n        feedDict.add(input, tensorValue);\n      }\n    } // Run execution.\n\n\n    const executeOutputs = execute(outputSymbolicTensors, feedDict);\n    return outputsIsArray ? executeOutputs : executeOutputs[0];\n  }\n  /**\r\n   * Retrieve the model's internal symbolic tensors from symbolic-tensor names.\r\n   */\n\n\n  retrieveSymbolicTensors(symbolicTensorNames) {\n    const outputSymbolicTensors = pyListRepeat(null, symbolicTensorNames.length);\n    let outputsRemaining = symbolicTensorNames.length;\n\n    for (const layer of this.layers) {\n      const layerOutputs = Array.isArray(layer.output) ? layer.output : [layer.output];\n      const layerOutputNames = layerOutputs.map(output => output.name);\n\n      for (let i = 0; i < symbolicTensorNames.length; ++i) {\n        const index = layerOutputNames.indexOf(symbolicTensorNames[i]);\n\n        if (index !== -1) {\n          outputSymbolicTensors[i] = layerOutputs[index];\n          outputsRemaining--;\n        }\n\n        if (outputsRemaining === 0) {\n          break;\n        }\n      }\n\n      if (outputsRemaining === 0) {\n        break;\n      }\n    }\n\n    if (outputsRemaining > 0) {\n      const remainingNames = [];\n      outputSymbolicTensors.forEach((tensor, i) => {\n        if (tensor == null) {\n          remainingNames.push(symbolicTensorNames[i]);\n        }\n      });\n      throw new ValueError(`Cannot find SymbolicTensors for output name(s): ` + `${JSON.stringify(remainingNames)}`);\n    }\n\n    return outputSymbolicTensors;\n  }\n  /**\r\n   * Helper method to loop over some data in batches.\r\n   *\r\n   * Porting Note: Not using the functional approach in the Python equivalent\r\n   *   due to the imperative backend.\r\n   * Porting Note: Does not support step mode currently.\r\n   *\r\n   * @param ins: input data\r\n   * @param batchSize: integer batch size.\r\n   * @param verbose: verbosity model\r\n   * @returns: Predictions as `tf.Tensor` (if a single output) or an `Array` of\r\n   *   `tf.Tensor` (if multipe outputs).\r\n   */\n\n\n  predictLoop(ins, batchSize = 32, verbose = false) {\n    return tfc.tidy(() => {\n      const numSamples = this.checkNumSamples(ins);\n\n      if (verbose) {\n        throw new NotImplementedError('Verbose predictLoop() is not implemented yet.');\n      } // Sample-based predictions.\n      // Porting Note: Tensor currently does not support sliced assignments as\n      //   in numpy, e.g., x[1:3] = y. Therefore we use concatenation while\n      //   iterating over the batches.\n\n\n      const batches = makeBatches(numSamples, batchSize);\n      const outsBatches = this.outputs.map(output => []); // TODO(cais): Can the scope() be pushed down inside the for loop?\n\n      for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n        const batchOuts = tfc.tidy(() => {\n          const batchStart = batches[batchIndex][0];\n          const batchEnd = batches[batchIndex][1]; // TODO(cais): Take care of the case of the last element is a flag for\n          //   training/test.\n\n          const insBatch = sliceArrays(ins, batchStart, batchEnd); // Construct the feeds for execute();\n\n          const feeds = [];\n\n          if (Array.isArray(insBatch)) {\n            for (let i = 0; i < insBatch.length; ++i) {\n              feeds.push({\n                key: this.inputs[i],\n                value: insBatch[i]\n              });\n            }\n          } else {\n            feeds.push({\n              key: this.inputs[0],\n              value: insBatch\n            });\n          }\n\n          const feedDict = new FeedDict(feeds);\n          return execute(this.outputs, feedDict);\n        });\n        batchOuts.forEach((batchOut, i) => outsBatches[i].push(batchOut));\n      }\n\n      return singletonOrArray(outsBatches.map(batches => tfc.concat(batches, 0)));\n    });\n  }\n  /**\r\n   * Generates output predictions for the input samples.\r\n   *\r\n   * Computation is done in batches.\r\n   *\r\n   * Note: the \"step\" mode of predict() is currently not supported.\r\n   *   This is because the TensorFlow.js core backend is imperative only.\r\n   *\r\n   * ```js\r\n   * const model = tf.sequential({\r\n   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\r\n   * });\r\n   * model.predict(tf.ones([8, 10]), {batchSize: 4}).print();\r\n   * ```\r\n   *\r\n   * @param x The input data, as a Tensor, or an `Array` of `tf.Tensor`s if\r\n   *   the model has multiple inputs.\r\n   * @param args A `ModelPredictArgs` object containing optional fields.\r\n   *\r\n   * @return Prediction results as a `tf.Tensor`(s).\r\n   *\r\n   * @exception ValueError In case of mismatch between the provided input data\r\n   *   and the model's expectations, or in case a stateful model receives a\r\n   *   number of samples that is not a multiple of the batch size.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n\n\n  predict(x, args = {}) {\n    const xsRank2OrHigher = ensureTensorsRank2OrHigher(x);\n    checkInputData(xsRank2OrHigher, this.inputNames, this.feedInputShapes, false);\n\n    try {\n      // TODO(cais): Take care of stateful models.\n      //   if (this.stateful) ...\n      // TODO(cais): Take care of the learning_phase boolean flag.\n      //   if (this.useLearningPhase) ...\n      const batchSize = args.batchSize == null ? 32 : args.batchSize;\n      checkBatchSize(batchSize);\n      return this.predictLoop(xsRank2OrHigher, batchSize);\n    } finally {\n      disposeNewTensors(xsRank2OrHigher, x);\n    }\n  }\n  /**\r\n   * Returns predictions for a single batch of samples.\r\n   *\r\n   * ```js\r\n   * const model = tf.sequential({\r\n   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\r\n   * });\r\n   * model.predictOnBatch(tf.ones([8, 10])).print();\r\n   * ```\r\n   * @param x: Input samples, as a Tensor (for models with exactly one\r\n   *   input) or an array of Tensors (for models with more than one input).\r\n   * @return Tensor(s) of predictions\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n\n\n  predictOnBatch(x) {\n    checkInputData(x, this.inputNames, this.feedInputShapes, true); // TODO(cais): Take care of the learning_phase boolean flag.\n    //   if (this.useLearningPhase) ...\n\n    const batchSize = (Array.isArray(x) ? x[0] : x).shape[0];\n    return this.predictLoop(x, batchSize);\n  }\n\n  standardizeUserDataXY(x, y, checkBatchAxis = true, batchSize) {\n    // TODO(cais): Add sampleWeight, classWeight\n    if (this.optimizer_ == null) {\n      throw new RuntimeError('You must compile a model before training/testing. Use ' + 'LayersModel.compile(modelCompileArgs).');\n    }\n\n    const outputShapes = [];\n\n    for (let i = 0; i < this.feedOutputShapes.length; ++i) {\n      const outputShape = this.feedOutputShapes[i];\n      const lossFn = this.feedLossFns[i];\n\n      if (lossFn === losses.sparseCategoricalCrossentropy) {\n        outputShapes.push(outputShape.slice(0, outputShape.length - 1).concat([1]));\n      } else {\n        // Porting Note: Because of strong typing `lossFn` must be a function.\n        outputShapes.push(outputShape);\n      }\n    }\n\n    x = standardizeInputData(x, this.feedInputNames, this.feedInputShapes, false, 'input');\n    y = standardizeInputData(y, this.feedOutputNames, outputShapes, false, 'target'); // TODO(cais): Standardize sampleWeights & classWeights.\n\n    checkArrayLengths(x, y, null); // TODO(cais): Check sampleWeights as well.\n\n    checkLossAndTargetCompatibility(y, this.feedLossFns, this.feedOutputShapes);\n\n    if (this.stateful && batchSize != null && batchSize > 0) {\n      if (x[0].shape[0] % batchSize !== 0) {\n        throw new ValueError(`In a stateful network, you should only pass inputs with a ` + `number of samples that is divisible by the batch size ` + `${batchSize}. Found: ${x[0].shape[0]} sample(s).`);\n      }\n    }\n\n    return [x, y];\n  }\n\n  async standardizeUserData(x, y, sampleWeight, classWeight, checkBatchAxis = true, batchSize) {\n    const [standardXs, standardYs] = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize); // TODO(cais): Handle sampleWeights.\n\n    if (sampleWeight != null) {\n      throw new Error('sample weight is not supported yet.');\n    }\n\n    let standardSampleWeights = null;\n\n    if (classWeight != null) {\n      const classWeights = standardizeClassWeights(classWeight, this.outputNames);\n      standardSampleWeights = [];\n\n      for (let i = 0; i < classWeights.length; ++i) {\n        standardSampleWeights.push(await standardizeWeights(standardYs[i], null, classWeights[i]));\n      }\n    } // TODO(cais): Deal with the case of model.stateful == true.\n\n\n    return [standardXs, standardYs, standardSampleWeights];\n  }\n  /**\r\n   * Loop over some test data in batches.\r\n   * @param f A Function returning a list of tensors.\r\n   * @param ins Array of tensors to be fed to `f`.\r\n   * @param batchSize Integer batch size or `null` / `undefined`.\r\n   * @param verbose verbosity mode.\r\n   * @param steps Total number of steps (batches of samples) before\r\n   * declaring test finished. Ignored with the default value of `null` /\r\n   * `undefined`.\r\n   * @returns Array of Scalars.\r\n   */\n\n\n  testLoop(f, ins, batchSize, verbose = 0, steps) {\n    return tfc.tidy(() => {\n      const numSamples = this.checkNumSamples(ins, batchSize, steps, 'steps');\n      const outs = [];\n\n      if (verbose > 0) {\n        throw new NotImplementedError('Verbose mode is not implemented yet.');\n      } // TODO(cais): Use `indicesForConversionToDense' to prevent slow down.\n\n\n      if (steps != null) {\n        throw new NotImplementedError('steps mode in testLoop() is not implemented yet');\n      } else {\n        const batches = makeBatches(numSamples, batchSize);\n        const indexArray = tensor1d(range(0, numSamples));\n\n        for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n          const batchStart = batches[batchIndex][0];\n          const batchEnd = batches[batchIndex][1];\n          const batchIds = K.sliceAlongFirstAxis(indexArray, batchStart, batchEnd - batchStart); // TODO(cais): In ins, train flag can be a number, instead of an\n          //   Tensor? Do we need to handle this in tfjs-layers?\n\n          const insBatch = sliceArraysByIndices(ins, batchIds);\n          const batchOuts = f(insBatch);\n\n          if (batchIndex === 0) {\n            for (let i = 0; i < batchOuts.length; ++i) {\n              outs.push(scalar(0));\n            }\n          }\n\n          for (let i = 0; i < batchOuts.length; ++i) {\n            const batchOut = batchOuts[i];\n            outs[i] = tfc.add(outs[i], tfc.mul(batchEnd - batchStart, batchOut));\n          }\n        }\n\n        for (let i = 0; i < outs.length; ++i) {\n          outs[i] = tfc.div(outs[i], numSamples);\n        }\n      }\n\n      return outs;\n    });\n  }\n\n  getDedupedMetricsNames() {\n    const outLabels = this.metricsNames; // Rename duplicated metrics names (can happen with an output layer\n    // shared among multiple dataflows).\n\n    const dedupedOutLabels = [];\n\n    for (let i = 0; i < outLabels.length; ++i) {\n      const label = outLabels[i];\n      let newLabel = label;\n\n      if (count(outLabels, label) > 1) {\n        const dupIndex = count(outLabels.slice(0, i), label);\n        newLabel += `_${dupIndex}`;\n      }\n\n      dedupedOutLabels.push(newLabel);\n    }\n\n    return dedupedOutLabels;\n  }\n  /**\r\n   * Creates a function that performs the following actions:\r\n   *\r\n   * 1. computes the losses\r\n   * 2. sums them to get the total loss\r\n   * 3. call the optimizer computes the gradients of the LayersModel's\r\n   *    trainable weights w.r.t. the total loss and update the variables\r\n   * 4. calculates the metrics\r\n   * 5. returns the values of the losses and metrics.\r\n   */\n\n\n  makeTrainFunction() {\n    return data => {\n      const lossValues = [];\n      const inputs = data.slice(0, this.inputs.length);\n      const targets = data.slice(this.inputs.length, this.inputs.length + this.outputs.length);\n      const sampleWeights = data.slice(this.inputs.length + this.outputs.length, this.inputs.length + this.outputs.length * 2);\n      const metricsValues = []; // Create a function that computes the total loss based on the\n      // inputs. This function is used for obtaining gradients through\n      // backprop.\n\n      const totalLossFunction = () => {\n        const feeds = [];\n\n        for (let i = 0; i < this.inputs.length; ++i) {\n          feeds.push({\n            key: this.inputs[i],\n            value: inputs[i]\n          });\n        }\n\n        const feedDict = new FeedDict(feeds);\n        const outputs = execute(this.outputs, feedDict, {\n          'training': true\n        }); // TODO(cais): Take care of the case of multiple outputs from a\n        //   single layer?\n\n        let totalLoss;\n\n        for (let i = 0; i < this.lossFunctions.length; ++i) {\n          const lossFunction = this.lossFunctions[i];\n          let loss = lossFunction(targets[i], outputs[i]);\n\n          if (sampleWeights[i] != null) {\n            loss = computeWeightedLoss(loss, sampleWeights[i]);\n          } // TODO(cais): push Scalar instead.\n\n\n          const meanLoss = tfc.mean(loss); // TODO(cais): Use a scope() instead, to avoid ownership.\n\n          lossValues.push(meanLoss);\n\n          if (i === 0) {\n            totalLoss = loss;\n          } else {\n            totalLoss = tfc.add(totalLoss, loss);\n          }\n        } // Compute the metrics.\n        // TODO(cais): These should probably be calculated outside\n        //   totalLossFunction to benefit speed?\n\n\n        for (let i = 0; i < this.metricsTensors.length; ++i) {\n          let weightedMetric;\n\n          if (this.outputs.length > 1 && i < this.outputs.length) {\n            weightedMetric = lossValues[i];\n          } else {\n            const metric = this.metricsTensors[i][0];\n            const outputIndex = this.metricsTensors[i][1];\n            weightedMetric = tfc.mean(metric(targets[outputIndex], outputs[outputIndex]));\n          }\n\n          tfc.keep(weightedMetric); // TODO(cais): Use a scope() instead, to avoid ownership.\n\n          metricsValues.push(weightedMetric);\n        }\n\n        totalLoss = tfc.mean(totalLoss); // Add regularizer penalties.\n\n        this.calculateLosses().forEach(regularizerLoss => {\n          totalLoss = tfc.add(totalLoss, regularizerLoss);\n        });\n        return totalLoss;\n      };\n\n      const variables = this.collectedTrainableWeights.map(param => param.read());\n      const returnCost = true;\n      const totalLossValue = this.optimizer_.minimize(totalLossFunction, returnCost, variables);\n      return [totalLossValue].concat(metricsValues);\n    };\n  }\n  /**\r\n   * Create a function which, when invoked with an array of `tf.Tensor`s as a\r\n   * batch of inputs, returns the prespecified loss and metrics of the model\r\n   * under the batch of input data.\r\n   */\n\n\n  makeTestFunction() {\n    this.testFunction = data => {\n      return tfc.tidy(() => {\n        const valOutputs = [];\n        let totalLoss;\n        const inputs = data.slice(0, this.inputs.length);\n        const targets = data.slice(this.inputs.length, this.inputs.length + this.outputs.length);\n        const feeds = [];\n\n        for (let i = 0; i < this.inputs.length; ++i) {\n          feeds.push({\n            key: this.inputs[i],\n            value: inputs[i]\n          });\n        }\n\n        const feedDict = new FeedDict(feeds);\n        const outputs = execute(this.outputs, feedDict); // Compute total loss.\n\n        for (let i = 0; i < this.lossFunctions.length; ++i) {\n          const lossFunction = this.lossFunctions[i]; // TODO(cais): Add sample weighting and replace the simple\n          // averaging.\n\n          const loss = tfc.mean(lossFunction(targets[i], outputs[i]));\n\n          if (i === 0) {\n            totalLoss = loss;\n          } else {\n            totalLoss = tfc.add(totalLoss, loss);\n          }\n\n          valOutputs.push(totalLoss);\n        } // Compute the metrics.\n\n\n        for (let i = 0; i < this.metricsTensors.length; ++i) {\n          const metric = this.metricsTensors[i][0];\n          const outputIndex = this.metricsTensors[i][1]; // TODO(cais): Replace K.mean() with a proper weighting function.\n\n          const meanMetric = tfc.mean(metric(targets[outputIndex], outputs[outputIndex]));\n          valOutputs.push(meanMetric);\n        }\n\n        return valOutputs;\n      });\n    };\n  }\n  /**\r\n   * Trains the model for a fixed number of epochs (iterations on a\r\n   * dataset).\r\n   *\r\n   * ```js\r\n   * const model = tf.sequential({\r\n   *     layers: [tf.layers.dense({units: 1, inputShape: [10]})]\r\n   * });\r\n   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\r\n   * for (let i = 1; i < 5 ; ++i) {\r\n   *   const h = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), {\r\n   *       batchSize: 4,\r\n   *       epochs: 3\r\n   *   });\r\n   *   console.log(\"Loss after Epoch \" + i + \" : \" + h.history.loss[0]);\r\n   * }\r\n   * ```\r\n   *\r\n   * @param x `tf.Tensor` of training data, or an array of `tf.Tensor`s if the\r\n   * model has multiple inputs. If all inputs in the model are named, you\r\n   * can also pass a dictionary mapping input names to `tf.Tensor`s.\r\n   * @param y `tf.Tensor` of target (label) data, or an array of `tf.Tensor`s if\r\n   * the model has multiple outputs. If all outputs in the model are named,\r\n   * you can also pass a dictionary mapping output names to `tf.Tensor`s.\r\n   * @param args A `ModelFitArgs`, containing optional fields.\r\n   *\r\n   * @return A `History` instance. Its `history` attribute contains all\r\n   *   information collected during training.\r\n   *\r\n   * @exception ValueError In case of mismatch between the provided input\r\n   * data and what the model expects.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n\n\n  async fit(x, y, args = {}) {\n    return fitTensors(this, x, y, args);\n  } // TODO(cais): Add code snippet below when it's possible to instantiate\n  //   actual dataset objects.\n\n  /**\r\n   * Trains the model using a dataset object.\r\n   *\r\n   * @param dataset A dataset object. Its `iterator()` method is expected\r\n   *   to generate a dataset iterator object, the `next()` method of which\r\n   *   is expected to produce data batches for training. The return value\r\n   *   of the `next()` call ought to contain a boolean `done` field and a\r\n   *   `value` field. The `value` field is expected to be an array of two\r\n   *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former\r\n   *   case is for models with exactly one input and one output (e.g..\r\n   *   a sequential model). The latter case is for models with multiple\r\n   *   inputs and/or multiple outputs.\r\n   *   Of the two items in the array, the first is the input feature(s) and\r\n   *   the second is the output target(s).\r\n   * @param args A `ModelFitDatasetArgs`, containing optional fields.\r\n   *\r\n   * @return A `History` instance. Its `history` attribute contains all\r\n   *   information collected during training.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n\n\n  async fitDataset(dataset, args) {\n    return fitDataset(this, dataset, args);\n  }\n  /**\r\n   * Runs a single gradient update on a single batch of data.\r\n   *\r\n   * This method differs from `fit()` and `fitDataset()` in the following\r\n   * regards:\r\n   *   - It operates on exactly one batch of data.\r\n   *   - It returns only the loss and matric values, instead of\r\n   *     returning the batch-by-batch loss and metric values.\r\n   *   - It doesn't support fine-grained options such as verbosity and\r\n   *     callbacks.\r\n   *\r\n   * @param x Input data. It could be one of the following:\r\n   *   - A `tf.Tensor`, or an Array of `tf.Tensor`s (in case the model has\r\n   *     multiple inputs).\r\n   *   - An Object mapping input names to corresponding `tf.Tensor` (if the\r\n   *     model has named inputs).\r\n   * @param y Target darta. It could be either a `tf.Tensor` a multiple\r\n   *   `tf.Tensor`s. It should be consistent with `x`.\r\n   * @returns Training loss or losses (in case the model has\r\n   *   multiple outputs), along with metrics (if any), as numbers.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes'}\r\n   */\n\n\n  async trainOnBatch(x, y) {\n    // TODO(cais): Support sampleWeight and classWeight.\n    // TODO(cais): Support Dataset objects.\n    const standardizeOut = await this.standardizeUserData(x, y);\n    const inputs = standardizeOut[0];\n    const targets = standardizeOut[1];\n    const trainFunction = this.makeTrainFunction();\n    const losses = trainFunction(inputs.concat(targets));\n    const lossValues = [];\n\n    for (const loss of losses) {\n      const v = await loss.data();\n      lossValues.push(v[0]);\n    }\n\n    tfc.dispose(losses);\n    return singletonOrArray(lossValues);\n  }\n  /**\r\n   * Extract weight values of the model.\r\n   *\r\n   * @param config: An instance of `io.SaveConfig`, which specifies\r\n   * model-saving options such as whether only trainable weights are to be\r\n   * saved.\r\n   * @returns A `NamedTensorMap` mapping original weight names (i.e.,\r\n   *   non-uniqueified weight names) to their values.\r\n   */\n\n\n  getNamedWeights(config) {\n    const namedWeights = [];\n    const trainableOnly = config != null && config.trainableOnly;\n    const weights = trainableOnly ? this.trainableWeights : this.weights;\n    const weightValues = this.getWeights(trainableOnly);\n\n    for (let i = 0; i < weights.length; ++i) {\n      if (trainableOnly && !weights[i].trainable) {\n        // Optionally skip non-trainable weights.\n        continue;\n      }\n\n      namedWeights.push({\n        name: weights[i].originalName,\n        tensor: weightValues[i]\n      });\n    }\n\n    return namedWeights;\n  }\n  /**\r\n   * Setter used for force stopping of LayersModel.fit() (i.e., training).\r\n   *\r\n   * Example:\r\n   *\r\n   * ```js\r\n   * const input = tf.input({shape: [10]});\r\n   * const output = tf.layers.dense({units: 1}).apply(input);\r\n   * const model = tf.model({inputs: [input], outputs: [output]});\r\n   * model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\r\n   * const xs = tf.ones([8, 10]);\r\n   * const ys = tf.zeros([8, 1]);\r\n   *\r\n   * const history = await model.fit(xs, ys, {\r\n   *   epochs: 10,\r\n   *   callbacks: {\r\n   *     onEpochEnd: async (epoch, logs) => {\r\n   *       if (epoch === 2) {\r\n   *         model.stopTraining = true;\r\n   *       }\r\n   *     }\r\n   *   }\r\n   * });\r\n   *\r\n   * // There should be only 3 values in the loss array, instead of 10\r\n   * values,\r\n   * // due to the stopping after 3 epochs.\r\n   * console.log(history.history.loss);\r\n   * ```\r\n   */\n\n\n  set stopTraining(stop) {\n    this.stopTraining_ = stop;\n  }\n\n  get stopTraining() {\n    return this.stopTraining_;\n  }\n\n  get optimizer() {\n    return this.optimizer_;\n  }\n\n  set optimizer(optimizer) {\n    if (this.optimizer_ !== optimizer) {\n      this.optimizer_ = optimizer;\n      this.isOptimizerOwned = false;\n    }\n  }\n\n  dispose() {\n    const result = super.dispose();\n\n    if (result.refCountAfterDispose === 0 && this.optimizer != null && this.isOptimizerOwned) {\n      const numTensorsBeforeOptmizerDisposal = tfc.memory().numTensors;\n      this.optimizer_.dispose();\n      result.numDisposedVariables += numTensorsBeforeOptmizerDisposal - tfc.memory().numTensors;\n    }\n\n    return result;\n  }\n\n  getLossIdentifiers() {\n    let lossNames;\n\n    if (typeof this.loss === 'string') {\n      lossNames = toSnakeCase(this.loss);\n    } else if (Array.isArray(this.loss)) {\n      for (const loss of this.loss) {\n        if (typeof loss !== 'string') {\n          throw new Error('Serialization of non-string loss is not supported.');\n        }\n      }\n\n      lossNames = this.loss.map(name => toSnakeCase(name));\n    } else {\n      const outputNames = Object.keys(this.loss);\n      lossNames = {};\n      const losses = this.loss;\n\n      for (const outputName of outputNames) {\n        if (typeof losses[outputName] === 'string') {\n          lossNames[outputName] = toSnakeCase(losses[outputName]);\n        } else {\n          throw new Error('Serialization of non-string loss is not supported.');\n        }\n      }\n    }\n\n    return lossNames;\n  }\n\n  getMetricIdentifiers() {\n    if (typeof this.metrics === 'string' || typeof this.metrics === 'function') {\n      return [toSnakeCase(Metrics.getLossOrMetricName(this.metrics))];\n    } else if (Array.isArray(this.metrics)) {\n      return this.metrics.map(metric => toSnakeCase(Metrics.getLossOrMetricName(metric)));\n    } else {\n      const metricsIdentifiers = {};\n\n      for (const key in this.metrics) {\n        metricsIdentifiers[key] = toSnakeCase(Metrics.getLossOrMetricName(this.metrics[key]));\n      }\n\n      return metricsIdentifiers;\n    }\n  }\n\n  getTrainingConfig() {\n    return {\n      loss: this.getLossIdentifiers(),\n      metrics: this.getMetricIdentifiers(),\n      optimizer_config: {\n        class_name: this.optimizer.getClassName(),\n        config: this.optimizer.getConfig()\n      }\n    }; // TODO(cais): Add weight_metrics when they are supported.\n    // TODO(cais): Add sample_weight_mode when it's supported.\n    // TODO(cais): Add loss_weights when it's supported.\n  }\n\n  loadTrainingConfig(trainingConfig) {\n    if (trainingConfig.weighted_metrics != null) {\n      throw new Error('Loading weight_metrics is not supported yet.');\n    }\n\n    if (trainingConfig.loss_weights != null) {\n      throw new Error('Loading loss_weights is not supported yet.');\n    }\n\n    if (trainingConfig.sample_weight_mode != null) {\n      throw new Error('Loading sample_weight_mode is not supported yet.');\n    }\n\n    const tsConfig = convertPythonicToTs(trainingConfig.optimizer_config);\n    const optimizer = deserialize(tsConfig);\n    let loss;\n\n    if (typeof trainingConfig.loss === 'string') {\n      loss = toCamelCase(trainingConfig.loss);\n    } else if (Array.isArray(trainingConfig.loss)) {\n      loss = trainingConfig.loss.map(lossEntry => toCamelCase(lossEntry));\n    } else if (trainingConfig.loss != null) {\n      loss = {};\n\n      for (const key in trainingConfig.loss) {\n        loss[key] = toCamelCase(trainingConfig.loss[key]);\n      }\n    }\n\n    let metrics;\n\n    if (Array.isArray(trainingConfig.metrics)) {\n      metrics = trainingConfig.metrics.map(metric => toCamelCase(metric));\n    } else if (trainingConfig.metrics != null) {\n      metrics = {};\n\n      for (const key in trainingConfig.metrics) {\n        metrics[key] = toCamelCase(trainingConfig.metrics[key]);\n      }\n    }\n\n    this.compile({\n      loss,\n      metrics,\n      optimizer\n    });\n  }\n  /**\r\n   * Save the configuration and/or weights of the LayersModel.\r\n   *\r\n   * An `IOHandler` is an object that has a `save` method of the proper\r\n   * signature defined. The `save` method manages the storing or\r\n   * transmission of serialized data (\"artifacts\") that represent the\r\n   * model's topology and weights onto or via a specific medium, such as\r\n   * file downloads, local storage, IndexedDB in the web browser and HTTP\r\n   * requests to a server. TensorFlow.js provides `IOHandler`\r\n   * implementations for a number of frequently used saving mediums, such as\r\n   * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`\r\n   * for more details.\r\n   *\r\n   * This method also allows you to refer to certain types of `IOHandler`s\r\n   * as URL-like string shortcuts, such as 'localstorage://' and\r\n   * 'indexeddb://'.\r\n   *\r\n   * Example 1: Save `model`'s topology and weights to browser [local\r\n   * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);\r\n   * then load it back.\r\n   *\r\n   * ```js\r\n   * const model = tf.sequential(\r\n   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\r\n   * console.log('Prediction from original model:');\r\n   * model.predict(tf.ones([1, 3])).print();\r\n   *\r\n   * const saveResults = await model.save('localstorage://my-model-1');\r\n   *\r\n   * const loadedModel = await tf.loadLayersModel('localstorage://my-model-1');\r\n   * console.log('Prediction from loaded model:');\r\n   * loadedModel.predict(tf.ones([1, 3])).print();\r\n   * ```\r\n   *\r\n   * Example 2. Saving `model`'s topology and weights to browser\r\n   * [IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API);\r\n   * then load it back.\r\n   *\r\n   * ```js\r\n   * const model = tf.sequential(\r\n   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\r\n   * console.log('Prediction from original model:');\r\n   * model.predict(tf.ones([1, 3])).print();\r\n   *\r\n   * const saveResults = await model.save('indexeddb://my-model-1');\r\n   *\r\n   * const loadedModel = await tf.loadLayersModel('indexeddb://my-model-1');\r\n   * console.log('Prediction from loaded model:');\r\n   * loadedModel.predict(tf.ones([1, 3])).print();\r\n   * ```\r\n   *\r\n   * Example 3. Saving `model`'s topology and weights as two files\r\n   * (`my-model-1.json` and `my-model-1.weights.bin`) downloaded from\r\n   * browser.\r\n   *\r\n   * ```js\r\n   * const model = tf.sequential(\r\n   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\r\n   * const saveResults = await model.save('downloads://my-model-1');\r\n   * ```\r\n   *\r\n   * Example 4. Send  `model`'s topology and weights to an HTTP server.\r\n   * See the documentation of `tf.io.http` for more details\r\n   * including specifying request parameters and implementation of the\r\n   * server.\r\n   *\r\n   * ```js\r\n   * const model = tf.sequential(\r\n   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\r\n   * const saveResults = await model.save('http://my-server/model/upload');\r\n   * ```\r\n   *\r\n   * @param handlerOrURL An instance of `IOHandler` or a URL-like,\r\n   * scheme-based string shortcut for `IOHandler`.\r\n   * @param config Options for saving the model.\r\n   * @returns A `Promise` of `SaveResult`, which summarizes the result of\r\n   * the saving, such as byte sizes of the saved artifacts for the model's\r\n   *   topology and weight values.\r\n   *\r\n   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\r\n   */\n\n\n  async save(handlerOrURL, config) {\n    if (typeof handlerOrURL === 'string') {\n      const handlers = io.getSaveHandlers(handlerOrURL);\n\n      if (handlers.length === 0) {\n        throw new ValueError(`Cannot find any save handlers for URL '${handlerOrURL}'`);\n      } else if (handlers.length > 1) {\n        throw new ValueError(`Found more than one (${handlers.length}) save handlers for ` + `URL '${handlerOrURL}'`);\n      }\n\n      handlerOrURL = handlers[0];\n    }\n\n    if (handlerOrURL.save == null) {\n      throw new ValueError('LayersModel.save() cannot proceed because the IOHandler ' + 'provided does not have the `save` attribute defined.');\n    }\n\n    const weightDataAndSpecs = await io.encodeWeights(this.getNamedWeights(config));\n    const returnString = false;\n    const unusedArg = null;\n    const modelConfig = this.toJSON(unusedArg, returnString);\n    const modelArtifacts = {\n      modelTopology: modelConfig,\n      format: LAYERS_MODEL_FORMAT_NAME,\n      generatedBy: `TensorFlow.js tfjs-layers v${version}`,\n      convertedBy: null\n    };\n    const includeOptimizer = config == null ? false : config.includeOptimizer;\n\n    if (includeOptimizer && this.optimizer != null) {\n      modelArtifacts.trainingConfig = this.getTrainingConfig();\n      const weightType = 'optimizer';\n      const {\n        data: optimizerWeightData,\n        specs: optimizerWeightSpecs\n      } = await io.encodeWeights(await this.optimizer.getWeights(), weightType);\n      weightDataAndSpecs.specs.push(...optimizerWeightSpecs);\n      weightDataAndSpecs.data = io.concatenateArrayBuffers([weightDataAndSpecs.data, optimizerWeightData]);\n    }\n\n    if (this.userDefinedMetadata != null) {\n      // Check serialized size of user-defined metadata.\n      const checkSize = true;\n      checkUserDefinedMetadata(this.userDefinedMetadata, this.name, checkSize);\n      modelArtifacts.userDefinedMetadata = this.userDefinedMetadata;\n    }\n\n    modelArtifacts.weightData = weightDataAndSpecs.data;\n    modelArtifacts.weightSpecs = weightDataAndSpecs.specs;\n    return handlerOrURL.save(modelArtifacts);\n  }\n  /**\r\n   * Set user-defined metadata.\r\n   *\r\n   * The set metadata will be serialized together with the topology\r\n   * and weights of the model during `save()` calls.\r\n   *\r\n   * @param setUserDefinedMetadata\r\n   */\n\n\n  setUserDefinedMetadata(userDefinedMetadata) {\n    checkUserDefinedMetadata(userDefinedMetadata, this.name);\n    this.userDefinedMetadata = userDefinedMetadata;\n  }\n  /**\r\n   * Get user-defined metadata.\r\n   *\r\n   * The metadata is supplied via one of the two routes:\r\n   *   1. By calling `setUserDefinedMetadata()`.\r\n   *   2. Loaded during model loading (if the model is constructed\r\n   *      via `tf.loadLayersModel()`.)\r\n   *\r\n   * If no user-defined metadata is available from either of the\r\n   * two routes, this function will return `undefined`.\r\n   */\n\n\n  getUserDefinedMetadata() {\n    return this.userDefinedMetadata;\n  }\n\n} // The class name is 'Model' rather than 'LayersModel' for backwards\n// compatibility since this class name shows up in the serialization format.\n\n/** @nocollapse */\n\nLayersModel.className = 'Model';\nserialization.registerClass(LayersModel);\n/**\r\n * A `tf.Functional` is an alias to `tf.LayersModel`.\r\n *\r\n * See also:\r\n *   `tf.LayersModel`, `tf.Sequential`, `tf.loadLayersModel`.\r\n */\n\n/** @doc {heading: 'Models', subheading: 'Classes'} */\n\nexport class Functional extends LayersModel {}\nFunctional.className = 'Functional';\nserialization.registerClass(Functional);","map":{"version":3,"sources":["../../../../../../tfjs-layers/src/engine/training.ts"],"names":[],"mappings":"AAAA;;;;;;;;AAQG;;AAEH;AAEA,OAAO,KAAK,GAAZ,MAAqB,uBAArB;AACA,SAAQ,EAAR,EAAoE,SAApE,EAAuF,MAAvF,EAA+F,aAA/F,EAA8G,MAA9G,EAAgI,QAAhI,EAA0I,IAA1I,QAAqJ,uBAArJ;AAEA,OAAO,KAAK,CAAZ,MAAmB,yBAAnB;AAEA,SAAQ,SAAR,QAAwB,WAAxB;AACA,SAAQ,mBAAR,EAA6B,YAA7B,EAA2C,UAA3C,QAA4D,WAA5D;AAKA,SAAQ,WAAR,QAA0B,yBAA1B;AACA,OAAO,KAAK,MAAZ,MAAwB,WAAxB;AACA,OAAO,KAAK,OAAZ,MAAyB,YAAzB;AACA,OAAO,KAAK,UAAZ,MAA4B,eAA5B;AAEA,SAAQ,wBAAR,QAAuC,0BAAvC;AACA,SAAQ,KAAR,EAAe,YAAf,EAA6B,gBAA7B,EAA+C,WAA/C,EAA4D,WAA5D,EAAyE,MAAzE,QAAsF,wBAAtF;AACA,SAAQ,YAAR,QAA2B,sBAA3B;AACA,SAAQ,KAAR,QAAoB,qBAApB;AACA,SAAQ,mBAAR,QAAkC,8BAAlC;AAEA,SAAQ,OAAR,QAAsB,YAAtB;AAEA,SAAQ,SAAR,QAAuC,aAAvC;AAEA,SAAQ,OAAR,EAAiB,QAAjB,QAAgC,YAAhC;AAEA,SAAQ,eAAR,EAAyB,UAAzB,QAAyF,oBAAzF;AACA,SAAQ,cAAR,EAAwB,iBAAxB,EAA2C,0BAA3C,EAAuE,UAAvE,EAAmF,WAAnF,EAA8G,WAA9G,EAA2H,oBAA3H,QAAsJ,oBAAtJ;AACA,SAAqC,mBAArC,EAA0D,uBAA1D,EAAmF,kBAAnF,QAA4G,kBAA5G;AAEA;;AAEG;;AACH,OAAM,SAAU,YAAV,CAAuB,CAAvB,EACsD;AAC1D,SAAO,CAAC,YAAY,MAApB;AACD;AAED;;AAEG;;AACH,OAAM,SAAU,WAAV,CAAsB,CAAtB,EACmD;AACvD,SAAO,KAAK,CAAC,OAAN,CAAc,CAAd,CAAP;AACD;AAED;;AAEG;;AACH,OAAM,SAAU,UAAV,CAAqB,CAArB,EACkD;AACtD,SAAO,CAAC,YAAY,CAAC,CAAD,CAAb,IAAoB,CAAC,WAAW,CAAC,CAAD,CAAvC;AACD;AAED;;;;;;;;;;AAUG;;AACH,OAAM,SAAU,oBAAV,CACF,IADE,EACmD,KADnD,EAEF,MAFE,EAEgB,cAAc,GAAG,IAFjC,EAEuC,eAAe,GAAG,EAFzD,EAE2D;AAC/D,MAAI,KAAK,IAAI,IAAT,IAAiB,KAAK,CAAC,MAAN,KAAiB,CAAtC,EAAyC;AACvC;AACA;AACA,QAAI,IAAI,IAAI,IAAZ,EAAkB;AAChB,UAAI,iBAAiB,GAAG,KAAxB;;AACA,UAAI,WAAW,CAAC,IAAD,CAAX,IAAsB,IAAiB,CAAC,MAAlB,GAA2B,CAArD,EAAwD;AACtD,QAAA,iBAAiB,GAAG,IAApB;AACD,OAFD,MAEO,IAAI,UAAU,CAAC,IAAD,CAAd,EAAsB;AAC3B,aAAK,MAAM,GAAX,IAAkB,IAAlB,EAAwB;AACtB,cAAI,IAAI,CAAC,cAAL,CAAoB,GAApB,CAAJ,EAA8B;AAC5B,YAAA,iBAAiB,GAAG,IAApB;AACA;AACD;AACF;AACF,OAPM,MAOA;AACL;AACA,QAAA,iBAAiB,GAAG,IAApB;AACD;;AACD,UAAI,iBAAJ,EAAuB;AACrB,cAAM,IAAI,UAAJ,CACF,6BAA6B,eAAe,qBAA5C,GACA,WAAW,IAAI,EAFb,CAAN;AAGD;AACF;;AACD,WAAO,EAAP;AACD;;AACD,MAAI,IAAI,IAAI,IAAZ,EAAkB;AAChB,WAAO,KAAK,CAAC,GAAN,CAAU,IAAI,IAAI,IAAlB,CAAP;AACD;;AAED,MAAI,MAAJ;;AACA,MAAI,UAAU,CAAC,IAAD,CAAd,EAAsB;AACpB,IAAA,IAAI,GAAG,IAAP;AACA,IAAA,MAAM,GAAG,EAAT;;AACA,SAAK,MAAM,IAAX,IAAmB,KAAnB,EAA0B;AACxB,UAAI,IAAI,CAAC,IAAD,CAAJ,IAAc,IAAlB,EAAwB;AACtB,cAAM,IAAI,UAAJ,CACF,yBAAyB,IAAI,gCAA7B,GACA,GAAG,KAAK,EAFN,CAAN;AAGD;;AACD,MAAA,MAAM,CAAC,IAAP,CAAY,IAAI,CAAC,IAAD,CAAhB;AACD;AACF,GAXD,MAWO,IAAI,WAAW,CAAC,IAAD,CAAf,EAAuB;AAC5B,IAAA,IAAI,GAAG,IAAP;;AACA,QAAI,IAAI,CAAC,MAAL,KAAgB,KAAK,CAAC,MAA1B,EAAkC;AAChC,YAAM,IAAI,UAAJ,CACF,6BAA6B,eAAe,iBAA5C,GACA,iEADA,GAEA,mCAAmC,KAAK,CAAC,MAAM,kBAF/C,GAGA,gDAAgD,IAAI,EAJlD,CAAN;AAKD;;AACD,IAAA,MAAM,GAAG,IAAT;AACD,GAVM,MAUA;AACL,IAAA,IAAI,GAAG,IAAP;;AACA,QAAI,KAAK,CAAC,MAAN,GAAe,CAAnB,EAAsB;AACpB,YAAM,IAAI,UAAJ,CACF,aAAa,eAAe,YAAY,KAAK,CAAC,MAAM,cAApD,GACA,0DACI,IAAI,CAAC,KAAK,EAHZ,CAAN;AAID;;AACD,IAAA,MAAM,GAAG,CAAC,IAAD,CAAT;AACD;;AAED,EAAA,MAAM,GAAG,0BAA0B,CAAC,MAAD,CAAnC,CAhE+D,CAkE/D;;AACA,MAAI,MAAM,IAAI,IAAd,EAAoB;AAClB,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,CAAC,MAA1B,EAAkC,EAAE,CAApC,EAAuC;AACrC,UAAI,MAAM,CAAC,CAAD,CAAN,IAAa,IAAjB,EAAuB;AACrB;AACD;;AACD,YAAM,KAAK,GAAG,MAAM,CAAC,CAAD,CAApB;;AACA,UAAI,KAAK,CAAC,KAAN,CAAY,MAAZ,KAAuB,MAAM,CAAC,CAAD,CAAN,CAAU,MAArC,EAA6C;AAC3C,cAAM,IAAI,UAAJ,CACF,uBAAuB,eAAe,cAAc,KAAK,CAAC,CAAD,CAAG,GAA5D,GACA,WAAW,MAAM,CAAC,CAAD,CAAN,CAAU,MAAM,oCAD3B,GAEA,SAAS,KAAK,CAAC,KAAK,EAHlB,CAAN;AAID;;AACD,WAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,CAAD,CAAN,CAAU,MAA9B,EAAsC,EAAE,CAAxC,EAA2C;AACzC,YAAI,CAAC,KAAK,CAAN,IAAW,CAAC,cAAhB,EAAgC;AAC9B;AACA;AACD;;AACD,cAAM,GAAG,GAAG,KAAK,CAAC,KAAN,CAAY,CAAZ,CAAZ;AACA,cAAM,MAAM,GAAG,MAAM,CAAC,CAAD,CAAN,CAAU,CAAV,CAAf;;AACA,YAAI,MAAM,IAAI,IAAV,IAAkB,MAAM,IAAI,CAA5B,IAAiC,GAAG,KAAK,MAA7C,EAAqD;AACnD,gBAAM,IAAI,UAAJ,CACF,GAAG,eAAe,2CAAlB,GACA,sBAAsB,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,CAAgB,CAAhB,EAAmB,MAAM,CAAC,CAAD,CAAN,CAAU,MAA7B,CAAoC,IAD1D,GAEA,yBACI,MAAM,CAAC,CAAD,CAAN,CAAU,KAAV,CAAgB,CAAhB,EAAmB,MAAM,CAAC,CAAD,CAAN,CAAU,MAA7B,CAAoC,IAHxC,GAIA,YAAY,eAAe,2BACvB,KAAK,CAAC,KAAN,CAAY,CAAZ,CAAc,EALlB,GAMA,+BACI,KAAK,CAAC,KAAN,CAAY,KAAZ,CAAkB,CAAlB,EAAqB,KAAK,CAAC,KAAN,CAAY,MAAjC,CAAwC,GAP5C,GAQA,mBAAmB,KAAK,CAAC,KAAK,IAT5B,CAAN;AAUD;AACF;AACF;AACF;;AACD,SAAO,MAAP;AACD;AAED;;;;;;AAMG;;AACH,OAAM,SAAU,iBAAV,CACF,MADE,EACgB,OADhB,EACmC,OADnC,EACqD;AACzD,QAAM,IAAI,GAAG,MAAM,CAAC,MAAM,CAAC,GAAP,CAAW,KAAK,IAAI,KAAK,CAAC,KAAN,CAAY,CAAZ,CAApB,CAAD,CAAnB;AACA,EAAA,IAAI,CAAC,IAAL;AACA,QAAM,IAAI,GAAG,MAAM,CAAC,OAAO,CAAC,GAAR,CAAY,MAAM,IAAI,MAAM,CAAC,KAAP,CAAa,CAAb,CAAtB,CAAD,CAAnB;AACA,EAAA,IAAI,CAAC,IAAL,GAJyD,CAKzD;;AACA,MAAI,IAAI,CAAC,MAAL,GAAc,CAAlB,EAAqB;AACnB,UAAM,IAAI,UAAJ,CACF,gEAAA,GACA,oBADA,GAEA,GAAG,IAAI,CAAC,SAAL,CAAe,MAAM,CAAC,GAAP,CAAW,KAAK,IAAI,KAAK,CAAC,KAA1B,CAAf,CAAgD,EAHjD,CAAN;AAID;;AACD,MAAI,IAAI,CAAC,MAAL,GAAc,CAAlB,EAAqB;AACnB,UAAM,IAAI,UAAJ,CACF,iEAAA,GACA,oBADA,GAEA,GAAG,IAAI,CAAC,SAAL,CAAe,OAAO,CAAC,GAAR,CAAY,MAAM,IAAI,MAAM,CAAC,KAA7B,CAAf,CAAmD,EAHpD,CAAN;AAID;;AACD,MAAI,IAAI,CAAC,MAAL,GAAc,CAAd,IAAmB,IAAI,CAAC,MAAL,GAAc,CAAjC,IAAsC,CAAC,IAAI,CAAC,WAAL,CAAiB,IAAjB,EAAuB,IAAvB,CAA3C,EAAyE;AACvE,UAAM,IAAI,UAAJ,CACF,iEAAA,GACA,kBAAkB,IAAI,CAAC,CAAD,CAAG,wBAAwB,IAAI,CAAC,CAAD,CAAG,UADxD,GAEA,YAHE,CAAN;AAID;AACF;AAED;;;;;;;;AAQG;;AACH,SAAS,+BAAT,CACI,OADJ,EACuB,OADvB,EACkD,YADlD,EACuE;AACrE;AACA,QAAM,SAAS,GAAG,CAChB,MAAM,CAAC,gBADS,EACS,MAAM,CAAC,kBADhB,EAEhB,MAAM,CAAC,uBAFS,CAAlB;;AAIA,OAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,OAAO,CAAC,MAA5B,EAAoC,EAAE,CAAtC,EAAyC;AACvC,UAAM,CAAC,GAAG,OAAO,CAAC,CAAD,CAAjB;AACA,UAAM,IAAI,GAAG,OAAO,CAAC,CAAD,CAApB;AACA,UAAM,KAAK,GAAG,YAAY,CAAC,CAAD,CAA1B;;AACA,QAAI,IAAI,IAAI,IAAZ,EAAkB;AAChB;AACD;;AACD,QAAI,IAAI,KAAK,MAAM,CAAC,uBAApB,EAA6C;AAC3C,UAAI,CAAC,CAAC,KAAF,CAAQ,CAAC,CAAC,KAAF,CAAQ,MAAR,GAAiB,CAAzB,MAAgC,CAApC,EAAuC;AACrC,cAAM,IAAI,UAAJ,CACF,2CAA2C,CAAC,CAAC,KAAK,eAAlD,GACA,+DADA,GAEA,6DAFA,GAGA,qBAJE,CAAN,CADqC,CAMrC;AACD;AACF;;AACD,QAAI,SAAS,CAAC,OAAV,CAAkB,IAAlB,MAA4B,CAAC,CAAjC,EAAoC;AAClC,YAAM,YAAY,GAAG,CAAC,CAAC,KAAF,CAAQ,KAAR,CAAc,CAAd,CAArB;AACA,YAAM,WAAW,GAAG,KAAK,CAAC,KAAN,CAAY,CAAZ,CAApB;;AACA,WAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,YAAY,CAAC,MAAjC,EAAyC,EAAE,CAA3C,EAA8C;AAC5C,cAAM,SAAS,GAAG,YAAY,CAAC,CAAD,CAA9B;AACA,cAAM,MAAM,GAAG,WAAW,CAAC,CAAD,CAA1B;;AACA,YAAI,MAAM,IAAI,IAAV,IAAkB,SAAS,KAAK,MAApC,EAA4C;AAC1C,gBAAM,IAAI,UAAJ,CACF,8BAA8B,CAAC,CAAC,KAAK,qBAArC,GACA,mBAAmB,KAAK,qCADxB,GAEA,uDAHE,CAAN;AAID;AACF;AACF;AACF;AACF;AAED;;;;;;;;;;;;;;;;;;;;;;;;;AAyBG;;;AACH,SAAS,cAAT,CACI,IADJ,EAC2B,KAD3B,EAC4C,MAD5C,EAEI,cAAc,GAAG,IAFrB,EAE2B,eAAe,GAAG,EAF7C,EAE+C;AAC7C,MAAI,MAAJ;;AACA,MAAI,KAAK,CAAC,OAAN,CAAc,IAAd,CAAJ,EAAyB;AACvB,QAAI,IAAI,CAAC,MAAL,KAAgB,KAAK,CAAC,MAA1B,EAAkC;AAChC,YAAM,IAAI,UAAJ,CACF,6BAA6B,eAAe,iBAA5C,GACA,iEADA,GAEA,uCAAuC,KAAK,CAAC,MAAM,aAFnD,GAGA,oBAAoB,IAAI,CAAC,MAAM,cAJ7B,CAAN;AAKD;;AACD,IAAA,MAAM,GAAG,IAAT;AACD,GATD,MASO;AACL,QAAI,KAAK,CAAC,MAAN,GAAe,CAAnB,EAAsB;AACpB,YAAM,IAAI,UAAJ,CACF,qBAAqB,KAAK,CAAC,MAAM,IAAI,eAAe,YAApD,GACA,wDADA,GAEA,GAAG,IAAI,CAAC,SAAL,CAAe,IAAI,CAAC,KAApB,CAA0B,GAH3B,CAAN;AAID;;AACD,IAAA,MAAM,GAAG,CAAC,IAAD,CAAT;AACD;;AAED,MAAI,MAAM,IAAI,IAAd,EAAoB;AAClB,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,CAAC,MAA1B,EAAkC,EAAE,CAApC,EAAuC;AACrC,UAAI,MAAM,CAAC,CAAD,CAAN,IAAa,IAAjB,EAAuB;AACrB;AACD;;AACD,YAAM,KAAK,GAAG,MAAM,CAAC,CAAD,CAApB;;AACA,UAAI,KAAK,CAAC,KAAN,CAAY,MAAZ,KAAuB,MAAM,CAAC,CAAD,CAAN,CAAU,MAArC,EAA6C;AAC3C,cAAM,IAAI,UAAJ,CACF,uBAAuB,eAAe,cAAc,KAAK,CAAC,CAAD,CAAG,GAA5D,GACA,WAAW,MAAM,CAAC,CAAD,CAAN,CAAU,MAAM,oCAD3B,GAEA,SAAS,IAAI,CAAC,SAAL,CAAe,KAAK,CAAC,KAArB,CAA2B,EAHlC,CAAN;AAID;;AACD,WAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,CAAD,CAAN,CAAU,MAA9B,EAAsC,EAAE,CAAxC,EAA2C;AACzC,YAAI,CAAC,KAAK,CAAN,IAAW,CAAC,cAAhB,EAAgC;AAC9B;AACD;;AACD,cAAM,GAAG,GAAG,KAAK,CAAC,KAAN,CAAY,CAAZ,CAAZ;AACA,cAAM,MAAM,GAAG,MAAM,CAAC,CAAD,CAAN,CAAU,CAAV,CAAf;;AACA,YAAI,MAAM,IAAI,IAAd,EAAoB;AAClB,cAAI,MAAM,KAAK,GAAf,EAAoB;AAClB,kBAAM,IAAI,UAAJ,CACF,uBAAuB,eAAe,aAAtC,GACA,GAAG,KAAK,CAAC,CAAD,CAAG,kBAAkB,IAAI,CAAC,SAAL,CAAe,MAAM,CAAC,CAAD,CAArB,CAAyB,OADtD,GAEA,wBAAwB,IAAI,CAAC,SAAL,CAAe,KAAK,CAAC,KAArB,CAA2B,GAHjD,CAAN;AAID;AACF;AACF;AACF;AACF;AACF;AAED;;;;;;;;;;;;AAYG;;;AACH,OAAM,SAAU,cAAV,CACF,OADE,EAGF,WAHE,EAGmB;AACvB,MAAI,OAAO,IAAI,IAAX,IAAmB,KAAK,CAAC,OAAN,CAAc,OAAd,KAA0B,OAAO,CAAC,MAAR,KAAmB,CAApE,EAAuE;AACrE,WAAO,WAAW,CAAC,GAAZ,CAAgB,IAAI,IAAI,EAAxB,CAAP;AACD;;AAED,MAAI,cAAJ;;AAEA,MAAI,OAAO,OAAP,KAAmB,QAAnB,IAA+B,OAAO,OAAP,KAAmB,UAAtD,EAAkE;AAChE,IAAA,cAAc,GAAG,CAAC,OAAD,CAAjB;AACD,GAFD,MAEO,IAAI,KAAK,CAAC,OAAN,CAAc,OAAd,KAA0B,OAAO,OAAP,KAAmB,QAAjD,EAA2D;AAChE,IAAA,cAAc,GAAG,OAAjB;AAED,GAHM,MAGA;AACL,UAAM,IAAI,SAAJ,CACF,iEACA,sCAAsC,OAAO,EAF3C,CAAN;AAGD;;AAED,MAAI,KAAK,CAAC,OAAN,CAAc,cAAd,CAAJ,EAAmC;AACjC;AACA,WAAO,WAAW,CAAC,GAAZ,CACH,IAAI,IAAI,cADL,CAAP;AAED,GAJD,MAIO;AACL;AACA,UAAM,aAAa,GAAwC,EAA3D;;AACA,SAAK,MAAM,IAAX,IAAmB,WAAnB,EAAgC;AAC9B,UAAI,aAAa,GACb,cAAc,CAAC,cAAf,CAA8B,IAA9B,IAAsC,cAAc,CAAC,IAAD,CAApD,GAA6D,EADjE;;AAEA,UAAI,CAAC,KAAK,CAAC,OAAN,CAAc,aAAd,CAAL,EAAmC;AACjC,QAAA,aAAa,GAAG,CAAC,aAAD,CAAhB;AACD;;AACD,MAAA,aAAa,CAAC,IAAd,CAAmB,aAAnB;AACD;;AACD,WAAO,aAAP;AACD;AACF;AA2DD,MAAM,wBAAwB,GAAG,cAAjC;AAEA;;;;;;;;;;;AAWG;;AACH,OAAM,MAAO,WAAP,SAA2B,SAA3B,CAAoC;AA4CxC,EAAA,WAAA,CAAY,IAAZ,EAA+B;AAC7B,UAAM,IAAN;AACA,SAAK,UAAL,GAAkB,KAAlB;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkCG;;;AACH,EAAA,OAAO,CACH,UADG,EACkB,SADlB,EAEH,OAAA,GAEoD,OAAO,CAAC,GAJzD,EAI4D;AACjE,QAAI,CAAC,KAAK,KAAV,EAAiB;AACf,YAAM,IAAI,UAAJ,CACF,mEAAA,GACA,+DADA,GAEA,gDAHE,CAAN;AAID;;AACD,IAAA,YAAY,CAAC,IAAD,EAAO,UAAP,EAAmB,SAAnB,EAA8B,OAA9B,CAAZ;AACD;AAED;;;;;;;;;AASG;;;AACH,EAAA,OAAO,CAAC,IAAD,EAAuB;AAC5B,QAAI,IAAI,CAAC,IAAL,IAAa,IAAjB,EAAuB;AACrB,MAAA,IAAI,CAAC,IAAL,GAAY,EAAZ;AACD;;AACD,SAAK,IAAL,GAAY,IAAI,CAAC,IAAjB;;AAEA,QAAI,OAAO,IAAI,CAAC,SAAZ,KAA0B,QAA9B,EAAwC;AACtC,WAAK,UAAL,GAAkB,UAAU,CAAC,YAAX,CAAwB,IAAI,CAAC,SAA7B,CAAlB;AACA,WAAK,gBAAL,GAAwB,IAAxB;AACD,KAHD,MAGO;AACL,UAAI,EAAE,IAAI,CAAC,SAAL,YAA0B,SAA5B,CAAJ,EAA4C;AAC1C,cAAM,IAAI,UAAJ,CACF,6DADE,CAAN;AAED;;AACD,WAAK,UAAL,GAAkB,IAAI,CAAC,SAAvB;AACA,WAAK,gBAAL,GAAwB,KAAxB;AACD,KAhB2B,CAkB5B;AACA;AAEA;;;AACA,QAAI,aAAa,GAAqB,EAAtC;;AACA,QAAI,CAAC,KAAK,CAAC,OAAN,CAAc,IAAI,CAAC,IAAnB,CAAD,IAA6B,OAAO,IAAI,CAAC,IAAZ,KAAqB,QAAlD,IACA,OAAO,IAAI,CAAC,IAAZ,KAAqB,UADzB,EACqC;AACnC,MAAA,IAAI,CAAC,IAAL,GAAY,IAAI,CAAC,IAAjB;;AACA,WAAK,MAAM,IAAX,IAAmB,IAAI,CAAC,IAAxB,EAA8B;AAC5B,YAAI,KAAK,WAAL,CAAiB,OAAjB,CAAyB,IAAzB,MAAmC,CAAC,CAAxC,EAA2C;AACzC,gBAAM,IAAI,UAAJ,CACF,sCAAsC,IAAI,KAA1C,GACA,qCAAqC,KAAK,WAAW,EAFnD,CAAN;AAGD;AACF;;AACD,WAAK,MAAM,IAAX,IAAmB,KAAK,WAAxB,EAAqC;AACnC,YAAI,IAAI,CAAC,IAAL,CAAU,IAAV,KAAmB,IAAvB,EAA6B;AAC3B,UAAA,OAAO,CAAC,IAAR,CACI,WAAW,IAAI,+CAAf,GACA,8DADA,GAEA,mBAAmB,IAAI,kBAH3B;AAID;;AACD,QAAA,aAAa,CAAC,IAAd,CAAmB,MAAM,CAAC,GAAP,CAAW,IAAI,CAAC,IAAL,CAAU,IAAV,CAAX,CAAnB;AACD;AACF,KAnBD,MAmBO,IAAI,KAAK,CAAC,OAAN,CAAc,IAAI,CAAC,IAAnB,CAAJ,EAA8B;AACnC,UAAI,IAAI,CAAC,IAAL,CAAU,MAAV,KAAqB,KAAK,OAAL,CAAa,MAAtC,EAA8C;AAC5C,cAAM,IAAI,UAAJ,CACF,8DAAA,GACA,+BAA+B,KAAK,OAAL,CAAa,MAAM,cADlD,GAEA,uBAAuB,IAAI,CAAC,IAAI,GAH9B,CAAN;AAID;;AACD,YAAM,SAAS,GAAG,IAAI,CAAC,IAAvB;AACA,MAAA,aAAa,GAAG,SAAS,CAAC,GAAV,CAAc,CAAC,IAAI,MAAM,CAAC,GAAP,CAAW,CAAX,CAAnB,CAAhB;AACD,KATM,MASA;AACL,YAAM,YAAY,GAAG,MAAM,CAAC,GAAP,CAAW,IAAI,CAAC,IAAhB,CAArB;AACA,WAAK,OAAL,CAAa,OAAb,CAAqB,CAAC,IAAG;AACvB,QAAA,aAAa,CAAC,IAAd,CAAmB,YAAnB;AACD,OAFD;AAGD;;AAED,SAAK,aAAL,GAAqB,aAArB;AAEA,SAAK,eAAL,GAAuB,EAAvB;AACA,SAAK,gBAAL,GAAwB,EAAxB;AACA,SAAK,WAAL,GAAmB,EAAnB;;AACA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,OAAL,CAAa,MAAjC,EAAyC,EAAE,CAA3C,EAA8C;AAC5C;AACA,YAAM,KAAK,GAAG,KAAK,oBAAL,CAA0B,CAA1B,CAAd;AACA,YAAM,IAAI,GAAG,KAAK,WAAL,CAAiB,CAAjB,CAAb;AACA,WAAK,eAAL,CAAqB,IAArB,CAA0B,IAA1B;AACA,WAAK,gBAAL,CAAsB,IAAtB,CAA2B,KAA3B;AACA,WAAK,WAAL,CAAiB,IAAjB,CAAsB,KAAK,aAAL,CAAmB,CAAnB,CAAtB;AACD,KAtE2B,CAwE5B;AACA;;;AACA,UAAM,iBAAiB,GAAa,EAApC,CA1E4B,CA4E5B;;AACA,SAAK,OAAL,GAAe,IAAI,CAAC,OAApB,CA7E4B,CA8E5B;;AACA,SAAK,YAAL,GAAoB,CAAC,MAAD,CAApB;AACA,SAAK,cAAL,GAAsB,EAAtB,CAhF4B,CAkF5B;AACA;AACA;AACA;;AACA,IAAA,SAAS,CAAC,MAAD,EAAS,MAAK;AACrB,WAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,OAAL,CAAa,MAAjC,EAAyC,EAAE,CAA3C,EAA8C;AAC5C,YAAI,iBAAiB,CAAC,OAAlB,CAA0B,CAA1B,MAAiC,CAAC,CAAtC,EAAyC;AACvC;AACD,SAH2C,CAI5C;AACA;;;AACA,cAAM,YAAY,GAAG,KAAK,aAAL,CAAmB,CAAnB,CAArB;;AACA,YAAI,KAAK,OAAL,CAAa,MAAb,GAAsB,CAA1B,EAA6B;AAC3B,eAAK,cAAL,CAAoB,IAApB,CAAyB,CAAC,YAAD,EAAe,CAAf,CAAzB;AACA,eAAK,YAAL,CAAkB,IAAlB,CAAuB,KAAK,WAAL,CAAiB,CAAjB,IAAsB,OAA7C;AACD;AACF,OAZoB,CAcrB;AACA;;AACD,KAhBQ,CAAT;AAkBA,UAAM,aAAa,GAAG,cAAc,CAAC,IAAI,CAAC,OAAN,EAAe,KAAK,WAApB,CAApC,CAxG4B,CAyG5B;;AAEA;;AAEG;;AACH,UAAM,YAAY,GACd,CAAC,WAAD,EAAsB,UAAtB,EACC,YADD,KACiC;AAC/B,UAAI,KAAK,WAAL,CAAiB,MAAjB,GAA0B,CAA9B,EAAiC;AAC/B,QAAA,UAAU,GAAG,KAAK,WAAL,CAAiB,WAAjB,IAAgC,GAAhC,GAAsC,UAAnD;AACD;;AACD,WAAK,YAAL,CAAkB,IAAlB,CAAuB,UAAvB;AACA,WAAK,cAAL,CAAoB,IAApB,CAAyB,CAAC,YAAD,EAAe,WAAf,CAAzB;AACD,KARL;;AAUA,IAAA,SAAS,CAAC,QAAD,EAAW,MAAK;AACvB,WAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,OAAL,CAAa,MAAjC,EAAyC,EAAE,CAA3C,EAA8C;AAC5C,YAAI,iBAAiB,CAAC,OAAlB,CAA0B,CAA1B,MAAiC,CAAC,CAAtC,EAAyC;AACvC;AACD;;AACD,cAAM,aAAa,GAAG,aAAa,CAAC,CAAD,CAAnC,CAJ4C,CAK5C;AAEA;;AACA,cAAM,aAAa,GAAI,OAAD,IAA0C;AAC9D,gBAAM,gBAAgB,GAAG,EAAzB;AACA,cAAI,UAAJ;AACA,cAAI,KAAJ;AACA,cAAI,gBAAJ,CAJ8D,CAK9D;;AAEA,eAAK,MAAM,MAAX,IAAqB,OAArB,EAA8B;AAC5B,gBAAI,OAAO,MAAP,KAAkB,QAAlB,IACA,CAAC,UAAD,EAAa,KAAb,EAAoB,cAApB,EAAoC,IAApC,EAA0C,OAA1C,CAAkD,MAAlD,MACI,CAAC,CAFT,EAEY;AACV,oBAAM,WAAW,GAAG,KAAK,oBAAL,CAA0B,CAA1B,CAApB;;AAEA,kBAAI,WAAW,CAAC,WAAW,CAAC,MAAZ,GAAqB,CAAtB,CAAX,KAAwC,CAAxC,IACA,KAAK,aAAL,CAAmB,CAAnB,MAA0B,MAAM,CAAC,kBADrC,EACyD;AACvD;AACA,oBAAI,CAAC,UAAD,EAAa,KAAb,EAAoB,OAApB,CAA4B,MAA5B,MAAwC,CAAC,CAA7C,EAAgD;AAC9C,kBAAA,KAAK,GAAG,OAAO,CAAC,cAAhB;AACD,iBAFD,MAEO,IAAI,CAAC,cAAD,EAAiB,IAAjB,EAAuB,OAAvB,CAA+B,MAA/B,MAA2C,CAAC,CAAhD,EAAmD;AACxD,kBAAA,KAAK,GAAG,OAAO,CAAC,kBAAhB;AACD;AACF,eARD,MAQO,IACH,KAAK,aAAL,CAAmB,CAAnB,MACA,MAAM,CAAC,6BAFJ,EAEmC;AACxC;AACA;AACA,oBAAI,CAAC,UAAD,EAAa,KAAb,EAAoB,OAApB,CAA4B,MAA5B,MAAwC,CAAC,CAA7C,EAAgD;AAC9C,kBAAA,KAAK,GAAG,OAAO,CAAC,yBAAhB;AACD,iBAFD,MAEO,IAAI,CAAC,cAAD,EAAiB,IAAjB,EAAuB,OAAvB,CAA+B,MAA/B,MAA2C,CAAC,CAAhD,EAAmD;AACxD,kBAAA,KAAK,GAAG,OAAO,CAAC,6BAAhB;AACD;AACF,eAVM,MAUA;AACL;AACA,oBAAI,CAAC,UAAD,EAAa,KAAb,EAAoB,OAApB,CAA4B,MAA5B,MAAwC,CAAC,CAA7C,EAAgD;AAC9C,kBAAA,KAAK,GAAG,OAAO,CAAC,mBAAhB;AACD,iBAFD,MAEO,IAAI,CAAC,cAAD,EAAiB,IAAjB,EAAuB,OAAvB,CAA+B,MAA/B,MAA2C,CAAC,CAAhD,EAAmD;AACxD,kBAAA,KAAK,GAAG,OAAO,CAAC,uBAAhB;AACD;AACF;;AACD,kBAAI,MAAJ;;AACA,kBAAI,CAAC,UAAD,EAAa,KAAb,EAAoB,OAApB,CAA4B,MAA5B,MAAwC,CAAC,CAA7C,EAAgD;AAC9C,gBAAA,MAAM,GAAG,KAAT;AACD,eAFD,MAEO,IAAI,CAAC,cAAD,EAAiB,IAAjB,EAAuB,OAAvB,CAA+B,MAA/B,MAA2C,CAAC,CAAhD,EAAmD;AACxD,gBAAA,MAAM,GAAG,IAAT;AACD,eAlCS,CAmCV;;;AACA,cAAA,gBAAgB,GAAG,KAAnB;AACA,cAAA,UAAU,GAAG,gBAAgB,GAAG,MAAhC;AACD,aAxCD,MAwCO;AACL,oBAAM,QAAQ,GAAG,OAAO,CAAC,GAAR,CAAY,MAAZ,CAAjB,CADK,CAEL;;AACA,cAAA,gBAAgB,GAAG,QAAnB;AACA,cAAA,UAAU,GACN,gBAAgB,GAAG,OAAO,CAAC,mBAAR,CAA4B,MAA5B,CADvB;AAED,aA/C2B,CAiD5B;;;AACA,gBAAI,YAAJ;AACA,YAAA,SAAS,CAAC,UAAD,EAAa,MAAK;AACzB,cAAA,YAAY,GAAG,gBAAf;AACD,aAFQ,CAAT;AAGA,YAAA,YAAY,CAAC,CAAD,EAAI,UAAJ,EAAgB,YAAhB,CAAZ;AACD;AACF,SA/DD;;AAiEA,QAAA,aAAa,CAAC,aAAD,CAAb,CAzE4C,CA0E5C;AACD;AACF,KA7EQ,CAAT,CAxH4B,CAuM5B;AACA;;AACA,SAAK,yBAAL,GAAiC,KAAK,gBAAtC;AACD;AAED;;;;;;;;AAQG;;;AACO,EAAA,gCAAgC,GAAA;AACxC,QAAI,KAAK,yBAAL,IAAkC,IAAtC,EAA4C;AAC1C;AACD;;AACD,QAAI,KAAK,gBAAL,CAAsB,MAAtB,KACA,KAAK,yBAAL,CAA+B,MADnC,EAC2C;AACzC,MAAA,OAAO,CAAC,IAAR,CACI,kEACA,yDADA,GAEA,+BAHJ;AAID;AACF;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA8BG;;;AACH,EAAA,QAAQ,CACJ,CADI,EACgB,CADhB,EAEJ,IAAA,GAA0B,EAFtB,EAEwB;AAC9B,UAAM,SAAS,GAAG,IAAI,CAAC,SAAL,IAAkB,IAAlB,GAAyB,EAAzB,GAA8B,IAAI,CAAC,SAArD;AACA,IAAA,cAAc,CAAC,SAAD,CAAd,CAF8B,CAI9B;AACA;;AACA,UAAM,cAAc,GAAG,IAAvB;AACA,UAAM,gBAAgB,GAClB,KAAK,qBAAL,CAA2B,CAA3B,EAA8B,CAA9B,EAAiC,cAAjC,EAAiD,SAAjD,CADJ;;AAEA,QAAI;AACF;AACA;AACA,YAAM,GAAG,GAAG,gBAAgB,CAAC,CAAD,CAAhB,CAAoB,MAApB,CAA2B,gBAAgB,CAAC,CAAD,CAA3C,CAAZ;AACA,WAAK,gBAAL;AACA,YAAM,CAAC,GAAG,KAAK,YAAf;AACA,YAAM,QAAQ,GACV,KAAK,QAAL,CAAc,CAAd,EAAiB,GAAjB,EAAsB,SAAtB,EAAiC,IAAI,CAAC,OAAtC,EAA+C,IAAI,CAAC,KAApD,CADJ;AAEA,aAAO,gBAAgB,CAAC,QAAD,CAAvB;AACD,KATD,SASU;AACR,MAAA,iBAAiB,CAAC,gBAAgB,CAAC,CAAD,CAAjB,EAAsB,CAAtB,CAAjB;AACA,MAAA,iBAAiB,CAAC,gBAAgB,CAAC,CAAD,CAAjB,EAAsB,CAAtB,CAAjB;AACD;AACF,GArYuC,CAuYxC;AACA;;AACA;;;;;;;;;;;;;;;;;;;AAmBG;;;AACkB,QAAf,eAAe,CAAC,OAAD,EAAuB,IAAvB,EAAsD;AAEzE,SAAK,gBAAL;AACA,WAAO,eAAe,CAAC,IAAD,EAAO,OAAP,EAAgB,IAAhB,CAAtB;AACD;AAED;;;;;;;;;AASG;;;AACK,EAAA,eAAe,CACnB,GADmB,EACG,SADH,EACuB,KADvB,EAEnB,SAAS,GAAG,OAFO,EAEA;AACrB,QAAI,UAAJ;;AACA,QAAI,KAAK,IAAI,IAAb,EAAmB;AACjB,MAAA,UAAU,GAAG,IAAb;;AACA,UAAI,SAAS,IAAI,IAAjB,EAAuB;AACrB,cAAM,IAAI,UAAJ,CACF,MAAM,SAAS,+CAAf,GACA,mBAAmB,SAAS,EAF1B,CAAN;AAGD;AACF,KAPD,MAOO,IAAI,GAAG,IAAI,IAAX,EAAiB;AACtB,UAAI,KAAK,CAAC,OAAN,CAAc,GAAd,CAAJ,EAAwB;AACtB,QAAA,UAAU,GAAG,GAAG,CAAC,CAAD,CAAH,CAAO,KAAP,CAAa,CAAb,CAAb;AACD,OAFD,MAEO;AACL,QAAA,UAAU,GAAG,GAAG,CAAC,KAAJ,CAAU,CAAV,CAAb;AACD;AACF,KANM,MAMA;AACL,YAAM,IAAI,UAAJ,CACF,wDAAA,GACA,GAAG,SAAS,sBAFV,CAAN;AAGD;;AACD,WAAO,UAAP;AACD;AAED;;;;;;AAMG;;;AACH,EAAA,OAAO,CAAC,MAAD,EAAyC,OAAzC,EAAiE;AAEtE,QAAI,KAAK,CAAC,OAAN,CAAc,OAAd,KAA0B,OAAO,CAAC,MAAR,KAAmB,CAAjD,EAAoD;AAClD,YAAM,IAAI,UAAJ,CACF,oDADE,CAAN;AAED;;AAED,UAAM,cAAc,GAAG,KAAK,CAAC,OAAN,CAAc,OAAd,CAAvB;AACA,UAAM,WAAW,GACZ,cAAc,GAAG,OAAH,GAAyB,CAAC,OAAD,CAD5C;AAEA,UAAM,qBAAqB,GAAG,KAAK,uBAAL,CAA6B,WAA7B,CAA9B,CAVsE,CAYtE;;AACA,UAAM,QAAQ,GAAG,IAAI,QAAJ,EAAjB;;AACA,QAAI,MAAM,YAAY,MAAtB,EAA8B;AAC5B,MAAA,MAAM,GAAG,CAAC,MAAD,CAAT;AACD;;AACD,QAAI,KAAK,CAAC,OAAN,CAAc,MAAd,CAAJ,EAA2B;AACzB,UAAI,MAAM,CAAC,MAAP,KAAkB,KAAK,MAAL,CAAY,MAAlC,EAA0C;AACxC,cAAM,IAAI,UAAJ,CACF,kCAAkC,MAAM,CAAC,MAAM,IAA/C,GACA,oDADA,GAEA,IAAI,KAAK,MAAL,CAAY,MAAM,IAHpB,CAAN;AAID;;AACD,WAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,MAAL,CAAY,MAAhC,EAAwC,EAAE,CAA1C,EAA6C;AAC3C,QAAA,QAAQ,CAAC,GAAT,CAAa,KAAK,MAAL,CAAY,CAAZ,CAAb,EAA6B,MAAM,CAAC,CAAD,CAAnC;AACD;AACF,KAVD,MAUO;AACL,WAAK,MAAM,KAAX,IAAoB,KAAK,MAAzB,EAAiC;AAC/B,cAAM,WAAW,GAAG,MAAM,CAAC,KAAK,CAAC,IAAP,CAA1B;;AACA,YAAI,WAAW,IAAI,IAAnB,EAAyB;AACvB,gBAAM,IAAI,UAAJ,CACF,8CAA8C,KAAK,CAAC,IAAI,EADtD,CAAN;AAED;;AACD,QAAA,QAAQ,CAAC,GAAT,CAAa,KAAb,EAAoB,WAApB;AACD;AACF,KApCqE,CAsCtE;;;AACA,UAAM,cAAc,GAAG,OAAO,CAAC,qBAAD,EAAwB,QAAxB,CAA9B;AACA,WAAO,cAAc,GAAG,cAAH,GAAoB,cAAc,CAAC,CAAD,CAAvD;AACD;AAED;;AAEG;;;AACK,EAAA,uBAAuB,CAAC,mBAAD,EAA8B;AAE3D,UAAM,qBAAqB,GACvB,YAAY,CAAC,IAAD,EAAO,mBAAmB,CAAC,MAA3B,CADhB;AAEA,QAAI,gBAAgB,GAAG,mBAAmB,CAAC,MAA3C;;AACA,SAAK,MAAM,KAAX,IAAoB,KAAK,MAAzB,EAAiC;AAC/B,YAAM,YAAY,GACd,KAAK,CAAC,OAAN,CAAc,KAAK,CAAC,MAApB,IAA8B,KAAK,CAAC,MAApC,GAA6C,CAAC,KAAK,CAAC,MAAP,CADjD;AAEA,YAAM,gBAAgB,GAAG,YAAY,CAAC,GAAb,CAAiB,MAAM,IAAI,MAAM,CAAC,IAAlC,CAAzB;;AACA,WAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,mBAAmB,CAAC,MAAxC,EAAgD,EAAE,CAAlD,EAAqD;AACnD,cAAM,KAAK,GAAG,gBAAgB,CAAC,OAAjB,CAAyB,mBAAmB,CAAC,CAAD,CAA5C,CAAd;;AACA,YAAI,KAAK,KAAK,CAAC,CAAf,EAAkB;AAChB,UAAA,qBAAqB,CAAC,CAAD,CAArB,GAA2B,YAAY,CAAC,KAAD,CAAvC;AACA,UAAA,gBAAgB;AACjB;;AACD,YAAI,gBAAgB,KAAK,CAAzB,EAA4B;AAC1B;AACD;AACF;;AACD,UAAI,gBAAgB,KAAK,CAAzB,EAA4B;AAC1B;AACD;AACF;;AAED,QAAI,gBAAgB,GAAG,CAAvB,EAA0B;AACxB,YAAM,cAAc,GAAa,EAAjC;AACA,MAAA,qBAAqB,CAAC,OAAtB,CAA8B,CAAC,MAAD,EAAS,CAAT,KAAc;AAC1C,YAAI,MAAM,IAAI,IAAd,EAAoB;AAClB,UAAA,cAAc,CAAC,IAAf,CAAoB,mBAAmB,CAAC,CAAD,CAAvC;AACD;AACF,OAJD;AAKA,YAAM,IAAI,UAAJ,CACF,kDAAA,GACA,GAAG,IAAI,CAAC,SAAL,CAAe,cAAf,CAA8B,EAF/B,CAAN;AAGD;;AACD,WAAO,qBAAP;AACD;AAED;;;;;;;;;;;;AAYG;;;AACK,EAAA,WAAW,CAAC,GAAD,EAAuB,SAAS,GAAG,EAAnC,EAAuC,OAAO,GAAG,KAAjD,EAAsD;AAEvE,WAAO,GAAG,CAAC,IAAJ,CAAS,MAAK;AACnB,YAAM,UAAU,GAAG,KAAK,eAAL,CAAqB,GAArB,CAAnB;;AACA,UAAI,OAAJ,EAAa;AACX,cAAM,IAAI,mBAAJ,CACF,+CADE,CAAN;AAED,OALkB,CAOnB;AACA;AACA;AACA;;;AAEA,YAAM,OAAO,GAAG,WAAW,CAAC,UAAD,EAAa,SAAb,CAA3B;AACA,YAAM,WAAW,GAAe,KAAK,OAAL,CAAa,GAAb,CAAiB,MAAM,IAAI,EAA3B,CAAhC,CAbmB,CAenB;;AACA,WAAK,IAAI,UAAU,GAAG,CAAtB,EAAyB,UAAU,GAAG,OAAO,CAAC,MAA9C,EAAsD,EAAE,UAAxD,EAAoE;AAClE,cAAM,SAAS,GAAG,GAAG,CAAC,IAAJ,CAAS,MAAK;AAC9B,gBAAM,UAAU,GAAG,OAAO,CAAC,UAAD,CAAP,CAAoB,CAApB,CAAnB;AACA,gBAAM,QAAQ,GAAG,OAAO,CAAC,UAAD,CAAP,CAAoB,CAApB,CAAjB,CAF8B,CAG9B;AACA;;AACA,gBAAM,QAAQ,GAAG,WAAW,CAAC,GAAD,EAAM,UAAN,EAAkB,QAAlB,CAA5B,CAL8B,CAO9B;;AACA,gBAAM,KAAK,GAAG,EAAd;;AACA,cAAI,KAAK,CAAC,OAAN,CAAc,QAAd,CAAJ,EAA6B;AAC3B,iBAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,QAAQ,CAAC,MAA7B,EAAqC,EAAE,CAAvC,EAA0C;AACxC,cAAA,KAAK,CAAC,IAAN,CAAW;AAAC,gBAAA,GAAG,EAAE,KAAK,MAAL,CAAY,CAAZ,CAAN;AAAsB,gBAAA,KAAK,EAAE,QAAQ,CAAC,CAAD;AAArC,eAAX;AACD;AACF,WAJD,MAIO;AACL,YAAA,KAAK,CAAC,IAAN,CAAW;AAAC,cAAA,GAAG,EAAE,KAAK,MAAL,CAAY,CAAZ,CAAN;AAAsB,cAAA,KAAK,EAAE;AAA7B,aAAX;AACD;;AACD,gBAAM,QAAQ,GAAG,IAAI,QAAJ,CAAa,KAAb,CAAjB;AACA,iBAAO,OAAO,CAAC,KAAK,OAAN,EAAe,QAAf,CAAd;AACD,SAlBiB,CAAlB;AAmBA,QAAA,SAAS,CAAC,OAAV,CAAkB,CAAC,QAAD,EAAW,CAAX,KAAiB,WAAW,CAAC,CAAD,CAAX,CAAe,IAAf,CAAoB,QAApB,CAAnC;AACD;;AACD,aAAO,gBAAgB,CACnB,WAAW,CAAC,GAAZ,CAAgB,OAAO,IAAI,GAAG,CAAC,MAAJ,CAAW,OAAX,EAAoB,CAApB,CAA3B,CADmB,CAAvB;AAED,KAxCM,CAAP;AAyCD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;AA0BG;;;AACH,EAAA,OAAO,CAAC,CAAD,EAAqB,IAAA,GAAyB,EAA9C,EAAgD;AACrD,UAAM,eAAe,GAAG,0BAA0B,CAAC,CAAD,CAAlD;AACA,IAAA,cAAc,CACV,eADU,EACO,KAAK,UADZ,EACwB,KAAK,eAD7B,EAC8C,KAD9C,CAAd;;AAEA,QAAI;AACF;AACA;AACA;AACA;AACA,YAAM,SAAS,GAAG,IAAI,CAAC,SAAL,IAAkB,IAAlB,GAAyB,EAAzB,GAA8B,IAAI,CAAC,SAArD;AACA,MAAA,cAAc,CAAC,SAAD,CAAd;AACA,aAAO,KAAK,WAAL,CAAiB,eAAjB,EAAkC,SAAlC,CAAP;AACD,KARD,SAQU;AACR,MAAA,iBAAiB,CAAC,eAAD,EAAkB,CAAlB,CAAjB;AACD;AACF;AAED;;;;;;;;;;;;;;AAcG;;;AACH,EAAA,cAAc,CAAC,CAAD,EAAmB;AAC/B,IAAA,cAAc,CAAC,CAAD,EAAI,KAAK,UAAT,EAAqB,KAAK,eAA1B,EAA2C,IAA3C,CAAd,CAD+B,CAE/B;AACA;;AACA,UAAM,SAAS,GAAG,CAAC,KAAK,CAAC,OAAN,CAAc,CAAd,IAAmB,CAAC,CAAC,CAAD,CAApB,GAA0B,CAA3B,EAA8B,KAA9B,CAAoC,CAApC,CAAlB;AACA,WAAO,KAAK,WAAL,CAAiB,CAAjB,EAAoB,SAApB,CAAP;AACD;;AAES,EAAA,qBAAqB,CAC3B,CAD2B,EAE3B,CAF2B,EAEuB,cAAc,GAAG,IAFxC,EAG3B,SAH2B,EAGT;AACpB;AACA,QAAI,KAAK,UAAL,IAAmB,IAAvB,EAA6B;AAC3B,YAAM,IAAI,YAAJ,CACF,2DACA,wCAFE,CAAN;AAGD;;AACD,UAAM,YAAY,GAAY,EAA9B;;AACA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,gBAAL,CAAsB,MAA1C,EAAkD,EAAE,CAApD,EAAuD;AACrD,YAAM,WAAW,GAAG,KAAK,gBAAL,CAAsB,CAAtB,CAApB;AACA,YAAM,MAAM,GAAG,KAAK,WAAL,CAAiB,CAAjB,CAAf;;AACA,UAAI,MAAM,KAAK,MAAM,CAAC,6BAAtB,EAAqD;AACnD,QAAA,YAAY,CAAC,IAAb,CACI,WAAW,CAAC,KAAZ,CAAkB,CAAlB,EAAqB,WAAW,CAAC,MAAZ,GAAqB,CAA1C,EAA6C,MAA7C,CAAoD,CAAC,CAAD,CAApD,CADJ;AAED,OAHD,MAGO;AACL;AACA,QAAA,YAAY,CAAC,IAAb,CAAkB,WAAlB;AACD;AACF;;AACD,IAAA,CAAC,GAAG,oBAAoB,CACpB,CADoB,EACjB,KAAK,cADY,EACI,KAAK,eADT,EAC0B,KAD1B,EACiC,OADjC,CAAxB;AAEA,IAAA,CAAC,GAAG,oBAAoB,CACpB,CADoB,EACjB,KAAK,eADY,EACK,YADL,EACmB,KADnB,EAC0B,QAD1B,CAAxB,CArBoB,CAuBpB;;AACA,IAAA,iBAAiB,CAAC,CAAD,EAAI,CAAJ,EAAO,IAAP,CAAjB,CAxBoB,CAyBpB;;AACA,IAAA,+BAA+B,CAAC,CAAD,EAAI,KAAK,WAAT,EAAsB,KAAK,gBAA3B,CAA/B;;AACA,QAAI,KAAK,QAAL,IAAiB,SAAS,IAAI,IAA9B,IAAsC,SAAS,GAAG,CAAtD,EAAyD;AACvD,UAAI,CAAC,CAAC,CAAD,CAAD,CAAK,KAAL,CAAW,CAAX,IAAgB,SAAhB,KAA8B,CAAlC,EAAqC;AACnC,cAAM,IAAI,UAAJ,CACF,4DAAA,GACA,wDADA,GAEA,GAAG,SAAS,YAAY,CAAC,CAAC,CAAD,CAAD,CAAK,KAAL,CAAW,CAAX,CAAa,aAHnC,CAAN;AAID;AACF;;AACD,WAAO,CAAC,CAAD,EAAI,CAAJ,CAAP;AACD;;AAEkC,QAAnB,mBAAmB,CAC/B,CAD+B,EAE/B,CAF+B,EAG/B,YAH+B,EAI/B,WAJ+B,EAK/B,cAAc,GAAG,IALc,EAM/B,SAN+B,EAMb;AACpB,UAAM,CAAC,UAAD,EAAa,UAAb,IACF,KAAK,qBAAL,CAA2B,CAA3B,EAA8B,CAA9B,EAAiC,cAAjC,EAAiD,SAAjD,CADJ,CADoB,CAGpB;;AACA,QAAI,YAAY,IAAI,IAApB,EAA0B;AACxB,YAAM,IAAI,KAAJ,CAAU,qCAAV,CAAN;AACD;;AAED,QAAI,qBAAqB,GAAa,IAAtC;;AACA,QAAI,WAAW,IAAI,IAAnB,EAAyB;AACvB,YAAM,YAAY,GACd,uBAAuB,CAAC,WAAD,EAAc,KAAK,WAAnB,CAD3B;AAEA,MAAA,qBAAqB,GAAG,EAAxB;;AACA,WAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,YAAY,CAAC,MAAjC,EAAyC,EAAE,CAA3C,EAA8C;AAC5C,QAAA,qBAAqB,CAAC,IAAtB,CACI,MAAM,kBAAkB,CAAC,UAAU,CAAC,CAAD,CAAX,EAAgB,IAAhB,EAAsB,YAAY,CAAC,CAAD,CAAlC,CAD5B;AAED;AACF,KAjBmB,CAmBpB;;;AACA,WAAO,CAAC,UAAD,EAAa,UAAb,EAAyB,qBAAzB,CAAP;AACD;AAED;;;;;;;;;;AAUG;;;AACK,EAAA,QAAQ,CACZ,CADY,EACqB,GADrB,EACoC,SADpC,EAEZ,OAAO,GAAG,CAFE,EAEC,KAFD,EAEe;AAC7B,WAAO,GAAG,CAAC,IAAJ,CAAS,MAAK;AACnB,YAAM,UAAU,GAAG,KAAK,eAAL,CAAqB,GAArB,EAA0B,SAA1B,EAAqC,KAArC,EAA4C,OAA5C,CAAnB;AACA,YAAM,IAAI,GAAa,EAAvB;;AACA,UAAI,OAAO,GAAG,CAAd,EAAiB;AACf,cAAM,IAAI,mBAAJ,CAAwB,sCAAxB,CAAN;AACD,OALkB,CAMnB;;;AACA,UAAI,KAAK,IAAI,IAAb,EAAmB;AACjB,cAAM,IAAI,mBAAJ,CACF,iDADE,CAAN;AAED,OAHD,MAGO;AACL,cAAM,OAAO,GAAG,WAAW,CAAC,UAAD,EAAa,SAAb,CAA3B;AACA,cAAM,UAAU,GAAG,QAAQ,CAAC,KAAK,CAAC,CAAD,EAAI,UAAJ,CAAN,CAA3B;;AACA,aAAK,IAAI,UAAU,GAAG,CAAtB,EAAyB,UAAU,GAAG,OAAO,CAAC,MAA9C,EAAsD,EAAE,UAAxD,EAAoE;AAClE,gBAAM,UAAU,GAAG,OAAO,CAAC,UAAD,CAAP,CAAoB,CAApB,CAAnB;AACA,gBAAM,QAAQ,GAAG,OAAO,CAAC,UAAD,CAAP,CAAoB,CAApB,CAAjB;AACA,gBAAM,QAAQ,GACV,CAAC,CAAC,mBAAF,CACI,UADJ,EACgB,UADhB,EAC4B,QAAQ,GAAG,UADvC,CADJ,CAHkE,CAMlE;AACA;;AACA,gBAAM,QAAQ,GAAG,oBAAoB,CAAC,GAAD,EAAM,QAAN,CAArC;AACA,gBAAM,SAAS,GAAG,CAAC,CAAC,QAAD,CAAnB;;AACA,cAAI,UAAU,KAAK,CAAnB,EAAsB;AACpB,iBAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,SAAS,CAAC,MAA9B,EAAsC,EAAE,CAAxC,EAA2C;AACzC,cAAA,IAAI,CAAC,IAAL,CAAU,MAAM,CAAC,CAAD,CAAhB;AACD;AACF;;AACD,eAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,SAAS,CAAC,MAA9B,EAAsC,EAAE,CAAxC,EAA2C;AACzC,kBAAM,QAAQ,GAAG,SAAS,CAAC,CAAD,CAA1B;AACA,YAAA,IAAI,CAAC,CAAD,CAAJ,GACI,GAAG,CAAC,GAAJ,CAAQ,IAAI,CAAC,CAAD,CAAZ,EAAiB,GAAG,CAAC,GAAJ,CAAQ,QAAQ,GAAG,UAAnB,EAA+B,QAA/B,CAAjB,CADJ;AAED;AACF;;AACD,aAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,IAAI,CAAC,MAAzB,EAAiC,EAAE,CAAnC,EAAsC;AACpC,UAAA,IAAI,CAAC,CAAD,CAAJ,GAAU,GAAG,CAAC,GAAJ,CAAQ,IAAI,CAAC,CAAD,CAAZ,EAAiB,UAAjB,CAAV;AACD;AACF;;AACD,aAAO,IAAP;AACD,KAvCM,CAAP;AAwCD;;AAES,EAAA,sBAAsB,GAAA;AAC9B,UAAM,SAAS,GAAG,KAAK,YAAvB,CAD8B,CAE9B;AACA;;AACA,UAAM,gBAAgB,GAAG,EAAzB;;AACA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,SAAS,CAAC,MAA9B,EAAsC,EAAE,CAAxC,EAA2C;AACzC,YAAM,KAAK,GAAG,SAAS,CAAC,CAAD,CAAvB;AACA,UAAI,QAAQ,GAAG,KAAf;;AACA,UAAI,KAAK,CAAC,SAAD,EAAY,KAAZ,CAAL,GAA0B,CAA9B,EAAiC;AAC/B,cAAM,QAAQ,GAAG,KAAK,CAAC,SAAS,CAAC,KAAV,CAAgB,CAAhB,EAAmB,CAAnB,CAAD,EAAwB,KAAxB,CAAtB;AACA,QAAA,QAAQ,IAAI,IAAI,QAAQ,EAAxB;AACD;;AACD,MAAA,gBAAgB,CAAC,IAAjB,CAAsB,QAAtB;AACD;;AACD,WAAO,gBAAP;AACD;AAED;;;;;;;;;AASG;;;AACO,EAAA,iBAAiB,GAAA;AACzB,WAAQ,IAAD,IAAmB;AACxB,YAAM,UAAU,GAAa,EAA7B;AAEA,YAAM,MAAM,GAAG,IAAI,CAAC,KAAL,CAAW,CAAX,EAAc,KAAK,MAAL,CAAY,MAA1B,CAAf;AACA,YAAM,OAAO,GAAG,IAAI,CAAC,KAAL,CACZ,KAAK,MAAL,CAAY,MADA,EACQ,KAAK,MAAL,CAAY,MAAZ,GAAqB,KAAK,OAAL,CAAa,MAD1C,CAAhB;AAEA,YAAM,aAAa,GAAG,IAAI,CAAC,KAAL,CAClB,KAAK,MAAL,CAAY,MAAZ,GAAqB,KAAK,OAAL,CAAa,MADhB,EAElB,KAAK,MAAL,CAAY,MAAZ,GAAqB,KAAK,OAAL,CAAa,MAAb,GAAsB,CAFzB,CAAtB;AAIA,YAAM,aAAa,GAAa,EAAhC,CAVwB,CAYxB;AACA;AACA;;AACA,YAAM,iBAAiB,GAAG,MAAK;AAC7B,cAAM,KAAK,GAAG,EAAd;;AACA,aAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,MAAL,CAAY,MAAhC,EAAwC,EAAE,CAA1C,EAA6C;AAC3C,UAAA,KAAK,CAAC,IAAN,CAAW;AAAC,YAAA,GAAG,EAAE,KAAK,MAAL,CAAY,CAAZ,CAAN;AAAsB,YAAA,KAAK,EAAE,MAAM,CAAC,CAAD;AAAnC,WAAX;AACD;;AACD,cAAM,QAAQ,GAAG,IAAI,QAAJ,CAAa,KAAb,CAAjB;AACA,cAAM,OAAO,GACT,OAAO,CAAC,KAAK,OAAN,EAAe,QAAf,EAAyB;AAAC,sBAAY;AAAb,SAAzB,CADX,CAN6B,CAQ7B;AACA;;AAEA,YAAI,SAAJ;;AACA,aAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,aAAL,CAAmB,MAAvC,EAA+C,EAAE,CAAjD,EAAoD;AAClD,gBAAM,YAAY,GAAG,KAAK,aAAL,CAAmB,CAAnB,CAArB;AACA,cAAI,IAAI,GAAG,YAAY,CAAC,OAAO,CAAC,CAAD,CAAR,EAAa,OAAO,CAAC,CAAD,CAApB,CAAvB;;AACA,cAAI,aAAa,CAAC,CAAD,CAAb,IAAoB,IAAxB,EAA8B;AAC5B,YAAA,IAAI,GAAG,mBAAmB,CAAC,IAAD,EAAO,aAAa,CAAC,CAAD,CAApB,CAA1B;AACD,WALiD,CAOlD;;;AACA,gBAAM,QAAQ,GAAW,GAAG,CAAC,IAAJ,CAAS,IAAT,CAAzB,CARkD,CASlD;;AACA,UAAA,UAAU,CAAC,IAAX,CAAgB,QAAhB;;AACA,cAAI,CAAC,KAAK,CAAV,EAAa;AACX,YAAA,SAAS,GAAG,IAAZ;AACD,WAFD,MAEO;AACL,YAAA,SAAS,GAAG,GAAG,CAAC,GAAJ,CAAQ,SAAR,EAAmB,IAAnB,CAAZ;AACD;AACF,SA5B4B,CA8B7B;AACA;AACA;;;AACA,aAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,cAAL,CAAoB,MAAxC,EAAgD,EAAE,CAAlD,EAAqD;AACnD,cAAI,cAAJ;;AAEA,cAAI,KAAK,OAAL,CAAa,MAAb,GAAsB,CAAtB,IAA2B,CAAC,GAAG,KAAK,OAAL,CAAa,MAAhD,EAAwD;AACtD,YAAA,cAAc,GAAG,UAAU,CAAC,CAAD,CAA3B;AACD,WAFD,MAEO;AACL,kBAAM,MAAM,GAAG,KAAK,cAAL,CAAoB,CAApB,EAAuB,CAAvB,CAAf;AACA,kBAAM,WAAW,GAAG,KAAK,cAAL,CAAoB,CAApB,EAAuB,CAAvB,CAApB;AACA,YAAA,cAAc,GACV,GAAG,CAAC,IAAJ,CAAS,MAAM,CAAC,OAAO,CAAC,WAAD,CAAR,EAAuB,OAAO,CAAC,WAAD,CAA9B,CAAf,CADJ;AAED;;AAED,UAAA,GAAG,CAAC,IAAJ,CAAS,cAAT,EAZmD,CAanD;;AACA,UAAA,aAAa,CAAC,IAAd,CAAmB,cAAnB;AACD;;AAED,QAAA,SAAS,GAAG,GAAG,CAAC,IAAJ,CAAS,SAAT,CAAZ,CAlD6B,CAoD7B;;AACA,aAAK,eAAL,GAAuB,OAAvB,CAA+B,eAAe,IAAG;AAC/C,UAAA,SAAS,GAAG,GAAG,CAAC,GAAJ,CAAQ,SAAR,EAAmB,eAAnB,CAAZ;AACD,SAFD;AAIA,eAAO,SAAP;AACD,OA1DD;;AA4DA,YAAM,SAAS,GAAG,KAAK,yBAAL,CAA+B,GAA/B,CACd,KAAK,IAAI,KAAK,CAAC,IAAN,EADK,CAAlB;AAEA,YAAM,UAAU,GAAG,IAAnB;AACA,YAAM,cAAc,GAChB,KAAK,UAAL,CAAgB,QAAhB,CAAyB,iBAAzB,EAA4C,UAA5C,EAAwD,SAAxD,CADJ;AAGA,aAAO,CAAC,cAAD,EAAiB,MAAjB,CAAwB,aAAxB,CAAP;AACD,KAlFD;AAmFD;AAED;;;;AAIG;;;AACK,EAAA,gBAAgB,GAAA;AACtB,SAAK,YAAL,GAAqB,IAAD,IAAmB;AACrC,aAAO,GAAG,CAAC,IAAJ,CAAS,MAAK;AACnB,cAAM,UAAU,GAAa,EAA7B;AACA,YAAI,SAAJ;AACA,cAAM,MAAM,GAAG,IAAI,CAAC,KAAL,CAAW,CAAX,EAAc,KAAK,MAAL,CAAY,MAA1B,CAAf;AACA,cAAM,OAAO,GAAG,IAAI,CAAC,KAAL,CACZ,KAAK,MAAL,CAAY,MADA,EACQ,KAAK,MAAL,CAAY,MAAZ,GAAqB,KAAK,OAAL,CAAa,MAD1C,CAAhB;AAEA,cAAM,KAAK,GAAG,EAAd;;AACA,aAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,MAAL,CAAY,MAAhC,EAAwC,EAAE,CAA1C,EAA6C;AAC3C,UAAA,KAAK,CAAC,IAAN,CAAW;AAAC,YAAA,GAAG,EAAE,KAAK,MAAL,CAAY,CAAZ,CAAN;AAAsB,YAAA,KAAK,EAAE,MAAM,CAAC,CAAD;AAAnC,WAAX;AACD;;AACD,cAAM,QAAQ,GAAG,IAAI,QAAJ,CAAa,KAAb,CAAjB;AACA,cAAM,OAAO,GAAG,OAAO,CAAC,KAAK,OAAN,EAAe,QAAf,CAAvB,CAXmB,CAYnB;;AACA,aAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,aAAL,CAAmB,MAAvC,EAA+C,EAAE,CAAjD,EAAoD;AAClD,gBAAM,YAAY,GAAG,KAAK,aAAL,CAAmB,CAAnB,CAArB,CADkD,CAElD;AACA;;AACA,gBAAM,IAAI,GAAW,GAAG,CAAC,IAAJ,CAAS,YAAY,CAAC,OAAO,CAAC,CAAD,CAAR,EAAa,OAAO,CAAC,CAAD,CAApB,CAArB,CAArB;;AACA,cAAI,CAAC,KAAK,CAAV,EAAa;AACX,YAAA,SAAS,GAAG,IAAZ;AACD,WAFD,MAEO;AACL,YAAA,SAAS,GAAG,GAAG,CAAC,GAAJ,CAAQ,SAAR,EAAmB,IAAnB,CAAZ;AACD;;AACD,UAAA,UAAU,CAAC,IAAX,CAAgB,SAAhB;AACD,SAxBkB,CAyBnB;;;AACA,aAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,KAAK,cAAL,CAAoB,MAAxC,EAAgD,EAAE,CAAlD,EAAqD;AACnD,gBAAM,MAAM,GAAG,KAAK,cAAL,CAAoB,CAApB,EAAuB,CAAvB,CAAf;AACA,gBAAM,WAAW,GAAG,KAAK,cAAL,CAAoB,CAApB,EAAuB,CAAvB,CAApB,CAFmD,CAGnD;;AACA,gBAAM,UAAU,GACZ,GAAG,CAAC,IAAJ,CAAS,MAAM,CAAC,OAAO,CAAC,WAAD,CAAR,EAAuB,OAAO,CAAC,WAAD,CAA9B,CAAf,CADJ;AAEA,UAAA,UAAU,CAAC,IAAX,CAAgB,UAAhB;AACD;;AACD,eAAO,UAAP;AACD,OAnCM,CAAP;AAoCD,KArCD;AAsCD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiCG;;;AACM,QAAH,GAAG,CACL,CADK,EAEL,CAFK,EAGL,IAAA,GAAqB,EAHhB,EAGkB;AACzB,WAAO,UAAU,CAAC,IAAD,EAAO,CAAP,EAAU,CAAV,EAAa,IAAb,CAAjB;AACD,GAl+BuC,CAo+BxC;AACA;;AACA;;;;;;;;;;;;;;;;;;;;AAoBG;;;AACa,QAAV,UAAU,CAAI,OAAJ,EAAyB,IAAzB,EAAqD;AAEnE,WAAO,UAAU,CAAC,IAAD,EAAO,OAAP,EAAgB,IAAhB,CAAjB;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;AAsBG;;;AACe,QAAZ,YAAY,CACd,CADc,EAEd,CAFc,EAGe;AAC/B;AACA;AACA,UAAM,cAAc,GAAG,MAAM,KAAK,mBAAL,CAAyB,CAAzB,EAA4B,CAA5B,CAA7B;AACA,UAAM,MAAM,GAAG,cAAc,CAAC,CAAD,CAA7B;AACA,UAAM,OAAO,GAAG,cAAc,CAAC,CAAD,CAA9B;AACA,UAAM,aAAa,GAAG,KAAK,iBAAL,EAAtB;AACA,UAAM,MAAM,GAAG,aAAa,CAAC,MAAM,CAAC,MAAP,CAAc,OAAd,CAAD,CAA5B;AACA,UAAM,UAAU,GAAa,EAA7B;;AACA,SAAK,MAAM,IAAX,IAAmB,MAAnB,EAA2B;AACzB,YAAM,CAAC,GAAG,MAAM,IAAI,CAAC,IAAL,EAAhB;AACA,MAAA,UAAU,CAAC,IAAX,CAAgB,CAAC,CAAC,CAAD,CAAjB;AACD;;AACD,IAAA,GAAG,CAAC,OAAJ,CAAY,MAAZ;AACA,WAAO,gBAAgB,CAAC,UAAD,CAAvB;AACD;AAED;;;;;;;;AAQG;;;AACO,EAAA,eAAe,CAAC,MAAD,EAAuB;AAC9C,UAAM,YAAY,GAAkB,EAApC;AAEA,UAAM,aAAa,GAAG,MAAM,IAAI,IAAV,IAAkB,MAAM,CAAC,aAA/C;AACA,UAAM,OAAO,GAAG,aAAa,GAAG,KAAK,gBAAR,GAA2B,KAAK,OAA7D;AACA,UAAM,YAAY,GAAG,KAAK,UAAL,CAAgB,aAAhB,CAArB;;AACA,SAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,OAAO,CAAC,MAA5B,EAAoC,EAAE,CAAtC,EAAyC;AACvC,UAAI,aAAa,IAAI,CAAC,OAAO,CAAC,CAAD,CAAP,CAAW,SAAjC,EAA4C;AAC1C;AACA;AACD;;AACD,MAAA,YAAY,CAAC,IAAb,CACI;AAAC,QAAA,IAAI,EAAE,OAAO,CAAC,CAAD,CAAP,CAAW,YAAlB;AAAgC,QAAA,MAAM,EAAE,YAAY,CAAC,CAAD;AAApD,OADJ;AAED;;AACD,WAAO,YAAP;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6BG;;;AACa,MAAZ,YAAY,CAAC,IAAD,EAAc;AAC5B,SAAK,aAAL,GAAqB,IAArB;AACD;;AAEe,MAAZ,YAAY,GAAA;AACd,WAAO,KAAK,aAAZ;AACD;;AAEY,MAAT,SAAS,GAAA;AACX,WAAO,KAAK,UAAZ;AACD;;AAEY,MAAT,SAAS,CAAC,SAAD,EAAqB;AAChC,QAAI,KAAK,UAAL,KAAoB,SAAxB,EAAmC;AACjC,WAAK,UAAL,GAAkB,SAAlB;AACA,WAAK,gBAAL,GAAwB,KAAxB;AACD;AACF;;AAED,EAAA,OAAO,GAAA;AACL,UAAM,MAAM,GAAG,MAAM,OAAN,EAAf;;AACA,QAAI,MAAM,CAAC,oBAAP,KAAgC,CAAhC,IAAqC,KAAK,SAAL,IAAkB,IAAvD,IACA,KAAK,gBADT,EAC2B;AACzB,YAAM,gCAAgC,GAAG,GAAG,CAAC,MAAJ,GAAa,UAAtD;AACA,WAAK,UAAL,CAAgB,OAAhB;AACA,MAAA,MAAM,CAAC,oBAAP,IACI,gCAAgC,GAAG,GAAG,CAAC,MAAJ,GAAa,UADpD;AAED;;AACD,WAAO,MAAP;AACD;;AAEO,EAAA,kBAAkB,GAAA;AAExB,QAAI,SAAJ;;AAEA,QAAI,OAAO,KAAK,IAAZ,KAAqB,QAAzB,EAAmC;AACjC,MAAA,SAAS,GAAG,WAAW,CAAC,KAAK,IAAN,CAAvB;AACD,KAFD,MAEO,IAAI,KAAK,CAAC,OAAN,CAAc,KAAK,IAAnB,CAAJ,EAA8B;AACnC,WAAK,MAAM,IAAX,IAAmB,KAAK,IAAxB,EAA8B;AAC5B,YAAI,OAAO,IAAP,KAAgB,QAApB,EAA8B;AAC5B,gBAAM,IAAI,KAAJ,CAAU,oDAAV,CAAN;AACD;AACF;;AACD,MAAA,SAAS,GAAI,KAAK,IAAL,CAAuB,GAAvB,CAA2B,IAAI,IAAI,WAAW,CAAC,IAAD,CAA9C,CAAb;AAED,KARM,MAQA;AACL,YAAM,WAAW,GAAG,MAAM,CAAC,IAAP,CAAY,KAAK,IAAjB,CAApB;AACA,MAAA,SAAS,GAAG,EAAZ;AACA,YAAM,MAAM,GACR,KAAK,IADT;;AAEA,WAAK,MAAM,UAAX,IAAyB,WAAzB,EAAsC;AACpC,YAAI,OAAO,MAAM,CAAC,UAAD,CAAb,KAA8B,QAAlC,EAA4C;AAC1C,UAAA,SAAS,CAAC,UAAD,CAAT,GACI,WAAW,CAAC,MAAM,CAAC,UAAD,CAAP,CADf;AAED,SAHD,MAGO;AACL,gBAAM,IAAI,KAAJ,CAAU,oDAAV,CAAN;AACD;AACF;AACF;;AACD,WAAO,SAAP;AACD;;AAEO,EAAA,oBAAoB,GAAA;AAE1B,QAAI,OAAO,KAAK,OAAZ,KAAwB,QAAxB,IACA,OAAO,KAAK,OAAZ,KAAwB,UAD5B,EACwC;AACtC,aAAO,CAAC,WAAW,CAAC,OAAO,CAAC,mBAAR,CAA4B,KAAK,OAAjC,CAAD,CAAZ,CAAP;AACD,KAHD,MAGO,IAAI,KAAK,CAAC,OAAN,CAAc,KAAK,OAAnB,CAAJ,EAAiC;AACtC,aAAO,KAAK,OAAL,CAAa,GAAb,CACH,MAAM,IAAI,WAAW,CAAC,OAAO,CAAC,mBAAR,CAA4B,MAA5B,CAAD,CADlB,CAAP;AAED,KAHM,MAGA;AACL,YAAM,kBAAkB,GAAuC,EAA/D;;AACA,WAAK,MAAM,GAAX,IAAkB,KAAK,OAAvB,EAAgC;AAC9B,QAAA,kBAAkB,CAAC,GAAD,CAAlB,GACI,WAAW,CAAC,OAAO,CAAC,mBAAR,CAA4B,KAAK,OAAL,CAAa,GAAb,CAA5B,CAAD,CADf;AAED;;AACD,aAAO,kBAAP;AACD;AACF;;AAES,EAAA,iBAAiB,GAAA;AACzB,WAAO;AACL,MAAA,IAAI,EAAE,KAAK,kBAAL,EADD;AAEL,MAAA,OAAO,EAAE,KAAK,oBAAL,EAFJ;AAGL,MAAA,gBAAgB,EAAE;AAChB,QAAA,UAAU,EAAE,KAAK,SAAL,CAAe,YAAf,EADI;AAEhB,QAAA,MAAM,EAAE,KAAK,SAAL,CAAe,SAAf;AAFQ;AAHb,KAAP,CADyB,CASzB;AACA;AACA;AACD;;AAED,EAAA,kBAAkB,CAAC,cAAD,EAA+B;AAC/C,QAAI,cAAc,CAAC,gBAAf,IAAmC,IAAvC,EAA6C;AAC3C,YAAM,IAAI,KAAJ,CAAU,8CAAV,CAAN;AACD;;AACD,QAAI,cAAc,CAAC,YAAf,IAA+B,IAAnC,EAAyC;AACvC,YAAM,IAAI,KAAJ,CAAU,4CAAV,CAAN;AACD;;AACD,QAAI,cAAc,CAAC,kBAAf,IAAqC,IAAzC,EAA+C;AAC7C,YAAM,IAAI,KAAJ,CAAU,kDAAV,CAAN;AACD;;AAED,UAAM,QAAQ,GAAG,mBAAmB,CAAC,cAAc,CAAC,gBAAhB,CAApC;AAEA,UAAM,SAAS,GAAG,WAAW,CAAC,QAAD,CAA7B;AAEA,QAAI,IAAJ;;AACA,QAAI,OAAO,cAAc,CAAC,IAAtB,KAA+B,QAAnC,EAA6C;AAC3C,MAAA,IAAI,GAAG,WAAW,CAAC,cAAc,CAAC,IAAhB,CAAlB;AACD,KAFD,MAEO,IAAI,KAAK,CAAC,OAAN,CAAc,cAAc,CAAC,IAA7B,CAAJ,EAAwC;AAC7C,MAAA,IAAI,GAAG,cAAc,CAAC,IAAf,CAAoB,GAApB,CAAwB,SAAS,IAAI,WAAW,CAAC,SAAD,CAAhD,CAAP;AACD,KAFM,MAEA,IAAI,cAAc,CAAC,IAAf,IAAuB,IAA3B,EAAiC;AACtC,MAAA,IAAI,GAAG,EAAP;;AACA,WAAK,MAAM,GAAX,IAAkB,cAAc,CAAC,IAAjC,EAAuC;AACrC,QAAA,IAAI,CAAC,GAAD,CAAJ,GAAY,WAAW,CAAC,cAAc,CAAC,IAAf,CAAoB,GAApB,CAAD,CAAvB;AACD;AACF;;AAED,QAAI,OAAJ;;AACA,QAAI,KAAK,CAAC,OAAN,CAAc,cAAc,CAAC,OAA7B,CAAJ,EAA2C;AACzC,MAAA,OAAO,GAAG,cAAc,CAAC,OAAf,CAAuB,GAAvB,CAA2B,MAAM,IAAI,WAAW,CAAC,MAAD,CAAhD,CAAV;AACD,KAFD,MAEO,IAAI,cAAc,CAAC,OAAf,IAA0B,IAA9B,EAAoC;AACzC,MAAA,OAAO,GAAG,EAAV;;AACA,WAAK,MAAM,GAAX,IAAkB,cAAc,CAAC,OAAjC,EAA0C;AACxC,QAAA,OAAO,CAAC,GAAD,CAAP,GAAe,WAAW,CAAC,cAAc,CAAC,OAAf,CAAuB,GAAvB,CAAD,CAA1B;AACD;AACF;;AAED,SAAK,OAAL,CAAa;AAAC,MAAA,IAAD;AAAO,MAAA,OAAP;AAAgB,MAAA;AAAhB,KAAb;AACD;AAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAgFG;;;AACO,QAAJ,IAAI,CAAC,YAAD,EAAoC,MAApC,EAA0D;AAElE,QAAI,OAAO,YAAP,KAAwB,QAA5B,EAAsC;AACpC,YAAM,QAAQ,GAAG,EAAE,CAAC,eAAH,CAAmB,YAAnB,CAAjB;;AACA,UAAI,QAAQ,CAAC,MAAT,KAAoB,CAAxB,EAA2B;AACzB,cAAM,IAAI,UAAJ,CACF,0CAA0C,YAAY,GADpD,CAAN;AAED,OAHD,MAGO,IAAI,QAAQ,CAAC,MAAT,GAAkB,CAAtB,EAAyB;AAC9B,cAAM,IAAI,UAAJ,CACF,wBAAwB,QAAQ,CAAC,MAAM,sBAAvC,GACA,QAAQ,YAAY,GAFlB,CAAN;AAGD;;AACD,MAAA,YAAY,GAAG,QAAQ,CAAC,CAAD,CAAvB;AACD;;AACD,QAAI,YAAY,CAAC,IAAb,IAAqB,IAAzB,EAA+B;AAC7B,YAAM,IAAI,UAAJ,CACF,6DACA,sDAFE,CAAN;AAGD;;AAED,UAAM,kBAAkB,GACpB,MAAM,EAAE,CAAC,aAAH,CAAiB,KAAK,eAAL,CAAqB,MAArB,CAAjB,CADV;AAGA,UAAM,YAAY,GAAG,KAArB;AACA,UAAM,SAAS,GAAO,IAAtB;AACA,UAAM,WAAW,GAAG,KAAK,MAAL,CAAY,SAAZ,EAAuB,YAAvB,CAApB;AACA,UAAM,cAAc,GAAsB;AACxC,MAAA,aAAa,EAAE,WADyB;AAExC,MAAA,MAAM,EAAE,wBAFgC;AAGxC,MAAA,WAAW,EAAE,8BAA8B,OAAO,EAHV;AAIxC,MAAA,WAAW,EAAE;AAJ2B,KAA1C;AAOA,UAAM,gBAAgB,GAAG,MAAM,IAAI,IAAV,GAAiB,KAAjB,GAAyB,MAAM,CAAC,gBAAzD;;AACA,QAAI,gBAAgB,IAAI,KAAK,SAAL,IAAkB,IAA1C,EAAgD;AAC9C,MAAA,cAAc,CAAC,cAAf,GAAgC,KAAK,iBAAL,EAAhC;AACA,YAAM,UAAU,GAAG,WAAnB;AACA,YAAM;AAAC,QAAA,IAAI,EAAE,mBAAP;AAA4B,QAAA,KAAK,EAAE;AAAnC,UACF,MAAM,EAAE,CAAC,aAAH,CAAiB,MAAM,KAAK,SAAL,CAAe,UAAf,EAAvB,EAAoD,UAApD,CADV;AAEA,MAAA,kBAAkB,CAAC,KAAnB,CAAyB,IAAzB,CAA8B,GAAG,oBAAjC;AACA,MAAA,kBAAkB,CAAC,IAAnB,GAA0B,EAAE,CAAC,uBAAH,CACtB,CAAC,kBAAkB,CAAC,IAApB,EAA0B,mBAA1B,CADsB,CAA1B;AAED;;AAED,QAAI,KAAK,mBAAL,IAA4B,IAAhC,EAAsC;AACpC;AACA,YAAM,SAAS,GAAG,IAAlB;AACA,MAAA,wBAAwB,CAAC,KAAK,mBAAN,EAA2B,KAAK,IAAhC,EAAsC,SAAtC,CAAxB;AACA,MAAA,cAAc,CAAC,mBAAf,GAAqC,KAAK,mBAA1C;AACD;;AAED,IAAA,cAAc,CAAC,UAAf,GAA4B,kBAAkB,CAAC,IAA/C;AACA,IAAA,cAAc,CAAC,WAAf,GAA6B,kBAAkB,CAAC,KAAhD;AACA,WAAO,YAAY,CAAC,IAAb,CAAkB,cAAlB,CAAP;AACD;AAED;;;;;;;AAOG;;;AACH,EAAA,sBAAsB,CAAC,mBAAD,EAAwB;AAC5C,IAAA,wBAAwB,CAAC,mBAAD,EAAsB,KAAK,IAA3B,CAAxB;AACA,SAAK,mBAAL,GAA2B,mBAA3B;AACD;AAED;;;;;;;;;;AAUG;;;AACH,EAAA,sBAAsB,GAAA;AACpB,WAAO,KAAK,mBAAZ;AACD;;AA54CuC,C,CACxC;AACA;;AACA;;AACO,WAAA,CAAA,SAAA,GAAY,OAAZ;AA04CT,aAAa,CAAC,aAAd,CAA4B,WAA5B;AAEA;;;;;AAKG;;AACH;;AACA,OAAM,MAAO,UAAP,SAA0B,WAA1B,CAAqC;AAClC,UAAA,CAAA,SAAA,GAAY,YAAZ;AAET,aAAa,CAAC,aAAd,CAA4B,UAA5B","sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/* Original Source: engine/training.py */\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport {io, ModelPredictConfig as ModelPredictArgs, NamedTensorMap, Optimizer, Scalar, scalar, serialization, Tensor, Tensor1D, tensor1d, util} from '@tensorflow/tfjs-core';\n\nimport * as K from '../backend/tfjs_backend';\nimport {History, ModelLoggingVerbosity} from '../base_callbacks';\nimport {nameScope} from '../common';\nimport {NotImplementedError, RuntimeError, ValueError} from '../errors';\nimport {Shape} from '../keras_format/common';\nimport {LossIdentifier} from '../keras_format/loss_config';\nimport {OptimizerSerialization} from '../keras_format/optimizer_config';\nimport {MetricsIdentifier, TrainingConfig} from '../keras_format/training_config';\nimport {deserialize} from '../layers/serialization';\nimport * as losses from '../losses';\nimport * as Metrics from '../metrics';\nimport * as optimizers from '../optimizers';\nimport {LossOrMetricFn, NamedTensor} from '../types';\nimport {checkUserDefinedMetadata} from '../user_defined_metadata';\nimport {count, pyListRepeat, singletonOrArray, toCamelCase, toSnakeCase, unique} from '../utils/generic_utils';\nimport {printSummary} from '../utils/layer_utils';\nimport {range} from '../utils/math_utils';\nimport {convertPythonicToTs} from '../utils/serialization_utils';\nimport {LayerVariable} from '../variables';\nimport {version} from '../version';\n\nimport {Container, ContainerArgs} from './container';\nimport {Dataset} from './dataset_stub';\nimport {execute, FeedDict} from './executor';\nimport {DisposeResult, SymbolicTensor} from './topology';\nimport {evaluateDataset, fitDataset, ModelEvaluateDatasetArgs, ModelFitDatasetArgs} from './training_dataset';\nimport {checkBatchSize, disposeNewTensors, ensureTensorsRank2OrHigher, fitTensors, makeBatches, ModelFitArgs, sliceArrays, sliceArraysByIndices} from './training_tensors';\nimport {ClassWeight, ClassWeightMap, computeWeightedLoss, standardizeClassWeights, standardizeWeights} from './training_utils';\n\n/**\n * Helper function for polymorphic input data: 1. singleton Tensor.\n */\nexport function isDataTensor(x: Tensor|Tensor[]|{[inputName: string]: Tensor}|\n                             {[inputName: string]: Tensor[]}): boolean {\n  return x instanceof Tensor;\n}\n\n/**\n * Helper function for polymorphic input data: 2. Array of Tensor.\n */\nexport function isDataArray(x: Tensor|Tensor[]|\n                            {[inputName: string]: Tensor}): boolean {\n  return Array.isArray(x);\n}\n\n/**\n * Helper function for polymorphic input data: 3. \"dict\" of Tensor.\n */\nexport function isDataDict(x: Tensor|Tensor[]|\n                           {[inputName: string]: Tensor}): boolean {\n  return !isDataTensor(x) && !isDataArray(x);\n}\n\n/**\n * Normalizes inputs and targets provided by users.\n * @param data User-provided input data (polymorphic).\n * @param names An Array of expected Tensor names.\n * @param shapes Optional Array of expected Tensor shapes.\n * @param checkBatchAxis Whether to check that the batch axis of the arrays\n *   match  the expected value found in `shapes`.\n * @param exceptionPrefix String prefix used for exception formatting.\n * @returns List of standardized input Tensors (one Tensor per model input).\n * @throws ValueError: in case of improperly formatted user data.\n */\nexport function standardizeInputData(\n    data: Tensor|Tensor[]|{[inputName: string]: Tensor}, names: string[],\n    shapes?: Shape[], checkBatchAxis = true, exceptionPrefix = ''): Tensor[] {\n  if (names == null || names.length === 0) {\n    // Check for the case where the model expected no data, but some data got\n    // sent.\n    if (data != null) {\n      let gotUnexpectedData = false;\n      if (isDataArray(data) && (data as Tensor[]).length > 0) {\n        gotUnexpectedData = true;\n      } else if (isDataDict(data)) {\n        for (const key in data) {\n          if (data.hasOwnProperty(key)) {\n            gotUnexpectedData = true;\n            break;\n          }\n        }\n      } else {\n        // `data` is a singleton Tensor in this case.\n        gotUnexpectedData = true;\n      }\n      if (gotUnexpectedData) {\n        throw new ValueError(\n            `Error when checking model ${exceptionPrefix} expected no data, ` +\n            `but got ${data}`);\n      }\n    }\n    return [];\n  }\n  if (data == null) {\n    return names.map(name => null);\n  }\n\n  let arrays: Tensor[];\n  if (isDataDict(data)) {\n    data = data as {[inputName: string]: Tensor};\n    arrays = [];\n    for (const name of names) {\n      if (data[name] == null) {\n        throw new ValueError(\n            `No data provided for \"${name}\". Need data for each key in: ` +\n            `${names}`);\n      }\n      arrays.push(data[name]);\n    }\n  } else if (isDataArray(data)) {\n    data = data as Tensor[];\n    if (data.length !== names.length) {\n      throw new ValueError(\n          `Error when checking model ${exceptionPrefix}: the Array of ` +\n          `Tensors that you are passing to your model is not the size the ` +\n          `model expected. Expected to see ${names.length} Tensor(s), but ` +\n          `instead got the following list of Tensor(s): ${data}`);\n    }\n    arrays = data;\n  } else {\n    data = data as Tensor;\n    if (names.length > 1) {\n      throw new ValueError(\n          `The model ${exceptionPrefix} expects ${names.length} Tensor(s), ` +\n          `but only received one Tensor. Found: Tensor with shape ${\n              data.shape}`);\n    }\n    arrays = [data];\n  }\n\n  arrays = ensureTensorsRank2OrHigher(arrays);\n\n  // Check shape compatibility.\n  if (shapes != null) {\n    for (let i = 0; i < names.length; ++i) {\n      if (shapes[i] == null) {\n        continue;\n      }\n      const array = arrays[i];\n      if (array.shape.length !== shapes[i].length) {\n        throw new ValueError(\n            `Error when checking ${exceptionPrefix}: expected ${names[i]} ` +\n            `to have ${shapes[i].length} dimension(s). but got array with ` +\n            `shape ${array.shape}`);\n      }\n      for (let j = 0; j < shapes[i].length; ++j) {\n        if (j === 0 && !checkBatchAxis) {\n          // Skip the first (batch) axis.\n          continue;\n        }\n        const dim = array.shape[j];\n        const refDim = shapes[i][j];\n        if (refDim != null && refDim >= 0 && dim !== refDim) {\n          throw new ValueError(\n              `${exceptionPrefix} expected a batch of elements where each ` +\n              `example has shape [${shapes[i].slice(1, shapes[i].length)}] ` +\n              `(i.e.,tensor shape [*,${\n                  shapes[i].slice(1, shapes[i].length)}])` +\n              ` but the ${exceptionPrefix} received an input with ${\n                  array.shape[0]}` +\n              ` examples, each with shape [${\n                  array.shape.slice(1, array.shape.length)}]` +\n              ` (tensor shape [${array.shape}])`);\n        }\n      }\n    }\n  }\n  return arrays;\n}\n\n/**\n * User input validation for Tensors.\n * @param inputs `Array` of `tf.Tensor`s for inputs.\n * @param targets `Array` of `tf.Tensor`s for targets.\n * @param weights Optional `Array` of `tf.Tensor`s for sample weights.\n * @throws ValueError: in case of incorrectly formatted data.\n */\nexport function checkArrayLengths(\n    inputs: Tensor[], targets: Tensor[], weights?: Tensor[]) {\n  const setX = unique(inputs.map(input => input.shape[0]));\n  setX.sort();\n  const setY = unique(targets.map(target => target.shape[0]));\n  setY.sort();\n  // TODO(cais): Check `weights` as well.\n  if (setX.length > 1) {\n    throw new ValueError(\n        `All input Tensors (x) should have the same number of samples. ` +\n        `Got array shapes: ` +\n        `${JSON.stringify(inputs.map(input => input.shape))}`);\n  }\n  if (setY.length > 1) {\n    throw new ValueError(\n        `All target Tensors (y) should have the same number of samples. ` +\n        `Got array shapes: ` +\n        `${JSON.stringify(targets.map(target => target.shape))}`);\n  }\n  if (setX.length > 0 && setY.length > 0 && !util.arraysEqual(setX, setY)) {\n    throw new ValueError(\n        `Input Tensors should have the same number of samples as target ` +\n        `Tensors. Found ${setX[0]} input sample(s) and ${setY[0]} target ` +\n        `sample(s).`);\n  }\n}\n\n/**\n * Validation on the compatibility of targes and loss functions.\n *\n * This helps prevent users from using loss functions incorrectly.\n *\n * @param targets `Array` of `tf.Tensor`s of targets.\n * @param lossFns `Array` of loss functions.\n * @param outputShapes `Array` of shapes of model outputs.\n */\nfunction checkLossAndTargetCompatibility(\n    targets: Tensor[], lossFns: LossOrMetricFn[], outputShapes: Shape[]) {\n  // TODO(cais): Dedicated test coverage?\n  const keyLosses = [\n    losses.meanSquaredError, losses.binaryCrossentropy,\n    losses.categoricalCrossentropy\n  ];\n  for (let i = 0; i < targets.length; ++i) {\n    const y = targets[i];\n    const loss = lossFns[i];\n    const shape = outputShapes[i];\n    if (loss == null) {\n      continue;\n    }\n    if (loss === losses.categoricalCrossentropy) {\n      if (y.shape[y.shape.length - 1] === 1) {\n        throw new ValueError(\n            `You are passing a target array of shape ${y.shape} while using ` +\n            `a loss 'categorical_crossentropy'. 'categorical_crossentropy'` +\n            `expects targets to be binary matrices (1s and 0s) of shape ` +\n            `[samples, classes].`);\n        // TODO(cais): Example code in error message.\n      }\n    }\n    if (keyLosses.indexOf(loss) !== -1) {\n      const slicedYShape = y.shape.slice(1);\n      const slicedShape = shape.slice(1);\n      for (let j = 0; j < slicedYShape.length; ++j) {\n        const targetDim = slicedYShape[j];\n        const outDim = slicedShape[j];\n        if (outDim != null && targetDim !== outDim) {\n          throw new ValueError(\n              `A target Tensor with shape ${y.shape} was passed for an ` +\n              `output of shape ${shape}, while using a loss function that ` +\n              `expects targets to have the same shape as the output.`);\n        }\n      }\n    }\n  }\n}\n\n/**\n * Check inputs provided by the user.\n *\n * Porting Note: This corresponds to _standardize_input_data() in Python\n *   Keras. Because of the strong typing in TF.js, we do not need to convert\n *   the data. Specifically:\n *   1) in PyKeras, `data` can be `DataFrame` instances from pandas, for\n *      example. We don't need to worry about that here because there is no\n *      widely popular javascript/typesdcript equivalent of pandas (so far).\n *      If one becomes available in the future, we can add support.\n *   2) in PyKeras, inputs can be Python dict. But here we are stipulating\n * that the data is either a single `tf.Tensor` or an Array of `tf.Tensor`s. We\n * may add support for `Object` data inputs in the future when the need\n * arises.\n *\n * Instead, we perform basic checks for number of parameters and shapes.\n *\n * @param data: The input data.\n * @param names: Name for the inputs, from the model.\n * @param shapes: Expected shapes for the input data, from the model.\n * @param checkBatchAxis: Whether the size along the batch axis (i.e., the\n *   first dimension) will be checked for matching.\n * @param exceptionPrefix: Execption prefix message, used in generating error\n *   messages.\n * @throws ValueError: on incorrect number of inputs or mismatches in shapes.\n */\nfunction checkInputData(\n    data: Tensor|Tensor[], names: string[], shapes?: Shape[],\n    checkBatchAxis = true, exceptionPrefix = '') {\n  let arrays: Tensor[];\n  if (Array.isArray(data)) {\n    if (data.length !== names.length) {\n      throw new ValueError(\n          `Error when checking model ${exceptionPrefix}: the Array of ` +\n          `Tensors that you are passing to your model is not the size the ` +\n          `the model expected. Expected to see ${names.length} Tensor(s),` +\n          ` but instead got ${data.length} Tensors(s).`);\n    }\n    arrays = data;\n  } else {\n    if (names.length > 1) {\n      throw new ValueError(\n          `The model expects ${names.length} ${exceptionPrefix} Tensors, ` +\n          `but only received one Tensor. Found: array with shape ` +\n          `${JSON.stringify(data.shape)}.`);\n    }\n    arrays = [data];\n  }\n\n  if (shapes != null) {\n    for (let i = 0; i < names.length; ++i) {\n      if (shapes[i] == null) {\n        continue;\n      }\n      const array = arrays[i];\n      if (array.shape.length !== shapes[i].length) {\n        throw new ValueError(\n            `Error when checking ${exceptionPrefix}: expected ${names[i]} ` +\n            `to have ${shapes[i].length} dimension(s), but got array with ` +\n            `shape ${JSON.stringify(array.shape)}`);\n      }\n      for (let j = 0; j < shapes[i].length; ++j) {\n        if (j === 0 && !checkBatchAxis) {\n          continue;\n        }\n        const dim = array.shape[j];\n        const refDim = shapes[i][j];\n        if (refDim != null) {\n          if (refDim !== dim) {\n            throw new ValueError(\n                `Error when checking ${exceptionPrefix}: expected ` +\n                `${names[i]} to have shape ${JSON.stringify(shapes[i])} but ` +\n                `got array with shape ${JSON.stringify(array.shape)}.`);\n          }\n        }\n      }\n    }\n  }\n}\n\n/**\n * Maps metric functions to model outputs.\n * @param metrics An shortcut strings name, metric function, `Array` or dict\n *   (`Object`) of metric functions.\n * @param outputNames An `Array` of the names of model outputs.\n * @returns An `Array` (one entry per model output) of `Array` of metric\n *   functions. For instance, if the model has 2 outputs, and for the first\n *   output we want to compute `binaryAccuracy` and `binaryCrossentropy`,\n *   and just `binaryAccuracy` for the second output, the `Array` would look\n *   like:\n *     `[[binaryAccuracy, binaryCrossentropy],  [binaryAccuracy]]`\n * @throws TypeError: incompatible metrics format.\n */\nexport function collectMetrics(\n    metrics: string|LossOrMetricFn|Array<string|LossOrMetricFn>|\n    {[outputName: string]: string | LossOrMetricFn},\n    outputNames: string[]): Array<Array<string|LossOrMetricFn>> {\n  if (metrics == null || Array.isArray(metrics) && metrics.length === 0) {\n    return outputNames.map(name => []);\n  }\n\n  let wrappedMetrics: Array<string|LossOrMetricFn>|\n      {[outputName: string]: string | LossOrMetricFn};\n  if (typeof metrics === 'string' || typeof metrics === 'function') {\n    wrappedMetrics = [metrics];\n  } else if (Array.isArray(metrics) || typeof metrics === 'object') {\n    wrappedMetrics = metrics as Array<string|LossOrMetricFn>|\n        {[outputName: string]: string} | {[outputName: string]: LossOrMetricFn};\n  } else {\n    throw new TypeError(\n        'Type of metrics argument not understood. Expected an string,' +\n        `function, Array, or Object, found: ${metrics}`);\n  }\n\n  if (Array.isArray(wrappedMetrics)) {\n    // We then apply all metrics to all outputs.\n    return outputNames.map(\n        name => wrappedMetrics as Array<string|LossOrMetricFn>);\n  } else {\n    // In this case, metrics is a dict.\n    const nestedMetrics: Array<Array<string|LossOrMetricFn>> = [];\n    for (const name of outputNames) {\n      let outputMetrics: string|LossOrMetricFn|Array<string|LossOrMetricFn> =\n          wrappedMetrics.hasOwnProperty(name) ? wrappedMetrics[name] : [];\n      if (!Array.isArray(outputMetrics)) {\n        outputMetrics = [outputMetrics];\n      }\n      nestedMetrics.push(outputMetrics);\n    }\n    return nestedMetrics;\n  }\n}\n\nexport interface ModelEvaluateArgs {\n  /**\n   * Batch size (Integer). If unspecified, it will default to 32.\n   */\n  batchSize?: number;\n\n  /**\n   * Verbosity mode.\n   */\n  verbose?: ModelLoggingVerbosity;\n\n  /**\n   * Tensor of weights to weight the contribution of different samples to the\n   * loss and metrics.\n   */\n  sampleWeight?: Tensor;\n\n  /**\n   * integer: total number of steps (batches of samples)\n   * before declaring the evaluation round finished. Ignored with the default\n   * value of `undefined`.\n   */\n  steps?: number;\n}\n\n/**\n * Configuration for calls to `LayersModel.compile()`.\n */\nexport interface ModelCompileArgs {\n  /**\n   * An instance of `tf.train.Optimizer` or a string name for an Optimizer.\n   */\n  optimizer: string|Optimizer;\n\n  /**\n   * Object function(s) or name(s) of object function(s).\n   * If the model has multiple outputs, you can use a different loss\n   * on each output by passing a dictionary or an Array of losses.\n   * The loss value that will be minimized by the model will then be the sum\n   * of all individual losses.\n   */\n  loss: string|string[]|{[outputName: string]: string}|LossOrMetricFn|\n      LossOrMetricFn[]|{[outputName: string]: LossOrMetricFn};\n\n  /**\n   * List of metrics to be evaluated by the model during training and testing.\n   * Typically you will use `metrics=['accuracy']`.\n   * To specify different metrics for different outputs of a multi-output\n   * model, you could also pass a dictionary.\n   */\n  metrics?: string|LossOrMetricFn|Array<string|LossOrMetricFn>|\n      {[outputName: string]: string | LossOrMetricFn};\n\n  // TODO(cais): Add lossWeights, sampleWeightMode, weightedMetrics, and\n  //   targetTensors.\n}\n\nconst LAYERS_MODEL_FORMAT_NAME = 'layers-model';\n\n/**\n * A `tf.LayersModel` is a directed, acyclic graph of `tf.Layer`s plus methods\n * for training, evaluation, prediction and saving.\n *\n * `tf.LayersModel` is the basic unit of training, inference and evaluation in\n * TensorFlow.js. To create a `tf.LayersModel`, use `tf.LayersModel`.\n *\n * See also:\n *   `tf.Sequential`, `tf.loadLayersModel`.\n *\n * @doc {heading: 'Models', subheading: 'Classes'}\n */\nexport class LayersModel extends Container implements tfc.InferenceModel {\n  // The class name is 'Model' rather than 'LayersModel' for backwards\n  // compatibility since this class name shows up in the serialization format.\n  /** @nocollapse */\n  static className = 'Model';\n  protected optimizer_: Optimizer;\n  // Whether the model instance owns the optimizer: `true` if and only if\n  // `optimizer` is created from a string parameter during `compile()` call.\n  protected isOptimizerOwned: boolean;\n\n  loss: string|string[]|{[outputName: string]: string}|LossOrMetricFn|\n      LossOrMetricFn[]|{[outputName: string]: LossOrMetricFn};\n  lossFunctions: LossOrMetricFn[];\n\n  // TODO(cais): These private variables should probably not have the string\n  //   'feed' in their names, because we are not dealing with a symbolic\n  //   backend.\n  private feedOutputShapes: Shape[];\n  private feedLossFns: LossOrMetricFn[];\n  private collectedTrainableWeights: LayerVariable[];\n  private testFunction: (data: Tensor[]) => Scalar[];\n  history: History;\n\n  // A public property that can be set by Callbacks to order early stopping\n  // during `fit()` calls.\n  protected stopTraining_: boolean;\n  protected isTraining: boolean;\n\n  metrics: string|LossOrMetricFn|Array<string|LossOrMetricFn>|\n      {[outputName: string]: string | LossOrMetricFn};\n  metricsNames: string[];\n  // Porting Note: `metrics_tensors` in PyKeras is a symbolic tensor. But given\n  //   the imperative nature of tfjs-core, `metricsTensors` is a\n  //   TypeScript function here.\n  //   Also note that due to the imperative nature of tfjs-core, `metricsTensor`\n  //   here needs an output index to keep track of which output of the\n  //   LayersModel a metric belongs to. This is unlike `metrics_tensors` in\n  //   PyKeras, which is a `list` of symbolic tensors, each of which has\n  //   implicit \"knowledge\" of the outputs it depends on.\n  metricsTensors: Array<[LossOrMetricFn, number]>;\n\n  // User defind metadata (if any).\n  private userDefinedMetadata: {};\n\n  constructor(args: ContainerArgs) {\n    super(args);\n    this.isTraining = false;\n  }\n\n  /**\n   * Print a text summary of the model's layers.\n   *\n   * The summary includes\n   * - Name and type of all layers that comprise the model.\n   * - Output shape(s) of the layers\n   * - Number of weight parameters of each layer\n   * - If the model has non-sequential-like topology, the inputs each layer\n   *   receives\n   * - The total number of trainable and non-trainable parameters of the model.\n   *\n   * ```js\n   * const input1 = tf.input({shape: [10]});\n   * const input2 = tf.input({shape: [20]});\n   * const dense1 = tf.layers.dense({units: 4}).apply(input1);\n   * const dense2 = tf.layers.dense({units: 8}).apply(input2);\n   * const concat = tf.layers.concatenate().apply([dense1, dense2]);\n   * const output =\n   *     tf.layers.dense({units: 3, activation: 'softmax'}).apply(concat);\n   *\n   * const model = tf.model({inputs: [input1, input2], outputs: output});\n   * model.summary();\n   * ```\n   *\n   * @param lineLength Custom line length, in number of characters.\n   * @param positions Custom widths of each of the columns, as either\n   *   fractions of `lineLength` (e.g., `[0.5, 0.75, 1]`) or absolute number\n   *   of characters (e.g., `[30, 50, 65]`). Each number corresponds to\n   *   right-most (i.e., ending) position of a column.\n   * @param printFn Custom print function. Can be used to replace the default\n   *   `console.log`. For example, you can use `x => {}` to mute the printed\n   *   messages in the console.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  summary(\n      lineLength?: number, positions?: number[],\n      printFn:\n          // tslint:disable-next-line:no-any\n      (message?: any, ...optionalParams: any[]) => void = console.log) {\n    if (!this.built) {\n      throw new ValueError(\n          `This model has never been called, thus its weights have not been ` +\n          `created yet. So no summary can be displayed. Build the model ` +\n          `first (e.g., by calling it on some test data).`);\n    }\n    printSummary(this, lineLength, positions, printFn);\n  }\n\n  /**\n   * Configures and prepares the model for training and evaluation.  Compiling\n   * outfits the model with an optimizer, loss, and/or metrics.  Calling `fit`\n   * or `evaluate` on an un-compiled model will throw an error.\n   *\n   * @param args a `ModelCompileArgs` specifying the loss, optimizer, and\n   * metrics to be used for fitting and evaluating this model.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  compile(args: ModelCompileArgs): void {\n    if (args.loss == null) {\n      args.loss = [];\n    }\n    this.loss = args.loss;\n\n    if (typeof args.optimizer === 'string') {\n      this.optimizer_ = optimizers.getOptimizer(args.optimizer);\n      this.isOptimizerOwned = true;\n    } else {\n      if (!(args.optimizer instanceof Optimizer)) {\n        throw new ValueError(\n            `User-defined optimizer must be an instance of tf.Optimizer.`);\n      }\n      this.optimizer_ = args.optimizer;\n      this.isOptimizerOwned = false;\n    }\n\n    // TODO(cais): Add lossWeights.\n    // TODO(cais): Add sampleWeightMode.\n\n    // Prepare loss functions.\n    let lossFunctions: LossOrMetricFn[] = [];\n    if (!Array.isArray(args.loss) && typeof args.loss !== 'string' &&\n        typeof args.loss !== 'function') {\n      args.loss = args.loss as {[outputName: string]: string};\n      for (const name in args.loss) {\n        if (this.outputNames.indexOf(name) === -1) {\n          throw new ValueError(\n              `Unknown entry in loss dictionary: \"${name}\". ` +\n              `Only expected the following keys: ${this.outputNames}`);\n        }\n      }\n      for (const name of this.outputNames) {\n        if (args.loss[name] == null) {\n          console.warn(\n              `Output \"${name}\" is missing from loss dictionary. We assume ` +\n              `this was done on purpose, and we will not be expecting data ` +\n              `to be passed to ${name} during training`);\n        }\n        lossFunctions.push(losses.get(args.loss[name]));\n      }\n    } else if (Array.isArray(args.loss)) {\n      if (args.loss.length !== this.outputs.length) {\n        throw new ValueError(\n            `When passing an Array as loss, it should have one entry per ` +\n            `model output. The model has ${this.outputs.length} output(s), ` +\n            `but you passed loss=${args.loss}.`);\n      }\n      const theLosses = args.loss as Array<string|LossOrMetricFn>;\n      lossFunctions = theLosses.map(l => losses.get(l));\n    } else {\n      const lossFunction = losses.get(args.loss);\n      this.outputs.forEach(_ => {\n        lossFunctions.push(lossFunction);\n      });\n    }\n\n    this.lossFunctions = lossFunctions;\n\n    this.feedOutputNames = [];\n    this.feedOutputShapes = [];\n    this.feedLossFns = [];\n    for (let i = 0; i < this.outputs.length; ++i) {\n      // TODO(cais): Logic for skipping target(s).\n      const shape = this.internalOutputShapes[i];\n      const name = this.outputNames[i];\n      this.feedOutputNames.push(name);\n      this.feedOutputShapes.push(shape);\n      this.feedLossFns.push(this.lossFunctions[i]);\n    }\n\n    // TODO(cais): Add logic for output masks.\n    // TODO(cais): Add logic for sample weights.\n    const skipTargetIndices: number[] = [];\n\n    // Prepare metrics.\n    this.metrics = args.metrics;\n    // TODO(cais): Add weightedMetrics.\n    this.metricsNames = ['loss'];\n    this.metricsTensors = [];\n\n    // Compute total loss.\n    // Porting Note: In PyKeras, metrics_tensors are symbolic tensor objects.\n    //   Here, metricsTensors are TypeScript functions. This difference is due\n    //   to the difference in symbolic/imperative property of the backends.\n    nameScope('loss', () => {\n      for (let i = 0; i < this.outputs.length; ++i) {\n        if (skipTargetIndices.indexOf(i) !== -1) {\n          continue;\n        }\n        // TODO(cais): Add weightedLoss, sampleWeight and mask.\n        //   The following line should be weightedLoss\n        const weightedLoss = this.lossFunctions[i];\n        if (this.outputs.length > 1) {\n          this.metricsTensors.push([weightedLoss, i]);\n          this.metricsNames.push(this.outputNames[i] + '_loss');\n        }\n      }\n\n      // Porting Note: Due to the imperative nature of the backend, we calculate\n      //   the regularizer penalties in the totalLossFunction, instead of here.\n    });\n\n    const nestedMetrics = collectMetrics(args.metrics, this.outputNames);\n    // TODO(cais): Add nestedWeightedMetrics.\n\n    /**\n     * Helper function used in loop below.\n     */\n    const appendMetric =\n        (outputIndex: number, metricName: string,\n         metricTensor: LossOrMetricFn) => {\n          if (this.outputNames.length > 1) {\n            metricName = this.outputNames[outputIndex] + '_' + metricName;\n          }\n          this.metricsNames.push(metricName);\n          this.metricsTensors.push([metricTensor, outputIndex]);\n        };\n\n    nameScope('metric', () => {\n      for (let i = 0; i < this.outputs.length; ++i) {\n        if (skipTargetIndices.indexOf(i) !== -1) {\n          continue;\n        }\n        const outputMetrics = nestedMetrics[i];\n        // TODO(cais): Add weights and outputWeightedMetrics.\n\n        // TODO(cais): Add optional arg `weights` to the following function.\n        const handleMetrics = (metrics: Array<string|LossOrMetricFn>) => {\n          const metricNamePrefix = '';\n          let metricName: string;\n          let accFn: LossOrMetricFn;\n          let weightedMetricFn: LossOrMetricFn;\n          //  TODO(cais): Use 'weights_' for weighted metrics.\n\n          for (const metric of metrics) {\n            if (typeof metric === 'string' &&\n                ['accuracy', 'acc', 'crossentropy', 'ce'].indexOf(metric) !==\n                    -1) {\n              const outputShape = this.internalOutputShapes[i];\n\n              if (outputShape[outputShape.length - 1] === 1 ||\n                  this.lossFunctions[i] === losses.binaryCrossentropy) {\n                // case: binary accuracy/crossentropy.\n                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                  accFn = Metrics.binaryAccuracy;\n                } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                  accFn = Metrics.binaryCrossentropy;\n                }\n              } else if (\n                  this.lossFunctions[i] ===\n                  losses.sparseCategoricalCrossentropy) {\n                // case: categorical accuracy / crossentropy with sparse\n                // targets.\n                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                  accFn = Metrics.sparseCategoricalAccuracy;\n                } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                  accFn = Metrics.sparseCategoricalCrossentropy;\n                }\n              } else {\n                // case: categorical accuracy / crossentropy.\n                if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                  accFn = Metrics.categoricalAccuracy;\n                } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                  accFn = Metrics.categoricalCrossentropy;\n                }\n              }\n              let suffix: string;\n              if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                suffix = 'acc';\n              } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                suffix = 'ce';\n              }\n              // TODO(cais): Add weighting actually.\n              weightedMetricFn = accFn;\n              metricName = metricNamePrefix + suffix;\n            } else {\n              const metricFn = Metrics.get(metric);\n              // TODO(cais): Add weighting actually.\n              weightedMetricFn = metricFn;\n              metricName =\n                  metricNamePrefix + Metrics.getLossOrMetricName(metric);\n            }\n\n            // TODO(cais): Add weighting and masking to metricResult.\n            let metricResult: LossOrMetricFn;\n            nameScope(metricName, () => {\n              metricResult = weightedMetricFn;\n            });\n            appendMetric(i, metricName, metricResult);\n          }\n        };\n\n        handleMetrics(outputMetrics);\n        // TODO(cais): Call handleMetrics with weights.\n      }\n    });\n\n    // Porting Notes: Given the imperative backend of tfjs-core,\n    //   there is no need for constructing the symbolic graph and placeholders.\n    this.collectedTrainableWeights = this.trainableWeights;\n  }\n\n  /**\n   * Check trainable weights count consistency.\n   *\n   * This will raise a warning if `this.trainableWeights` and\n   * `this.collectedTrainableWeights` are inconsistent (i.e., have different\n   * numbers of parameters).\n   * Inconsistency will typically arise when one modifies `model.trainable`\n   * without calling `model.compile()` again.\n   */\n  protected checkTrainableWeightsConsistency(): void {\n    if (this.collectedTrainableWeights == null) {\n      return;\n    }\n    if (this.trainableWeights.length !==\n        this.collectedTrainableWeights.length) {\n      console.warn(\n          'Discrepancy between trainableweights and collected trainable ' +\n          'weights. Did you set `model.trainable` without calling ' +\n          '`model.compile()` afterwards?');\n    }\n  }\n\n  /**\n   * Returns the loss value & metrics values for the model in test mode.\n   *\n   * Loss and metrics are specified during `compile()`, which needs to happen\n   * before calls to `evaluate()`.\n   *\n   * Computation is done in batches.\n   *\n   * ```js\n   * const model = tf.sequential({\n   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n   * });\n   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\n   * const result = model.evaluate(\n   *     tf.ones([8, 10]), tf.ones([8, 1]), {batchSize: 4});\n   * result.print();\n   * ```\n   *\n   * @param x `tf.Tensor` of test data, or an `Array` of `tf.Tensor`s if the\n   * model has multiple inputs.\n   * @param y `tf.Tensor` of target data, or an `Array` of `tf.Tensor`s if the\n   * model has multiple outputs.\n   * @param args A `ModelEvaluateArgs`, containing optional fields.\n   *\n   * @return `Scalar` test loss (if the model has a single output and no\n   *   metrics) or `Array` of `Scalar`s (if the model has multiple outputs\n   *   and/or metrics). The attribute `model.metricsNames`\n   *   will give you the display labels for the scalar outputs.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  evaluate(\n      x: Tensor|Tensor[], y: Tensor|Tensor[],\n      args: ModelEvaluateArgs = {}): Scalar|Scalar[] {\n    const batchSize = args.batchSize == null ? 32 : args.batchSize;\n    checkBatchSize(batchSize);\n\n    // TODO(cais): Standardize `config.sampleWeights` as well.\n    // Validate user data.\n    const checkBatchAxis = true;\n    const standardizedOuts =\n        this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);\n    try {\n      // TODO(cais): If uses `useLearningPhase`, set the corresponding element\n      // of the input to 0.\n      const ins = standardizedOuts[0].concat(standardizedOuts[1]);\n      this.makeTestFunction();\n      const f = this.testFunction;\n      const testOuts =\n          this.testLoop(f, ins, batchSize, args.verbose, args.steps);\n      return singletonOrArray(testOuts);\n    } finally {\n      disposeNewTensors(standardizedOuts[0], x);\n      disposeNewTensors(standardizedOuts[1], y);\n    }\n  }\n\n  // TODO(cais): Add code snippet below once real dataset objects are\n  //   available.\n  /**\n   * Evaluate model using a dataset object.\n   *\n   * Note: Unlike `evaluate()`, this method is asynchronous (`async`);\n   *\n   * @param dataset A dataset object. Its `iterator()` method is expected\n   *   to generate a dataset iterator object, the `next()` method of which\n   *   is expected to produce data batches for evaluation. The return value\n   *   of the `next()` call ought to contain a boolean `done` field and a\n   *   `value` field. The `value` field is expected to be an array of two\n   *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former\n   *   case is for models with exactly one input and one output (e.g..\n   *   a sequential model). The latter case is for models with multiple\n   *   inputs and/or multiple outputs. Of the two items in the array, the\n   *   first is the input feature(s) and the second is the output target(s).\n   * @param args A configuration object for the dataset-based evaluation.\n   * @returns Loss and metric values as an Array of `Scalar` objects.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  async evaluateDataset(dataset: Dataset<{}>, args?: ModelEvaluateDatasetArgs):\n      Promise<Scalar|Scalar[]> {\n    this.makeTestFunction();\n    return evaluateDataset(this, dataset, args);\n  }\n\n  /**\n   * Get number of samples provided for training, evaluation or prediction.\n   *\n   * @param ins Input `tf.Tensor`.\n   * @param batchSize Integer batch size, optional.\n   * @param steps Total number of steps (batches of samples) before\n   * declaring loop finished. Optional.\n   * @param stepsName The public API's parameter name for `steps`.\n   * @returns Number of samples provided.\n   */\n  private checkNumSamples(\n      ins: Tensor|Tensor[], batchSize?: number, steps?: number,\n      stepsName = 'steps'): number {\n    let numSamples: number;\n    if (steps != null) {\n      numSamples = null;\n      if (batchSize != null) {\n        throw new ValueError(\n            `If ${stepsName} is set, batchSize must be null or undefined.` +\n            `Got batchSize = ${batchSize}`);\n      }\n    } else if (ins != null) {\n      if (Array.isArray(ins)) {\n        numSamples = ins[0].shape[0];\n      } else {\n        numSamples = ins.shape[0];\n      }\n    } else {\n      throw new ValueError(\n          `Either the input data should have a defined shape, or ` +\n          `${stepsName} shoud be specified.`);\n    }\n    return numSamples;\n  }\n\n  /**\n   * Execute internal tensors of the model with input data feed.\n   * @param inputs Input data feed. Must match the inputs of the model.\n   * @param outputs Names of the output tensors to be fetched. Must match\n   *   names of the SymbolicTensors that belong to the graph.\n   * @returns Fetched values for `outputs`.\n   */\n  execute(inputs: Tensor|Tensor[]|NamedTensorMap, outputs: string|string[]):\n      Tensor|Tensor[] {\n    if (Array.isArray(outputs) && outputs.length === 0) {\n      throw new ValueError(\n          '`outputs` is an empty Array, which is not allowed.');\n    }\n\n    const outputsIsArray = Array.isArray(outputs);\n    const outputNames =\n        (outputsIsArray ? outputs as string[] : [outputs as string]);\n    const outputSymbolicTensors = this.retrieveSymbolicTensors(outputNames);\n\n    // Format the input into a FeedDict.\n    const feedDict = new FeedDict();\n    if (inputs instanceof Tensor) {\n      inputs = [inputs];\n    }\n    if (Array.isArray(inputs)) {\n      if (inputs.length !== this.inputs.length) {\n        throw new ValueError(\n            `The number of inputs provided (${inputs.length}) ` +\n            `does not match the number of inputs of this model ` +\n            `(${this.inputs.length}).`);\n      }\n      for (let i = 0; i < this.inputs.length; ++i) {\n        feedDict.add(this.inputs[i], inputs[i]);\n      }\n    } else {\n      for (const input of this.inputs) {\n        const tensorValue = inputs[input.name];\n        if (tensorValue == null) {\n          throw new ValueError(\n              `No value is provided for the model's input ${input.name}`);\n        }\n        feedDict.add(input, tensorValue);\n      }\n    }\n\n    // Run execution.\n    const executeOutputs = execute(outputSymbolicTensors, feedDict) as Tensor[];\n    return outputsIsArray ? executeOutputs : executeOutputs[0];\n  }\n\n  /**\n   * Retrieve the model's internal symbolic tensors from symbolic-tensor names.\n   */\n  private retrieveSymbolicTensors(symbolicTensorNames: string[]):\n      SymbolicTensor[] {\n    const outputSymbolicTensors: SymbolicTensor[] =\n        pyListRepeat(null, symbolicTensorNames.length);\n    let outputsRemaining = symbolicTensorNames.length;\n    for (const layer of this.layers) {\n      const layerOutputs: SymbolicTensor[] =\n          Array.isArray(layer.output) ? layer.output : [layer.output];\n      const layerOutputNames = layerOutputs.map(output => output.name);\n      for (let i = 0; i < symbolicTensorNames.length; ++i) {\n        const index = layerOutputNames.indexOf(symbolicTensorNames[i]);\n        if (index !== -1) {\n          outputSymbolicTensors[i] = layerOutputs[index];\n          outputsRemaining--;\n        }\n        if (outputsRemaining === 0) {\n          break;\n        }\n      }\n      if (outputsRemaining === 0) {\n        break;\n      }\n    }\n\n    if (outputsRemaining > 0) {\n      const remainingNames: string[] = [];\n      outputSymbolicTensors.forEach((tensor, i) => {\n        if (tensor == null) {\n          remainingNames.push(symbolicTensorNames[i]);\n        }\n      });\n      throw new ValueError(\n          `Cannot find SymbolicTensors for output name(s): ` +\n          `${JSON.stringify(remainingNames)}`);\n    }\n    return outputSymbolicTensors;\n  }\n\n  /**\n   * Helper method to loop over some data in batches.\n   *\n   * Porting Note: Not using the functional approach in the Python equivalent\n   *   due to the imperative backend.\n   * Porting Note: Does not support step mode currently.\n   *\n   * @param ins: input data\n   * @param batchSize: integer batch size.\n   * @param verbose: verbosity model\n   * @returns: Predictions as `tf.Tensor` (if a single output) or an `Array` of\n   *   `tf.Tensor` (if multipe outputs).\n   */\n  private predictLoop(ins: Tensor|Tensor[], batchSize = 32, verbose = false):\n      Tensor|Tensor[] {\n    return tfc.tidy(() => {\n      const numSamples = this.checkNumSamples(ins);\n      if (verbose) {\n        throw new NotImplementedError(\n            'Verbose predictLoop() is not implemented yet.');\n      }\n\n      // Sample-based predictions.\n      // Porting Note: Tensor currently does not support sliced assignments as\n      //   in numpy, e.g., x[1:3] = y. Therefore we use concatenation while\n      //   iterating over the batches.\n\n      const batches = makeBatches(numSamples, batchSize);\n      const outsBatches: Tensor[][] = this.outputs.map(output => []);\n\n      // TODO(cais): Can the scope() be pushed down inside the for loop?\n      for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n        const batchOuts = tfc.tidy(() => {\n          const batchStart = batches[batchIndex][0];\n          const batchEnd = batches[batchIndex][1];\n          // TODO(cais): Take care of the case of the last element is a flag for\n          //   training/test.\n          const insBatch = sliceArrays(ins, batchStart, batchEnd);\n\n          // Construct the feeds for execute();\n          const feeds = [];\n          if (Array.isArray(insBatch)) {\n            for (let i = 0; i < insBatch.length; ++i) {\n              feeds.push({key: this.inputs[i], value: insBatch[i]});\n            }\n          } else {\n            feeds.push({key: this.inputs[0], value: insBatch});\n          }\n          const feedDict = new FeedDict(feeds);\n          return execute(this.outputs, feedDict) as Tensor[];\n        });\n        batchOuts.forEach((batchOut, i) => outsBatches[i].push(batchOut));\n      }\n      return singletonOrArray(\n          outsBatches.map(batches => tfc.concat(batches, 0)));\n    });\n  }\n\n  /**\n   * Generates output predictions for the input samples.\n   *\n   * Computation is done in batches.\n   *\n   * Note: the \"step\" mode of predict() is currently not supported.\n   *   This is because the TensorFlow.js core backend is imperative only.\n   *\n   * ```js\n   * const model = tf.sequential({\n   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n   * });\n   * model.predict(tf.ones([8, 10]), {batchSize: 4}).print();\n   * ```\n   *\n   * @param x The input data, as a Tensor, or an `Array` of `tf.Tensor`s if\n   *   the model has multiple inputs.\n   * @param args A `ModelPredictArgs` object containing optional fields.\n   *\n   * @return Prediction results as a `tf.Tensor`(s).\n   *\n   * @exception ValueError In case of mismatch between the provided input data\n   *   and the model's expectations, or in case a stateful model receives a\n   *   number of samples that is not a multiple of the batch size.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  predict(x: Tensor|Tensor[], args: ModelPredictArgs = {}): Tensor|Tensor[] {\n    const xsRank2OrHigher = ensureTensorsRank2OrHigher(x);\n    checkInputData(\n        xsRank2OrHigher, this.inputNames, this.feedInputShapes, false);\n    try {\n      // TODO(cais): Take care of stateful models.\n      //   if (this.stateful) ...\n      // TODO(cais): Take care of the learning_phase boolean flag.\n      //   if (this.useLearningPhase) ...\n      const batchSize = args.batchSize == null ? 32 : args.batchSize;\n      checkBatchSize(batchSize);\n      return this.predictLoop(xsRank2OrHigher, batchSize);\n    } finally {\n      disposeNewTensors(xsRank2OrHigher, x);\n    }\n  }\n\n  /**\n   * Returns predictions for a single batch of samples.\n   *\n   * ```js\n   * const model = tf.sequential({\n   *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n   * });\n   * model.predictOnBatch(tf.ones([8, 10])).print();\n   * ```\n   * @param x: Input samples, as a Tensor (for models with exactly one\n   *   input) or an array of Tensors (for models with more than one input).\n   * @return Tensor(s) of predictions\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  predictOnBatch(x: Tensor|Tensor[]): Tensor|Tensor[] {\n    checkInputData(x, this.inputNames, this.feedInputShapes, true);\n    // TODO(cais): Take care of the learning_phase boolean flag.\n    //   if (this.useLearningPhase) ...\n    const batchSize = (Array.isArray(x) ? x[0] : x).shape[0];\n    return this.predictLoop(x, batchSize);\n  }\n\n  protected standardizeUserDataXY(\n      x: Tensor|Tensor[]|{[inputName: string]: Tensor},\n      y: Tensor|Tensor[]|{[inputName: string]: Tensor}, checkBatchAxis = true,\n      batchSize?: number): [Tensor[], Tensor[]] {\n    // TODO(cais): Add sampleWeight, classWeight\n    if (this.optimizer_ == null) {\n      throw new RuntimeError(\n          'You must compile a model before training/testing. Use ' +\n          'LayersModel.compile(modelCompileArgs).');\n    }\n    const outputShapes: Shape[] = [];\n    for (let i = 0; i < this.feedOutputShapes.length; ++i) {\n      const outputShape = this.feedOutputShapes[i];\n      const lossFn = this.feedLossFns[i];\n      if (lossFn === losses.sparseCategoricalCrossentropy) {\n        outputShapes.push(\n            outputShape.slice(0, outputShape.length - 1).concat([1]));\n      } else {\n        // Porting Note: Because of strong typing `lossFn` must be a function.\n        outputShapes.push(outputShape);\n      }\n    }\n    x = standardizeInputData(\n        x, this.feedInputNames, this.feedInputShapes, false, 'input');\n    y = standardizeInputData(\n        y, this.feedOutputNames, outputShapes, false, 'target');\n    // TODO(cais): Standardize sampleWeights & classWeights.\n    checkArrayLengths(x, y, null);\n    // TODO(cais): Check sampleWeights as well.\n    checkLossAndTargetCompatibility(y, this.feedLossFns, this.feedOutputShapes);\n    if (this.stateful && batchSize != null && batchSize > 0) {\n      if (x[0].shape[0] % batchSize !== 0) {\n        throw new ValueError(\n            `In a stateful network, you should only pass inputs with a ` +\n            `number of samples that is divisible by the batch size ` +\n            `${batchSize}. Found: ${x[0].shape[0]} sample(s).`);\n      }\n    }\n    return [x, y];\n  }\n\n  protected async standardizeUserData(\n      x: Tensor|Tensor[]|{[inputName: string]: Tensor},\n      y: Tensor|Tensor[]|{[inputName: string]: Tensor},\n      sampleWeight?: Tensor|Tensor[]|{[outputName: string]: Tensor},\n      classWeight?: ClassWeight|ClassWeight[]|ClassWeightMap,\n      checkBatchAxis = true,\n      batchSize?: number): Promise<[Tensor[], Tensor[], Tensor[]]> {\n    const [standardXs, standardYs] =\n        this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);\n    // TODO(cais): Handle sampleWeights.\n    if (sampleWeight != null) {\n      throw new Error('sample weight is not supported yet.');\n    }\n\n    let standardSampleWeights: Tensor[] = null;\n    if (classWeight != null) {\n      const classWeights =\n          standardizeClassWeights(classWeight, this.outputNames);\n      standardSampleWeights = [];\n      for (let i = 0; i < classWeights.length; ++i) {\n        standardSampleWeights.push(\n            await standardizeWeights(standardYs[i], null, classWeights[i]));\n      }\n    }\n\n    // TODO(cais): Deal with the case of model.stateful == true.\n    return [standardXs, standardYs, standardSampleWeights];\n  }\n\n  /**\n   * Loop over some test data in batches.\n   * @param f A Function returning a list of tensors.\n   * @param ins Array of tensors to be fed to `f`.\n   * @param batchSize Integer batch size or `null` / `undefined`.\n   * @param verbose verbosity mode.\n   * @param steps Total number of steps (batches of samples) before\n   * declaring test finished. Ignored with the default value of `null` /\n   * `undefined`.\n   * @returns Array of Scalars.\n   */\n  private testLoop(\n      f: (data: Tensor[]) => Scalar[], ins: Tensor[], batchSize?: number,\n      verbose = 0, steps?: number): Scalar[] {\n    return tfc.tidy(() => {\n      const numSamples = this.checkNumSamples(ins, batchSize, steps, 'steps');\n      const outs: Scalar[] = [];\n      if (verbose > 0) {\n        throw new NotImplementedError('Verbose mode is not implemented yet.');\n      }\n      // TODO(cais): Use `indicesForConversionToDense' to prevent slow down.\n      if (steps != null) {\n        throw new NotImplementedError(\n            'steps mode in testLoop() is not implemented yet');\n      } else {\n        const batches = makeBatches(numSamples, batchSize);\n        const indexArray = tensor1d(range(0, numSamples));\n        for (let batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n          const batchStart = batches[batchIndex][0];\n          const batchEnd = batches[batchIndex][1];\n          const batchIds =\n              K.sliceAlongFirstAxis(\n                  indexArray, batchStart, batchEnd - batchStart) as Tensor1D;\n          // TODO(cais): In ins, train flag can be a number, instead of an\n          //   Tensor? Do we need to handle this in tfjs-layers?\n          const insBatch = sliceArraysByIndices(ins, batchIds) as Scalar[];\n          const batchOuts = f(insBatch);\n          if (batchIndex === 0) {\n            for (let i = 0; i < batchOuts.length; ++i) {\n              outs.push(scalar(0));\n            }\n          }\n          for (let i = 0; i < batchOuts.length; ++i) {\n            const batchOut = batchOuts[i];\n            outs[i] =\n                tfc.add(outs[i], tfc.mul(batchEnd - batchStart, batchOut));\n          }\n        }\n        for (let i = 0; i < outs.length; ++i) {\n          outs[i] = tfc.div(outs[i], numSamples);\n        }\n      }\n      return outs;\n    });\n  }\n\n  protected getDedupedMetricsNames(): string[] {\n    const outLabels = this.metricsNames;\n    // Rename duplicated metrics names (can happen with an output layer\n    // shared among multiple dataflows).\n    const dedupedOutLabels = [];\n    for (let i = 0; i < outLabels.length; ++i) {\n      const label = outLabels[i];\n      let newLabel = label;\n      if (count(outLabels, label) > 1) {\n        const dupIndex = count(outLabels.slice(0, i), label);\n        newLabel += `_${dupIndex}`;\n      }\n      dedupedOutLabels.push(newLabel);\n    }\n    return dedupedOutLabels;\n  }\n\n  /**\n   * Creates a function that performs the following actions:\n   *\n   * 1. computes the losses\n   * 2. sums them to get the total loss\n   * 3. call the optimizer computes the gradients of the LayersModel's\n   *    trainable weights w.r.t. the total loss and update the variables\n   * 4. calculates the metrics\n   * 5. returns the values of the losses and metrics.\n   */\n  protected makeTrainFunction(): (data: Tensor[]) => Scalar[] {\n    return (data: Tensor[]) => {\n      const lossValues: Scalar[] = [];\n\n      const inputs = data.slice(0, this.inputs.length);\n      const targets = data.slice(\n          this.inputs.length, this.inputs.length + this.outputs.length);\n      const sampleWeights = data.slice(\n          this.inputs.length + this.outputs.length,\n          this.inputs.length + this.outputs.length * 2);\n\n      const metricsValues: Scalar[] = [];\n\n      // Create a function that computes the total loss based on the\n      // inputs. This function is used for obtaining gradients through\n      // backprop.\n      const totalLossFunction = () => {\n        const feeds = [];\n        for (let i = 0; i < this.inputs.length; ++i) {\n          feeds.push({key: this.inputs[i], value: inputs[i]});\n        }\n        const feedDict = new FeedDict(feeds);\n        const outputs =\n            execute(this.outputs, feedDict, {'training': true}) as Tensor[];\n        // TODO(cais): Take care of the case of multiple outputs from a\n        //   single layer?\n\n        let totalLoss: Tensor;\n        for (let i = 0; i < this.lossFunctions.length; ++i) {\n          const lossFunction = this.lossFunctions[i];\n          let loss = lossFunction(targets[i], outputs[i]);\n          if (sampleWeights[i] != null) {\n            loss = computeWeightedLoss(loss, sampleWeights[i]);\n          }\n\n          // TODO(cais): push Scalar instead.\n          const meanLoss: Scalar = tfc.mean(loss);\n          // TODO(cais): Use a scope() instead, to avoid ownership.\n          lossValues.push(meanLoss);\n          if (i === 0) {\n            totalLoss = loss;\n          } else {\n            totalLoss = tfc.add(totalLoss, loss);\n          }\n        }\n\n        // Compute the metrics.\n        // TODO(cais): These should probably be calculated outside\n        //   totalLossFunction to benefit speed?\n        for (let i = 0; i < this.metricsTensors.length; ++i) {\n          let weightedMetric: Scalar;\n\n          if (this.outputs.length > 1 && i < this.outputs.length) {\n            weightedMetric = lossValues[i];\n          } else {\n            const metric = this.metricsTensors[i][0];\n            const outputIndex = this.metricsTensors[i][1];\n            weightedMetric =\n                tfc.mean(metric(targets[outputIndex], outputs[outputIndex]));\n          }\n\n          tfc.keep(weightedMetric);\n          // TODO(cais): Use a scope() instead, to avoid ownership.\n          metricsValues.push(weightedMetric);\n        }\n\n        totalLoss = tfc.mean(totalLoss);\n\n        // Add regularizer penalties.\n        this.calculateLosses().forEach(regularizerLoss => {\n          totalLoss = tfc.add(totalLoss, regularizerLoss);\n        });\n\n        return totalLoss as Scalar;\n      };\n\n      const variables = this.collectedTrainableWeights.map(\n          param => param.read() as tfc.Variable);\n      const returnCost = true;\n      const totalLossValue =\n          this.optimizer_.minimize(totalLossFunction, returnCost, variables);\n\n      return [totalLossValue].concat(metricsValues);\n    };\n  }\n\n  /**\n   * Create a function which, when invoked with an array of `tf.Tensor`s as a\n   * batch of inputs, returns the prespecified loss and metrics of the model\n   * under the batch of input data.\n   */\n  private makeTestFunction() {\n    this.testFunction = (data: Tensor[]) => {\n      return tfc.tidy(() => {\n        const valOutputs: Scalar[] = [];\n        let totalLoss: Scalar;\n        const inputs = data.slice(0, this.inputs.length);\n        const targets = data.slice(\n            this.inputs.length, this.inputs.length + this.outputs.length);\n        const feeds = [];\n        for (let i = 0; i < this.inputs.length; ++i) {\n          feeds.push({key: this.inputs[i], value: inputs[i]});\n        }\n        const feedDict = new FeedDict(feeds);\n        const outputs = execute(this.outputs, feedDict) as Tensor[];\n        // Compute total loss.\n        for (let i = 0; i < this.lossFunctions.length; ++i) {\n          const lossFunction = this.lossFunctions[i];\n          // TODO(cais): Add sample weighting and replace the simple\n          // averaging.\n          const loss: Scalar = tfc.mean(lossFunction(targets[i], outputs[i]));\n          if (i === 0) {\n            totalLoss = loss;\n          } else {\n            totalLoss = tfc.add(totalLoss, loss);\n          }\n          valOutputs.push(totalLoss);\n        }\n        // Compute the metrics.\n        for (let i = 0; i < this.metricsTensors.length; ++i) {\n          const metric = this.metricsTensors[i][0];\n          const outputIndex = this.metricsTensors[i][1];\n          // TODO(cais): Replace K.mean() with a proper weighting function.\n          const meanMetric =\n              tfc.mean(metric(targets[outputIndex], outputs[outputIndex]));\n          valOutputs.push(meanMetric as Scalar);\n        }\n        return valOutputs;\n      });\n    };\n  }\n\n  /**\n   * Trains the model for a fixed number of epochs (iterations on a\n   * dataset).\n   *\n   * ```js\n   * const model = tf.sequential({\n   *     layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n   * });\n   * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\n   * for (let i = 1; i < 5 ; ++i) {\n   *   const h = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), {\n   *       batchSize: 4,\n   *       epochs: 3\n   *   });\n   *   console.log(\"Loss after Epoch \" + i + \" : \" + h.history.loss[0]);\n   * }\n   * ```\n   *\n   * @param x `tf.Tensor` of training data, or an array of `tf.Tensor`s if the\n   * model has multiple inputs. If all inputs in the model are named, you\n   * can also pass a dictionary mapping input names to `tf.Tensor`s.\n   * @param y `tf.Tensor` of target (label) data, or an array of `tf.Tensor`s if\n   * the model has multiple outputs. If all outputs in the model are named,\n   * you can also pass a dictionary mapping output names to `tf.Tensor`s.\n   * @param args A `ModelFitArgs`, containing optional fields.\n   *\n   * @return A `History` instance. Its `history` attribute contains all\n   *   information collected during training.\n   *\n   * @exception ValueError In case of mismatch between the provided input\n   * data and what the model expects.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  async fit(\n      x: Tensor|Tensor[]|{[inputName: string]: Tensor},\n      y: Tensor|Tensor[]|{[inputName: string]: Tensor},\n      args: ModelFitArgs = {}): Promise<History> {\n    return fitTensors(this, x, y, args);\n  }\n\n  // TODO(cais): Add code snippet below when it's possible to instantiate\n  //   actual dataset objects.\n  /**\n   * Trains the model using a dataset object.\n   *\n   * @param dataset A dataset object. Its `iterator()` method is expected\n   *   to generate a dataset iterator object, the `next()` method of which\n   *   is expected to produce data batches for training. The return value\n   *   of the `next()` call ought to contain a boolean `done` field and a\n   *   `value` field. The `value` field is expected to be an array of two\n   *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former\n   *   case is for models with exactly one input and one output (e.g..\n   *   a sequential model). The latter case is for models with multiple\n   *   inputs and/or multiple outputs.\n   *   Of the two items in the array, the first is the input feature(s) and\n   *   the second is the output target(s).\n   * @param args A `ModelFitDatasetArgs`, containing optional fields.\n   *\n   * @return A `History` instance. Its `history` attribute contains all\n   *   information collected during training.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  async fitDataset<T>(dataset: Dataset<T>, args: ModelFitDatasetArgs<T>):\n      Promise<History> {\n    return fitDataset(this, dataset, args);\n  }\n\n  /**\n   * Runs a single gradient update on a single batch of data.\n   *\n   * This method differs from `fit()` and `fitDataset()` in the following\n   * regards:\n   *   - It operates on exactly one batch of data.\n   *   - It returns only the loss and matric values, instead of\n   *     returning the batch-by-batch loss and metric values.\n   *   - It doesn't support fine-grained options such as verbosity and\n   *     callbacks.\n   *\n   * @param x Input data. It could be one of the following:\n   *   - A `tf.Tensor`, or an Array of `tf.Tensor`s (in case the model has\n   *     multiple inputs).\n   *   - An Object mapping input names to corresponding `tf.Tensor` (if the\n   *     model has named inputs).\n   * @param y Target darta. It could be either a `tf.Tensor` a multiple\n   *   `tf.Tensor`s. It should be consistent with `x`.\n   * @returns Training loss or losses (in case the model has\n   *   multiple outputs), along with metrics (if any), as numbers.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n  async trainOnBatch(\n      x: Tensor|Tensor[]|{[inputName: string]: Tensor},\n      y: Tensor|Tensor[]|\n      {[inputName: string]: Tensor}): Promise<number|number[]> {\n    // TODO(cais): Support sampleWeight and classWeight.\n    // TODO(cais): Support Dataset objects.\n    const standardizeOut = await this.standardizeUserData(x, y);\n    const inputs = standardizeOut[0];\n    const targets = standardizeOut[1];\n    const trainFunction = this.makeTrainFunction();\n    const losses = trainFunction(inputs.concat(targets));\n    const lossValues: number[] = [];\n    for (const loss of losses) {\n      const v = await loss.data();\n      lossValues.push(v[0]);\n    }\n    tfc.dispose(losses);\n    return singletonOrArray(lossValues);\n  }\n\n  /**\n   * Extract weight values of the model.\n   *\n   * @param config: An instance of `io.SaveConfig`, which specifies\n   * model-saving options such as whether only trainable weights are to be\n   * saved.\n   * @returns A `NamedTensorMap` mapping original weight names (i.e.,\n   *   non-uniqueified weight names) to their values.\n   */\n  protected getNamedWeights(config?: io.SaveConfig): NamedTensor[] {\n    const namedWeights: NamedTensor[] = [];\n\n    const trainableOnly = config != null && config.trainableOnly;\n    const weights = trainableOnly ? this.trainableWeights : this.weights;\n    const weightValues = this.getWeights(trainableOnly);\n    for (let i = 0; i < weights.length; ++i) {\n      if (trainableOnly && !weights[i].trainable) {\n        // Optionally skip non-trainable weights.\n        continue;\n      }\n      namedWeights.push(\n          {name: weights[i].originalName, tensor: weightValues[i]});\n    }\n    return namedWeights;\n  }\n\n  /**\n   * Setter used for force stopping of LayersModel.fit() (i.e., training).\n   *\n   * Example:\n   *\n   * ```js\n   * const input = tf.input({shape: [10]});\n   * const output = tf.layers.dense({units: 1}).apply(input);\n   * const model = tf.model({inputs: [input], outputs: [output]});\n   * model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n   * const xs = tf.ones([8, 10]);\n   * const ys = tf.zeros([8, 1]);\n   *\n   * const history = await model.fit(xs, ys, {\n   *   epochs: 10,\n   *   callbacks: {\n   *     onEpochEnd: async (epoch, logs) => {\n   *       if (epoch === 2) {\n   *         model.stopTraining = true;\n   *       }\n   *     }\n   *   }\n   * });\n   *\n   * // There should be only 3 values in the loss array, instead of 10\n   * values,\n   * // due to the stopping after 3 epochs.\n   * console.log(history.history.loss);\n   * ```\n   */\n  set stopTraining(stop: boolean) {\n    this.stopTraining_ = stop;\n  }\n\n  get stopTraining(): boolean {\n    return this.stopTraining_;\n  }\n\n  get optimizer(): Optimizer {\n    return this.optimizer_;\n  }\n\n  set optimizer(optimizer: Optimizer) {\n    if (this.optimizer_ !== optimizer) {\n      this.optimizer_ = optimizer;\n      this.isOptimizerOwned = false;\n    }\n  }\n\n  dispose(): DisposeResult {\n    const result = super.dispose();\n    if (result.refCountAfterDispose === 0 && this.optimizer != null &&\n        this.isOptimizerOwned) {\n      const numTensorsBeforeOptmizerDisposal = tfc.memory().numTensors;\n      this.optimizer_.dispose();\n      result.numDisposedVariables +=\n          numTensorsBeforeOptmizerDisposal - tfc.memory().numTensors;\n    }\n    return result;\n  }\n\n  private getLossIdentifiers(): LossIdentifier|LossIdentifier[]|\n      {[outputName: string]: LossIdentifier} {\n    let lossNames: LossIdentifier|LossIdentifier[]|\n        {[outputName: string]: LossIdentifier};\n    if (typeof this.loss === 'string') {\n      lossNames = toSnakeCase(this.loss) as LossIdentifier;\n    } else if (Array.isArray(this.loss)) {\n      for (const loss of this.loss) {\n        if (typeof loss !== 'string') {\n          throw new Error('Serialization of non-string loss is not supported.');\n        }\n      }\n      lossNames = (this.loss as string[]).map(name => toSnakeCase(name)) as\n          LossIdentifier[];\n    } else {\n      const outputNames = Object.keys(this.loss);\n      lossNames = {} as {[outputName: string]: LossIdentifier};\n      const losses =\n          this.loss as {[outputName: string]: LossOrMetricFn | string};\n      for (const outputName of outputNames) {\n        if (typeof losses[outputName] === 'string') {\n          lossNames[outputName] =\n              toSnakeCase(losses[outputName] as string) as LossIdentifier;\n        } else {\n          throw new Error('Serialization of non-string loss is not supported.');\n        }\n      }\n    }\n    return lossNames;\n  }\n\n  private getMetricIdentifiers(): MetricsIdentifier[]|\n      {[key: string]: MetricsIdentifier} {\n    if (typeof this.metrics === 'string' ||\n        typeof this.metrics === 'function') {\n      return [toSnakeCase(Metrics.getLossOrMetricName(this.metrics))];\n    } else if (Array.isArray(this.metrics)) {\n      return this.metrics.map(\n          metric => toSnakeCase(Metrics.getLossOrMetricName(metric)));\n    } else {\n      const metricsIdentifiers: {[key: string]: MetricsIdentifier} = {};\n      for (const key in this.metrics) {\n        metricsIdentifiers[key] =\n            toSnakeCase(Metrics.getLossOrMetricName(this.metrics[key]));\n      }\n      return metricsIdentifiers;\n    }\n  }\n\n  protected getTrainingConfig(): TrainingConfig {\n    return {\n      loss: this.getLossIdentifiers(),\n      metrics: this.getMetricIdentifiers(),\n      optimizer_config: {\n        class_name: this.optimizer.getClassName(),\n        config: this.optimizer.getConfig()\n      } as OptimizerSerialization\n    };\n    // TODO(cais): Add weight_metrics when they are supported.\n    // TODO(cais): Add sample_weight_mode when it's supported.\n    // TODO(cais): Add loss_weights when it's supported.\n  }\n\n  loadTrainingConfig(trainingConfig: TrainingConfig) {\n    if (trainingConfig.weighted_metrics != null) {\n      throw new Error('Loading weight_metrics is not supported yet.');\n    }\n    if (trainingConfig.loss_weights != null) {\n      throw new Error('Loading loss_weights is not supported yet.');\n    }\n    if (trainingConfig.sample_weight_mode != null) {\n      throw new Error('Loading sample_weight_mode is not supported yet.');\n    }\n\n    const tsConfig = convertPythonicToTs(trainingConfig.optimizer_config) as\n        serialization.ConfigDict;\n    const optimizer = deserialize(tsConfig) as Optimizer;\n\n    let loss;\n    if (typeof trainingConfig.loss === 'string') {\n      loss = toCamelCase(trainingConfig.loss);\n    } else if (Array.isArray(trainingConfig.loss)) {\n      loss = trainingConfig.loss.map(lossEntry => toCamelCase(lossEntry));\n    } else if (trainingConfig.loss != null) {\n      loss = {} as {[outputName: string]: LossIdentifier};\n      for (const key in trainingConfig.loss) {\n        loss[key] = toCamelCase(trainingConfig.loss[key]) as LossIdentifier;\n      }\n    }\n\n    let metrics;\n    if (Array.isArray(trainingConfig.metrics)) {\n      metrics = trainingConfig.metrics.map(metric => toCamelCase(metric));\n    } else if (trainingConfig.metrics != null) {\n      metrics = {} as {[outputName: string]: MetricsIdentifier};\n      for (const key in trainingConfig.metrics) {\n        metrics[key] = toCamelCase(trainingConfig.metrics[key]);\n      }\n    }\n\n    this.compile({loss, metrics, optimizer});\n  }\n\n  /**\n   * Save the configuration and/or weights of the LayersModel.\n   *\n   * An `IOHandler` is an object that has a `save` method of the proper\n   * signature defined. The `save` method manages the storing or\n   * transmission of serialized data (\"artifacts\") that represent the\n   * model's topology and weights onto or via a specific medium, such as\n   * file downloads, local storage, IndexedDB in the web browser and HTTP\n   * requests to a server. TensorFlow.js provides `IOHandler`\n   * implementations for a number of frequently used saving mediums, such as\n   * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`\n   * for more details.\n   *\n   * This method also allows you to refer to certain types of `IOHandler`s\n   * as URL-like string shortcuts, such as 'localstorage://' and\n   * 'indexeddb://'.\n   *\n   * Example 1: Save `model`'s topology and weights to browser [local\n   * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);\n   * then load it back.\n   *\n   * ```js\n   * const model = tf.sequential(\n   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n   * console.log('Prediction from original model:');\n   * model.predict(tf.ones([1, 3])).print();\n   *\n   * const saveResults = await model.save('localstorage://my-model-1');\n   *\n   * const loadedModel = await tf.loadLayersModel('localstorage://my-model-1');\n   * console.log('Prediction from loaded model:');\n   * loadedModel.predict(tf.ones([1, 3])).print();\n   * ```\n   *\n   * Example 2. Saving `model`'s topology and weights to browser\n   * [IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API);\n   * then load it back.\n   *\n   * ```js\n   * const model = tf.sequential(\n   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n   * console.log('Prediction from original model:');\n   * model.predict(tf.ones([1, 3])).print();\n   *\n   * const saveResults = await model.save('indexeddb://my-model-1');\n   *\n   * const loadedModel = await tf.loadLayersModel('indexeddb://my-model-1');\n   * console.log('Prediction from loaded model:');\n   * loadedModel.predict(tf.ones([1, 3])).print();\n   * ```\n   *\n   * Example 3. Saving `model`'s topology and weights as two files\n   * (`my-model-1.json` and `my-model-1.weights.bin`) downloaded from\n   * browser.\n   *\n   * ```js\n   * const model = tf.sequential(\n   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n   * const saveResults = await model.save('downloads://my-model-1');\n   * ```\n   *\n   * Example 4. Send  `model`'s topology and weights to an HTTP server.\n   * See the documentation of `tf.io.http` for more details\n   * including specifying request parameters and implementation of the\n   * server.\n   *\n   * ```js\n   * const model = tf.sequential(\n   *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n   * const saveResults = await model.save('http://my-server/model/upload');\n   * ```\n   *\n   * @param handlerOrURL An instance of `IOHandler` or a URL-like,\n   * scheme-based string shortcut for `IOHandler`.\n   * @param config Options for saving the model.\n   * @returns A `Promise` of `SaveResult`, which summarizes the result of\n   * the saving, such as byte sizes of the saved artifacts for the model's\n   *   topology and weight values.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n   */\n  async save(handlerOrURL: io.IOHandler|string, config?: io.SaveConfig):\n      Promise<io.SaveResult> {\n    if (typeof handlerOrURL === 'string') {\n      const handlers = io.getSaveHandlers(handlerOrURL);\n      if (handlers.length === 0) {\n        throw new ValueError(\n            `Cannot find any save handlers for URL '${handlerOrURL}'`);\n      } else if (handlers.length > 1) {\n        throw new ValueError(\n            `Found more than one (${handlers.length}) save handlers for ` +\n            `URL '${handlerOrURL}'`);\n      }\n      handlerOrURL = handlers[0];\n    }\n    if (handlerOrURL.save == null) {\n      throw new ValueError(\n          'LayersModel.save() cannot proceed because the IOHandler ' +\n          'provided does not have the `save` attribute defined.');\n    }\n\n    const weightDataAndSpecs =\n        await io.encodeWeights(this.getNamedWeights(config));\n\n    const returnString = false;\n    const unusedArg: {} = null;\n    const modelConfig = this.toJSON(unusedArg, returnString);\n    const modelArtifacts: io.ModelArtifacts = {\n      modelTopology: modelConfig,\n      format: LAYERS_MODEL_FORMAT_NAME,\n      generatedBy: `TensorFlow.js tfjs-layers v${version}`,\n      convertedBy: null,\n    };\n\n    const includeOptimizer = config == null ? false : config.includeOptimizer;\n    if (includeOptimizer && this.optimizer != null) {\n      modelArtifacts.trainingConfig = this.getTrainingConfig();\n      const weightType = 'optimizer';\n      const {data: optimizerWeightData, specs: optimizerWeightSpecs} =\n          await io.encodeWeights(await this.optimizer.getWeights(), weightType);\n      weightDataAndSpecs.specs.push(...optimizerWeightSpecs);\n      weightDataAndSpecs.data = io.concatenateArrayBuffers(\n          [weightDataAndSpecs.data, optimizerWeightData]);\n    }\n\n    if (this.userDefinedMetadata != null) {\n      // Check serialized size of user-defined metadata.\n      const checkSize = true;\n      checkUserDefinedMetadata(this.userDefinedMetadata, this.name, checkSize);\n      modelArtifacts.userDefinedMetadata = this.userDefinedMetadata;\n    }\n\n    modelArtifacts.weightData = weightDataAndSpecs.data;\n    modelArtifacts.weightSpecs = weightDataAndSpecs.specs;\n    return handlerOrURL.save(modelArtifacts);\n  }\n\n  /**\n   * Set user-defined metadata.\n   *\n   * The set metadata will be serialized together with the topology\n   * and weights of the model during `save()` calls.\n   *\n   * @param setUserDefinedMetadata\n   */\n  setUserDefinedMetadata(userDefinedMetadata: {}): void {\n    checkUserDefinedMetadata(userDefinedMetadata, this.name);\n    this.userDefinedMetadata = userDefinedMetadata;\n  }\n\n  /**\n   * Get user-defined metadata.\n   *\n   * The metadata is supplied via one of the two routes:\n   *   1. By calling `setUserDefinedMetadata()`.\n   *   2. Loaded during model loading (if the model is constructed\n   *      via `tf.loadLayersModel()`.)\n   *\n   * If no user-defined metadata is available from either of the\n   * two routes, this function will return `undefined`.\n   */\n  getUserDefinedMetadata(): {} {\n    return this.userDefinedMetadata;\n  }\n}\nserialization.registerClass(LayersModel);\n\n/**\n * A `tf.Functional` is an alias to `tf.LayersModel`.\n *\n * See also:\n *   `tf.LayersModel`, `tf.Sequential`, `tf.loadLayersModel`.\n */\n/** @doc {heading: 'Models', subheading: 'Classes'} */\nexport class Functional extends LayersModel {\n  static className = 'Functional';\n}\nserialization.registerClass(Functional);\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}