{"ast":null,"code":"import { convertToTensor } from '../../tensor_util_env';\nimport { assertShapesMatch } from '../../util';\nimport { Reduction } from '../loss_ops_utils';\nimport { mul } from '../mul';\nimport { op } from '../operation';\nimport { scalar } from '../scalar';\nimport { sub } from '../sub';\nimport { sum } from '../sum';\nimport { computeWeightedLoss } from './compute_weighted_loss';\n/**\n * Computes the cosine distance loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param axis The dimension along which the cosine distance is computed.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\n\nfunction cosineDistance_(labels, predictions, axis, weights, reduction = Reduction.SUM_BY_NONZERO_WEIGHTS) {\n  const $labels = convertToTensor(labels, 'labels', 'cosineDistance');\n  const $predictions = convertToTensor(predictions, 'predictions', 'cosineDistance');\n  let $weights = null;\n\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'cosineDistance');\n  }\n\n  assertShapesMatch($labels.shape, $predictions.shape, 'Error in cosineDistance: ');\n  const one = scalar(1);\n  const losses = sub(one, sum(mul($labels, $predictions), axis, true));\n  return computeWeightedLoss(losses, $weights, reduction);\n}\n\nexport const cosineDistance = op({\n  cosineDistance_\n});","map":{"version":3,"sources":["../../../../../../../tfjs-core/src/ops/losses/cosine_distance.ts"],"names":[],"mappings":"AAiBA,SAAQ,eAAR,QAA8B,uBAA9B;AAEA,SAAQ,iBAAR,QAAgC,YAAhC;AACA,SAAQ,SAAR,QAAwB,mBAAxB;AACA,SAAQ,GAAR,QAAkB,QAAlB;AACA,SAAQ,EAAR,QAAiB,cAAjB;AACA,SAAQ,MAAR,QAAqB,WAArB;AACA,SAAQ,GAAR,QAAkB,QAAlB;AACA,SAAQ,GAAR,QAAkB,QAAlB;AAEA,SAAQ,mBAAR,QAAkC,yBAAlC;AAEA;;;;;;;;;;;;;;;AAeG;;AACH,SAAS,eAAT,CACI,MADJ,EAC0B,WAD1B,EACqD,IADrD,EAEI,OAFJ,EAGI,SAAS,GAAG,SAAS,CAAC,sBAH1B,EAGgD;AAC9C,QAAM,OAAO,GAAG,eAAe,CAAC,MAAD,EAAS,QAAT,EAAmB,gBAAnB,CAA/B;AACA,QAAM,YAAY,GACd,eAAe,CAAC,WAAD,EAAc,aAAd,EAA6B,gBAA7B,CADnB;AAEA,MAAI,QAAQ,GAAW,IAAvB;;AACA,MAAI,OAAO,IAAI,IAAf,EAAqB;AACnB,IAAA,QAAQ,GAAG,eAAe,CAAC,OAAD,EAAU,SAAV,EAAqB,gBAArB,CAA1B;AACD;;AACD,EAAA,iBAAiB,CACb,OAAO,CAAC,KADK,EACE,YAAY,CAAC,KADf,EACsB,2BADtB,CAAjB;AAGA,QAAM,GAAG,GAAG,MAAM,CAAC,CAAD,CAAlB;AACA,QAAM,MAAM,GAAG,GAAG,CAAC,GAAD,EAAM,GAAG,CAAC,GAAG,CAAC,OAAD,EAAU,YAAV,CAAJ,EAA6B,IAA7B,EAAmC,IAAnC,CAAT,CAAlB;AACA,SAAO,mBAAmB,CAAC,MAAD,EAAS,QAAT,EAAmB,SAAnB,CAA1B;AACD;;AACD,OAAO,MAAM,cAAc,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAAzB","sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {Tensor} from '../../tensor';\nimport {convertToTensor} from '../../tensor_util_env';\nimport {TensorLike} from '../../types';\nimport {assertShapesMatch} from '../../util';\nimport {Reduction} from '../loss_ops_utils';\nimport {mul} from '../mul';\nimport {op} from '../operation';\nimport {scalar} from '../scalar';\nimport {sub} from '../sub';\nimport {sum} from '../sum';\n\nimport {computeWeightedLoss} from './compute_weighted_loss';\n\n/**\n * Computes the cosine distance loss between two tensors.\n *\n * @param labels The ground truth output tensor, same dimensions as\n *    'predictions'.\n * @param predictions The predicted outputs.\n * @param axis The dimension along which the cosine distance is computed.\n * @param weights Tensor whose rank is either 0, or the same rank as\n *    `labels`, and must be broadcastable to `labels` (i.e., all dimensions\n *    must be either `1`, or the same as the corresponding `losses`\n *    dimension).\n * @param reduction Type of reduction to apply to loss. Should be of type\n *    `Reduction`\n *\n * @doc {heading: 'Training', subheading: 'Losses', namespace: 'losses'}\n */\nfunction cosineDistance_<T extends Tensor, O extends Tensor>(\n    labels: T|TensorLike, predictions: T|TensorLike, axis: number,\n    weights?: Tensor|TensorLike,\n    reduction = Reduction.SUM_BY_NONZERO_WEIGHTS): O {\n  const $labels = convertToTensor(labels, 'labels', 'cosineDistance');\n  const $predictions =\n      convertToTensor(predictions, 'predictions', 'cosineDistance');\n  let $weights: Tensor = null;\n  if (weights != null) {\n    $weights = convertToTensor(weights, 'weights', 'cosineDistance');\n  }\n  assertShapesMatch(\n      $labels.shape, $predictions.shape, 'Error in cosineDistance: ');\n\n  const one = scalar(1);\n  const losses = sub(one, sum(mul($labels, $predictions), axis, true));\n  return computeWeightedLoss(losses, $weights, reduction);\n}\nexport const cosineDistance = op({cosineDistance_});\n"],"sourceRoot":""},"metadata":{},"sourceType":"module"}